
import sys
import pandas as pd


from tigeropen.common.consts import (Language,        # è¯­è¨€
                                Market,           # å¸‚åœº
                                BarPeriod,        # kçº¿å‘¨æœŸ
                                QuoteRight)       # å¤æƒç±»å‹
from tigeropen.tiger_open_config import TigerOpenClientConfig
from tigeropen.common.util.signature_utils import read_private_key
from tigeropen.quote.quote_client import QuoteClient
from tigeropen.tiger_open_config import TigerOpenClientConfig

import time
import os
import hmac
import hashlib
import json
import numpy as np
import pandas as pd
import talib
from datetime import datetime, timedelta
from tigeropen.common.consts import Currency
from tigeropen.quote.quote_client import QuoteClient
from tigeropen.trade.trade_client import TradeClient
from dotenv import load_dotenv
from datetime import datetime, timedelta, timezone
import logging

# module logger
logger = logging.getLogger(__name__)


# Read command-line mode when running as a script, but be import-safe for tests
count_type = sys.argv[1] if len(sys.argv) > 1 else 'd'

client_config = None
quote_client = None
trade_client = None

# Only try to instantiate real client objects when running with explicit args
if len(sys.argv) > 1:
    if count_type == 'd':
        try:
            client_config = TigerOpenClientConfig(props_path='./openapicfg_dem')
            print("demo count\r\n")
        except Exception:
            client_config = None
    elif count_type == 'c':
        try:
            client_config = TigerOpenClientConfig(props_path='./openapicfg_com')
            print("combine count\r\n")
        except Exception:
            client_config = None
    else:
        print(f"é”™è¯¯ï¼šä¸æ”¯æŒçš„å‚æ•° '{count_type}'ï¼Œä»…æ”¯æŒ d æˆ– c")
        # When running as a script we will exit later in main; do not sys.exit on import
        client_config = None

# Try to build clients if we have a config; fail gracefully for import-time safety
if client_config is not None:
    try:
        print(client_config.account, client_config.tiger_id)
        quote_client = QuoteClient(client_config)  # è¡Œæƒ…å®¢æˆ·ç«¯
        trade_client = TradeClient(client_config)  # äº¤æ˜“å®¢æˆ·ç«¯
    except Exception:
        quote_client = None
        trade_client = None
# anothor method 
# def get_client_config():
#    client_config = TigerOpenClientConfig()
#    # å¦‚æœæ˜¯windownsç³»ç»Ÿï¼Œè·¯å¾„å­—ç¬¦ä¸²å‰éœ€åŠ  r é˜²æ­¢è½¬ä¹‰ï¼Œ å¦‚ read_private_key(r'C:\Users\admin\tiger.pem')
#    client_config.private_key = read_private_key('å¡«å†™ç§é’¥PEMæ–‡ä»¶çš„è·¯å¾„')
#    client_config.tiger_id = 'æ›¿æ¢ä¸ºtigerid'
#    client_config.account = 'æ›¿æ¢ä¸ºè´¦æˆ·ï¼Œå»ºè®®ä½¿ç”¨æ¨¡æ‹Ÿè´¦æˆ·'
#    client_config.language = Language.zh_CN  #å¯é€‰ï¼Œä¸å¡«é»˜è®¤ä¸ºè‹±è¯­'
#    # client_config.timezone = 'US/Eastern' # å¯é€‰æ—¶åŒºè®¾ç½®
#    return client_config
# è°ƒç”¨ä¸Šæ–¹å®šä¹‰çš„å‡½æ•°ç”Ÿæˆç”¨æˆ·é…ç½®ClientConfigå¯¹è±¡
# client_config = get_client_config()

# åˆçº¦é…ç½®ï¼ˆSIL2603ï¼šCOMEXç™½é“¶2026å¹´3æœˆæœŸè´§ï¼‰
# è€è™è¯åˆ¸æœŸè´§åˆçº¦æ ¼å¼ï¼š{å“ç§}.{äº¤æ˜“æ‰€}.{åˆ°æœŸæœˆ}ï¼Œéœ€ç¡®è®¤å®é™…åˆçº¦ä»£ç 
FUTURE_SYMBOL = "SIL.COMEX.202603"
FUTURE_CURRENCY = Currency.USD
FUTURE_MULTIPLIER = 1000  # ç™½é“¶æœŸè´§æ¯æ‰‹1000ç›å¸

# ç½‘æ ¼ç­–ç•¥æ ¸å¿ƒå‚æ•°ï¼ˆåŒ¹é…ä¹‹å‰è®¨è®ºçš„è§„åˆ™ï¼‰
GRID_MAX_POSITION = 3          # æœ€å¤§æŒä»“æ‰‹æ•°
GRID_ATR_PERIOD = 14           # ATRè®¡ç®—å‘¨æœŸ
GRID_BOLL_PERIOD = 20          # BOLLå¸¦å‘¨æœŸ
GRID_BOLL_STD = 2              # BOLLæ ‡å‡†å·®
GRID_RSI_PERIOD_1M = 14        # 1åˆ†é’ŸRSIå‘¨æœŸ
GRID_RSI_PERIOD_5M = 14        # 5åˆ†é’ŸRSIå‘¨æœŸ

# é£æ§å‚æ•°ï¼ˆ6ä¸‡ç¾å…ƒè´¦æˆ·é€‚é…ï¼‰
DAILY_LOSS_LIMIT = 600         # æ—¥äºæŸä¸Šé™ï¼ˆç¾å…ƒï¼‰
SINGLE_TRADE_LOSS = 180        # å•ç¬”æœ€å¤§äºæŸï¼ˆç¾å…ƒï¼‰
STOP_LOSS_MULTIPLIER = 1.0     # æ­¢æŸå€æ•°ï¼ˆATRï¼‰
MIN_KLINES = 10                 # æœ€å°‘Kçº¿æ¡æ•°é˜ˆå€¼ï¼ˆç”¨äºget_kline_dataï¼‰

# è¡Œæƒ…åˆ¤æ–­é˜ˆå€¼
BOLL_DIVERGENCE_THRESHOLD = 0.2  # BOLLå‘æ•£é˜ˆå€¼ï¼ˆè½¨é“é—´è·æ‰©å¤§â‰¥20%ï¼‰
ATR_AMPLIFICATION_THRESHOLD = 0.3 # ATRæ”¾å¤§â‰¥30%åˆ¤å®šæ³¢åŠ¨åŠ å‰§

# ç­–ç•¥å…¨å±€å˜é‡
current_position = 0           # å½“å‰æŒä»“æ‰‹æ•°
daily_loss = 0                 # å½“æ—¥ç´¯è®¡äºæŸ
grid_upper = 0                 # ç½‘æ ¼ä¸Šè½¨
grid_lower = 0                 # ç½‘æ ¼ä¸‹è½¨
last_boll_width = 0            # ä¸Šä¸€æ¬¡BOLLè½¨é“é—´è·
atr_5m = 0                     # 5åˆ†é’ŸATRå€¼
is_boll_divergence = False     # æ˜¯å¦BOLLå‘æ•£

# è¿è¡Œç¯å¢ƒæ ‡è¯†ï¼ˆç”¨äºæ—¥å¿—/æ¨¡æ‹Ÿä¸‹å•æç¤ºï¼‰ï¼Œä»¥åŠä»Šæ—¥æ—¥æœŸç”¨äºæ¯æ—¥äºæŸé‡ç½®
RUN_ENV = 'sandbox' if count_type == 'd' else 'production'
today = datetime.now().date()

# ====================== æ ¸å¿ƒå·¥å…·å‡½æ•° ======================
def get_timestamp():
    """ç”ŸæˆAPIç­¾åæ‰€éœ€çš„æ—¶é—´æˆ³"""
    return int(time.time() * 1000)

def verify_api_connection():
    """éªŒè¯APIè¿æ¥ï¼ˆä½¿ç”¨å®˜æ–¹æ ‡å‡†æ–¹æ³•get_account_infoï¼‰"""
    try:
        # è°ƒç”¨APIæŸ¥è¯¢è‚¡ç¥¨è¡Œæƒ…
        stock_price = quote_client.get_stock_briefs(['00700'])

        # æŸ¥è¯¢è¡Œæƒ…å‡½æ•°ä¼šè¿”å›ä¸€ä¸ªåŒ…å«å½“å‰è¡Œæƒ…å¿«ç…§çš„pandas.DataFrameå¯¹è±¡ï¼Œè§è¿”å›ç¤ºä¾‹ã€‚å…·ä½“å­—æ®µå«ä¹‰å‚è§get_stock_briefsæ–¹æ³•è¯´æ˜
        print(stock_price)

        exchanges = quote_client.get_future_exchanges()
        # æ‰“å°ç¬¬ä¸€ä¸ªäº¤æ˜“æ‰€çš„ä»£ç ï¼Œåç§°ï¼Œæ—¶åŒº
        for exchange1 in  exchanges.iloc :
            print(f'code: {exchange1.code}, name: {exchange1.name}, zone: {exchange1.zone}')


        contracts = quote_client.get_future_contracts('COMEX')

        # å°†åˆçº¦ä»£ç è®¾ç½®ä¸ºpandas DataFrame ç´¢å¼•ï¼Œå¹¶æŸ¥è¯¢å­—æ®µ
        contract1 = contracts.set_index('contract_code').loc['SIL2603']
        print(contract1.name)  # åˆçº¦åç§°
        print(contract1.multiplier)  # åˆçº¦ä¹˜æ•°
        print(contract1.last_trading_date)  # æœ€åäº¤æ˜“æ—¥

        contracts = quote_client.get_all_future_contracts('SIL')
        print(contracts)

        contract = quote_client.get_current_future_contract('SIL')
        print(contract)

        permissions = quote_client.get_quote_permission()
        print(permissions)

        klines = quote_client.get_future_brief(['SIL2603'])
            
        print(klines.head().to_string())


        klines = quote_client.get_future_bars(
            ['SIL2603'],
            BarPeriod.ONE_MINUTE,
            -1,
            -1,
            2,
            None)

        print(klines.head().to_string())

        #place_tiger_order('BUY', 1, 91.63, 90)
        #place_tiger_order('SELL', 1, 91.63, 90)

        return True
    except Exception as e:
        # é€šç”¨å¼‚å¸¸æ•è·ï¼Œè¾“å‡ºè¯¦ç»†é”™è¯¯
        error_msg = str(e)
        print(f"âŒ {count_type} ç¯å¢ƒè¿æ¥å¤±è´¥ï¼š{error_msg}")
        return False

def get_future_brief_info(symbol):
    """è°ƒç”¨QuoteClient.get_future_briefè·å–æœŸè´§åˆçº¦æ¦‚è¦ä¿¡æ¯"""
    try:
        future_brief_list = quote_client.get_future_brief(identifiers=[symbol])
        if not future_brief_list:
            raise Exception(f"æœªè·å–åˆ° {symbol} çš„æ¦‚è¦ä¿¡æ¯ï¼Œå°†ä½¿ç”¨é»˜è®¤å‚æ•°ï¼ˆä¹˜æ•°1000ï¼‰")
        
        # æå–åˆçº¦ä¿¡æ¯
        future_brief = future_brief_list[0]
        global FUTURE_MULTIPLIER, FUTURE_TICK_SIZE, FUTURE_EXPIRY_DATE
        FUTURE_MULTIPLIER = future_brief.multiplier if future_brief.multiplier else 1000
        FUTURE_TICK_SIZE = future_brief.tick_size if future_brief.tick_size else 0.01
        FUTURE_EXPIRY_DATE = future_brief.expiry_date if future_brief.expiry_date else "2026-03-28"
        
        # æ‰“å°åˆçº¦ä¿¡æ¯
        print(f"âœ… è·å–åˆçº¦ä¿¡æ¯æˆåŠŸ")
        print(f"   åˆçº¦ä»£ç ï¼š{future_brief.symbol}")
        print(f"   äº¤æ˜“æ‰€ï¼š{future_brief.exchange}")
        print(f"   åˆçº¦ä¹˜æ•°ï¼š{FUTURE_MULTIPLIER} ç›å¸/æ‰‹")
        print(f"   æœ€å°å˜åŠ¨ä»·ä½ï¼š{FUTURE_TICK_SIZE} USD")
        print(f"   åˆ°æœŸæ—¥ï¼š{FUTURE_EXPIRY_DATE}")
        
        return True
    except Exception as e:
        # é™çº§å¤„ç†ï¼šä½¿ç”¨é»˜è®¤å‚æ•°
        print(f"âš ï¸ è·å–æ¦‚è¦ä¿¡æ¯å¤±è´¥ï¼š{e}")
        print(f"ğŸ“Œ é™çº§ä½¿ç”¨é»˜è®¤å‚æ•°ï¼šä¹˜æ•°=1000ï¼Œæœ€å°å˜åŠ¨ä»·ä½=0.01ï¼Œåˆ°æœŸæ—¥=2026-03-28")
        #global FUTURE_MULTIPLIER
        #FUTURE_MULTIPLIER = 1000
        return True

def _to_api_identifier(symbol: str) -> str:
    """Convert known symbol patterns into the compact identifier expected by the
    quote by-page API.

    Examples:
      - 'SIL.COMEX.202603' -> 'SIL2603'
      - 'SIL2603' -> 'SIL2603' (unchanged)

    This is a best-effort helper to improve compatibility with different symbol
    naming conventions returned/used elsewhere in the codebase and SDK.
    """
    try:
        s = symbol.strip()
        # Already compact like SIL2603
        import re
        if re.match(r'^[A-Za-z]+\d{4}$', s):
            return s
        # Dotted format like 'SIL.COMEX.202603' -> base 'SIL', date '202603' -> 'SIL2603'
        if '.' in s:
            parts = s.split('.')
            base = parts[0]
            datepart = parts[-1]
            if len(datepart) == 6 and datepart.isdigit():
                year = datepart[:4]
                month = datepart[4:6]
                return f"{base}{year[-2:]}{month}"
        return s
    except Exception:
        return symbol


def get_kline_data(symbol, period, count=100, start_time=None, end_time=None):
    """Fetch K-line data (candles) and normalize to a pandas.DataFrame.

    Supports optional `start_time` and `end_time` (both `datetime` or epoch ms) and
    best-effort automatic paging using `QuoteClient.get_future_bars_by_page` for
    single-symbol time-range or large requests.

    Parameters
    - symbol: str or list-like of symbols
    - period: str one of {'1min','5min','1h','1d'}
    - count: int, number of most-recent bars to return
    - start_time, end_time: optional datetime or epoch ms (milliseconds since epoch)

    Returns
    - pandas.DataFrame indexed by timezone-aware `time` (Asia/Shanghai) with
      columns ['open','high','low','close','volume'] or an empty DataFrame on error.
    """
    period_map = {
        "1min": BarPeriod.ONE_MINUTE,
        "5min": BarPeriod.FIVE_MINUTES,
        "1h": BarPeriod.ONE_HOUR,
        "1d": BarPeriod.DAY
    }
    if period not in period_map:
        print(f"âŒ ä¸æ”¯æŒçš„å‘¨æœŸï¼š{period}")
        return pd.DataFrame()
    
    try:
        end_time = datetime.now(timezone.utc)
        start_time = end_time - timedelta(hours=4) if period == "5min" else end_time - timedelta(hours=1)
        # keep a lightweight backward-compatible print while adding structured logs
        print(symbol)
        logger.debug("get_kline_data request: symbol=%s period=%s count=%s start_time=%s end_time=%s", symbol, period, count, start_time, end_time)
        # Accept symbol as string or list-like, and use it when calling the API
        if isinstance(symbol, str):
            symbol1 = [symbol]
        elif isinstance(symbol, (list, tuple, pd.Series)):
            symbol1 = list(symbol)
        else:
            symbol1 = [symbol]

        # Convert optional start/end into epoch ms (UTC). Accept datetime (tz-aware or naive) or integer ms
        def _to_epoch_ms(t):
            if t is None:
                return None
            if isinstance(t, (int, float)):
                return int(t)
            if isinstance(t, datetime):
                # assume naive datetimes are UTC
                if t.tzinfo is None:
                    t = t.replace(tzinfo=timezone.utc)
                return int(t.astimezone(timezone.utc).timestamp() * 1000)
            raise ValueError('start_time/end_time must be datetime or epoch ms')

        start_ms = _to_epoch_ms(start_time) if 'start_time' in locals() or 'start_time' in globals() else None
        end_ms = _to_epoch_ms(end_time) if 'end_time' in locals() or 'end_time' in globals() else None

        # If a time range or a large count is requested and we have a single symbol, try the paged API
        use_paging = (start_ms is not None or end_ms is not None or count > 1000) and len(symbol1) == 1 and hasattr(quote_client, 'get_future_bars_by_page')

        if use_paging:
            # fetch pages until done or we've collected `count` rows
            all_pages = []
            next_token = None
            fetched = 0
            while True:
                try:
                    # API may accept (identifier, period, begin_time, end_time, total, page_size, time_interval)
                    identifier_for_api = _to_api_identifier(symbol1[0])
                    logger.debug("using identifier_for_api=%s for by-page call", identifier_for_api)
                    # prefer identifier string for by-page fetch
                    res = quote_client.get_future_bars_by_page(
                        identifier_for_api,
                        period_map[period],
                        start_ms if start_ms is not None else -1,
                        end_ms if end_ms is not None else -1,
                        count,
                        min(1000, max(100, count)),
                        2)
                except TypeError:
                    # fall back to a simpler signature if needed
                    identifier_for_api = _to_api_identifier(symbol1[0])
                    res = quote_client.get_future_bars_by_page(identifier_for_api, period_map[period], start_ms or -1, end_ms or -1, count)

                df_page = None
                next_token = None
                if isinstance(res, tuple) and len(res) == 2:
                    df_page, next_token = res
                elif isinstance(res, dict):
                    df_page = res.get('df') or res.get('data') or pd.DataFrame(res)
                    next_token = res.get('next_page_token')
                else:
                    df_page = res

                token_from_column = False
                if isinstance(df_page, pd.DataFrame):
                    # If the SDK returns next_page_token as a column, prefer that
                    if 'next_page_token' in df_page.columns:
                        # extract last non-null token
                        non_null = df_page['next_page_token'].dropna()
                        next_token = non_null.iloc[-1] if len(non_null) > 0 else None
                        # drop the token column from data we keep
                        df_page = df_page.drop(columns=['next_page_token'])
                        token_from_column = True
                    all_pages.append(df_page)
                    fetched += len(df_page)
                else:
                    # If the page returned an iterable of bars, convert to DataFrame
                    try:
                        df_page = pd.DataFrame([{
                            'time': getattr(bar, 'time', None),
                            'open': getattr(bar, 'open', None),
                            'high': getattr(bar, 'high', None),
                            'low': getattr(bar, 'low', None),
                            'close': getattr(bar, 'close', None),
                            'volume': getattr(bar, 'volume', None)
                        } for bar in df_page])
                        all_pages.append(df_page)
                        fetched += len(df_page)
                    except Exception:
                        # give up if we cannot interpret page
                        break

                if not next_token or fetched >= count:
                    break

                # otherwise keep looping; pass page token when possible â€” best-effort
                try:
                    logger.debug("paging: token=%s fetched=%s target=%s token_from_column=%s", next_token, fetched, count, token_from_column)
                    if token_from_column:
                        # When token came from a DataFrame column, prefer the simpler get_future_bars that accepts page_token
                        try:
                            res = quote_client.get_future_bars(symbol1, period_map[period], -1, -1, count, next_token)
                        except Exception:
                            # fall back to by-page with token if direct call fails
                            logger.debug("get_future_bars with page_token failed; falling back to by_page with page_token")
                            res = quote_client.get_future_bars_by_page(symbol1[0], period_map[period], start_ms or -1, end_ms or -1, count, min(1000, count), 2, page_token=next_token)
                    else:
                        # try page-token variant on get_future_bars_by_page
                        try:
                            res = quote_client.get_future_bars_by_page(symbol1[0], period_map[period], start_ms or -1, end_ms or -1, count, min(1000, count), 2, page_token=next_token)
                        except TypeError:
                            # some SDKs don't accept page_token param on by_page; fall back to get_future_bars which accepts page_token
                            # prefer a simple by-page call without page_token if get_future_bars is not available on this client
                            if hasattr(quote_client, 'get_future_bars'):
                                try:
                                    res = quote_client.get_future_bars(symbol1, period_map[period], -1, -1, count, next_token)
                                except Exception:
                                    logger.debug("get_future_bars failed to accept token; attempting plain by_page call")
                                    res = quote_client.get_future_bars_by_page(symbol1[0], period_map[period], start_ms or -1, end_ms or -1, count, min(1000, count), 2)
                            else:
                                # try a plain by-page call (no page_token)
                                res = quote_client.get_future_bars_by_page(symbol1[0], period_map[period], start_ms or -1, end_ms or -1, count, min(1000, count), 2)
                except Exception:
                    # if all attempts fail, exit loop
                    logger.exception("paging loop exception")
                    break

            if all_pages:
                klines = pd.concat(all_pages, ignore_index=True)
            else:
                klines = pd.DataFrame()
        else:
            klines = quote_client.get_future_bars(
                symbol1,
                period_map[period],
                -1,
                -1,
                count,
                None)

        # required columns we expect in the final DataFrame
        required_cols = ['open', 'high', 'low', 'close', 'volume']

        # Normalize returned klines: can be a pandas.DataFrame or an iterable of bar objects
        if isinstance(klines, pd.DataFrame):
            df = klines.copy()
            if 'time' not in df.columns:
                print(f"âŒ è¿”å›çš„Kæ•°æ®ç¼ºå°‘'time'åˆ—ï¼Œå®é™…åˆ—ï¼š{df.columns.tolist()}")
                return pd.DataFrame()
            if not all(col in df.columns for col in required_cols):
                print(f"âŒ Kæ•°æ®åˆ—ç¼ºå¤±ï¼Œå¿…è¦åˆ—ï¼š{required_cols}ï¼Œå®é™…åˆ—ï¼š{df.columns.tolist()}")
                return pd.DataFrame()
            df = df[['time', 'open', 'high', 'low', 'close', 'volume']].copy()

            # Ensure time is parsed and timezone-aware, then convert to Asia/Shanghai
            try:
                def _parse_time_series(ts):
                    """Robustly parse numeric or string time series into datetimes.

                    Heuristic units detection for numeric epochs: prefers ns/us/ms/s by
                    checking magnitude and will attempt alternative units if parsed
                    dates appear unreasonable (e.g., year < 2000 -> 1970-era times).
                    """
                    try:
                        s = ts.dropna()
                    except Exception:
                        s = ts

                    if pd.api.types.is_integer_dtype(ts) or pd.api.types.is_float_dtype(ts):
                        mx = float(s.max()) if len(s) > 0 else 0.0
                        if mx > 1e14:
                            unit = 'ns'
                        elif mx > 1e11:
                            unit = 'us'
                        elif mx > 1e10:
                            unit = 'ms'
                        elif mx > 1e9:
                            unit = 's'
                        else:
                            unit = 's'

                        try:
                            dt = pd.to_datetime(ts, unit=unit)
                        except Exception:
                            dt = pd.to_datetime(ts, errors='coerce')

                        if dt.dt.year.max() < 2000:
                            for alt in ('s', 'ms', 'us', 'ns'):
                                if alt == unit:
                                    continue
                                try:
                                    alt_dt = pd.to_datetime(ts, unit=alt)
                                    if alt_dt.dt.year.max() >= 2000:
                                        logger.warning("Parsed times appeared to be around 1970 using unit=%s; switched to unit=%s", unit, alt)
                                        dt = alt_dt
                                        break
                                except Exception:
                                    continue
                        return dt
                    else:
                        return pd.to_datetime(ts, errors='coerce')

                df['time'] = _parse_time_series(df['time'])
                # if tz-naive, assume UTC
                if df['time'].dt.tz is None:
                    df['time'] = df['time'].dt.tz_localize('UTC')
                df['time'] = df['time'].dt.tz_convert('Asia/Shanghai')
            except Exception as e:
                logger.exception("æ—¶é—´è§£æå¤±è´¥")
                print(f"âŒ æ—¶é—´è§£æå¤±è´¥ï¼š{e}")
                return pd.DataFrame()
        else:
            # iterable of bar-like objects (with attributes .time, .open, etc.)
            # Ensure we can measure length; if not, convert to list
            try:
                klines_len = len(klines)
            except TypeError:
                klines = list(klines)
                klines_len = len(klines)

            # print bars for debugging (now that klines is sized or converted to list)
            for bar in klines:
                print(bar)

            if (hasattr(klines, 'empty') and getattr(klines, 'empty')) or klines_len < MIN_KLINES:
                print(f"âŒ Kæ•°æ®ä¸è¶³ï¼ˆä»…è·å–{klines_len}æ¡ï¼‰")
                return pd.DataFrame()
            else:
                print("kæ•°æ®è·å–\r\n")

            df = pd.DataFrame([{
                'time': getattr(bar, 'time', None),
                'open': getattr(bar, 'open', None),
                'high': getattr(bar, 'high', None),
                'low': getattr(bar, 'low', None),
                'close': getattr(bar, 'close', None),
                'volume': getattr(bar, 'volume', None)
            } for bar in klines])

            if df.empty or len(df) < MIN_KLINES:
                print(f"âŒ Kæ•°æ®ä¸è¶³ï¼ˆä»…è·å–{len(df)}æ¡ï¼‰")
                return pd.DataFrame()

            if not all(col in df.columns for col in required_cols):
                print(f"âŒ Kæ•°æ®åˆ—ç¼ºå¤±ï¼Œå¿…è¦åˆ—ï¼š{required_cols}ï¼Œå®é™…åˆ—ï¼š{df.columns.tolist()}")
                return pd.DataFrame()

            # Ensure time is parsed and timezone-aware, then convert to Asia/Shanghai
            try:
                def _parse_time_series(ts):
                    try:
                        s = ts.dropna()
                    except Exception:
                        s = ts

                    if pd.api.types.is_integer_dtype(ts) or pd.api.types.is_float_dtype(ts):
                        mx = float(s.max()) if len(s) > 0 else 0.0
                        if mx > 1e14:
                            unit = 'ns'
                        elif mx > 1e11:
                            unit = 'us'
                        elif mx > 1e10:
                            unit = 'ms'
                        elif mx > 1e9:
                            unit = 's'
                        else:
                            unit = 's'

                        try:
                            dt = pd.to_datetime(ts, unit=unit)
                        except Exception:
                            dt = pd.to_datetime(ts, errors='coerce')

                        if dt.dt.year.max() < 2000:
                            for alt in ('s', 'ms', 'us', 'ns'):
                                if alt == unit:
                                    continue
                                try:
                                    alt_dt = pd.to_datetime(ts, unit=alt)
                                    if alt_dt.dt.year.max() >= 2000:
                                        logger.warning("Parsed times appeared to be around 1970 using unit=%s; switched to unit=%s", unit, alt)
                                        dt = alt_dt
                                        break
                                except Exception:
                                    continue
                        return dt
                    else:
                        return pd.to_datetime(ts, errors='coerce')

                df['time'] = _parse_time_series(df['time'])
                # if tz-naive, assume UTC
                if df['time'].dt.tz is None:
                    df['time'] = df['time'].dt.tz_localize('UTC')
                df['time'] = df['time'].dt.tz_convert('Asia/Shanghai')
            except Exception as e:
                logger.exception("æ—¶é—´è§£æå¤±è´¥")
                print(f"âŒ æ—¶é—´è§£æå¤±è´¥ï¼š{e}")
                return pd.DataFrame()

        df.set_index('time', inplace=True)
        # sort and keep the most recent `count` rows
        df.sort_index(inplace=True)
        if len(df) > count:
            df = df.tail(count)

        print(df)
        logger.info("get_kline_data returning %s rows for %s", len(df), symbol)
        return df

    except Exception as e:
        logger.exception("get_kline_data failed")
        print(f"âŒ è·å–Kå¤±è´¥11ï¼š{str(e)}")
        return pd.DataFrame()

def calculate_indicators(df_1m, df_5m):
    """è®¡ç®—æŠ€æœ¯æŒ‡æ ‡ï¼ˆé€»è¾‘ä¸å˜ï¼‰"""
    global atr_5m, last_boll_width, is_boll_divergence
    indicators = {}
    
    if not df_5m.empty and len(df_5m) >= GRID_BOLL_PERIOD:
        # Work on a copy to avoid mutating caller's DataFrame
        df5 = df_5m.copy()
        ma = talib.MA(df5['close'], timeperiod=GRID_BOLL_PERIOD)
        df5['boll_mid'] = ma.values if hasattr(ma, 'values') else ma

        upper, mid, lower = talib.BBANDS(
            df5['close'],
            timeperiod=GRID_BOLL_PERIOD,
            nbdevup=GRID_BOLL_STD,
            nbdevdn=GRID_BOLL_STD,
            matype=0
        )
        df5['boll_upper'] = upper.values if hasattr(upper, 'values') else upper
        df5['boll_lower'] = lower.values if hasattr(lower, 'values') else lower
        
        atrv = talib.ATR(
            df5['high'],
            df5['low'],
            df5['close'],
            timeperiod=GRID_ATR_PERIOD
        )
        df5['atr'] = atrv.values if hasattr(atrv, 'values') else atrv
        
        rsiv = talib.RSI(df5['close'], timeperiod=GRID_RSI_PERIOD_5M)
        df5['rsi'] = rsiv.values if hasattr(rsiv, 'values') else rsiv

        # Helper: last valid (non-NaN) value or default
        def _last_valid(series, default=None):
            s = series.dropna()
            return s.iloc[-1] if len(s) > 0 else default

        # Update atr_5m only if the latest (last-row) ATR value is valid (non-NaN).
        # This preserves previous atr_5m when the newest bar has missing ATR.
        try:
            atr_latest = df5['atr'].iloc[-1]
        except Exception:
            atr_latest = None
        if pd.notna(atr_latest):
            atr_5m = atr_latest
        else:
            # keep previous atr_5m unchanged
            pass

        # Compute current Boll width using last valid upper/lower
        last_upper = _last_valid(df5['boll_upper'], None)
        last_lower = _last_valid(df5['boll_lower'], None)
        if last_upper is not None and last_lower is not None:
            current_boll_width = last_upper - last_lower
        else:
            current_boll_width = last_boll_width

        if last_boll_width > 0 and current_boll_width is not None:
            width_increase = (current_boll_width - last_boll_width) / last_boll_width
            # atr increase computed from last two non-NaN ATR values
            atr_nonnull = df5['atr'].dropna()
            if len(atr_nonnull) >= 1:
                atr_current = atr_nonnull.iloc[-1]
                atr_prev = atr_nonnull.iloc[-2] if len(atr_nonnull) >= 2 else atr_current
                atr_increase = (atr_current - atr_prev) / atr_prev if atr_prev > 0 else 0
            else:
                atr_current = atr_5m
                atr_prev = atr_5m
                atr_increase = 0

            is_boll_divergence = (width_increase >= BOLL_DIVERGENCE_THRESHOLD) and (atr_increase >= ATR_AMPLIFICATION_THRESHOLD)

        last_boll_width = current_boll_width

        # Use last valid (non-NaN) values for indicators to avoid NaN propagation
        indicators['5m'] = {
            'boll_mid': _last_valid(df5['boll_mid'], None),
            'boll_upper': _last_valid(df5['boll_upper'], None),
            'boll_lower': _last_valid(df5['boll_lower'], None),
            'rsi': _last_valid(df5['rsi'], None),
            'atr': atr_5m
        }
    
    if not df_1m.empty and len(df_1m) >= GRID_RSI_PERIOD_1M:
        df_1m['rsi'] = talib.RSI(df_1m['close'], timeperiod=GRID_RSI_PERIOD_1M)
        indicators['1m'] = {
            'rsi': df_1m['rsi'].iloc[-1],
            'close': df_1m['close'].iloc[-1],
            'volume': df_1m['volume'].iloc[-1]
        }
    
    return indicators

def judge_market_trend(indicators):
    """åˆ¤æ–­è¡Œæƒ…ç±»å‹ï¼ˆé€»è¾‘ä¸å˜ï¼‰"""
    if '5m' not in indicators or '1m' not in indicators:
        return 'unknown'
    
    boll_mid = indicators['5m']['boll_mid']
    boll_upper = indicators['5m']['boll_upper']
    boll_lower = indicators['5m']['boll_lower']
    rsi_5m = indicators['5m']['rsi']
    price_current = indicators['1m']['close']
    
    if is_boll_divergence:
        return 'boll_divergence_up' if price_current > boll_mid else 'boll_divergence_down'
    if price_current > boll_upper and rsi_5m > 70:
        return 'bull_trend'
    elif price_current < boll_lower and rsi_5m < 30:
        return 'bear_trend'
    elif boll_mid < price_current < boll_upper and 50 < rsi_5m < 70:
        return 'osc_bull'
    elif boll_lower < price_current < boll_mid and 30 < rsi_5m < 50:
        return 'osc_bear'
    else:
        return 'osc_normal'

def adjust_grid_interval(trend, indicators):
    """åŠ¨æ€è°ƒæ•´ç½‘æ ¼åŒºé—´ï¼ˆé€»è¾‘ä¸å˜ï¼‰"""
    global grid_upper, grid_lower
    boll_mid = indicators['5m']['boll_mid']
    boll_upper = indicators['5m']['boll_upper']
    boll_lower = indicators['5m']['boll_lower']
    atr = indicators['5m']['atr']
    
    if trend == 'boll_divergence_up':
        grid_lower = boll_mid + 0.3 * atr
        grid_upper = boll_upper - 0.5 * atr
    elif trend == 'boll_divergence_down':
        grid_lower = boll_lower + 0.5 * atr
        grid_upper = boll_mid - 0.3 * atr
    elif trend == 'bull_trend':
        grid_lower = boll_mid
        grid_upper = boll_upper
    elif trend == 'bear_trend':
        grid_lower = boll_lower
        grid_upper = boll_mid
    elif trend == 'osc_bull':
        grid_lower = boll_mid - 0.2 * atr
        grid_upper = boll_upper - 0.2 * atr
    elif trend == 'osc_bear':
        grid_lower = boll_lower + 0.2 * atr
        grid_upper = boll_mid + 0.2 * atr
    else:
        grid_lower = boll_lower
        grid_upper = boll_upper
    
    # Try to include current price (from 1m indicators) in the status printout if available
    price_current = None
    try:
        price_current = indicators.get('1m', {}).get('close')
    except Exception:
        price_current = None

    if price_current is None or (isinstance(price_current, float) and np.isnan(price_current)):
        price_str = 'N/A'
    else:
        price_str = f"{price_current:.2f}"

    print(f"ğŸ“Œ è¡Œæƒ…ç±»å‹ï¼š{trend} | ç½‘æ ¼åŒºé—´ï¼š{grid_lower:.2f} - {grid_upper:.2f} | ATRï¼š{atr:.2f} | å½“å‰ä»·ï¼š{price_str}")

def check_risk_control(price, side):
    """é£æ§æ£€æŸ¥ï¼ˆé€‚é…åŠ¨æ€ä¹˜æ•°ï¼‰"""
    global daily_loss, current_position, today
    
    # æ¯æ—¥é‡ç½®äºæŸ
    if datetime.now().date() != today:
        daily_loss = 0
        today = datetime.now().date()
    
    # 1. ä»“ä½ä¸Šé™æ£€æŸ¥
    if side == 'BUY' and current_position >= GRID_MAX_POSITION:
        print(f"âš ï¸ ä»“ä½å·²è¾¾ä¸Šé™ï¼ˆ{GRID_MAX_POSITION}æ‰‹ï¼‰ï¼Œç¦æ­¢åŠ ä»“")
        return False
    
    # 2. æ—¥äºæŸä¸Šé™æ£€æŸ¥
    if daily_loss >= DAILY_LOSS_LIMIT:
        print(f"âš ï¸ å½“æ—¥äºæŸè¾¾ä¸Šé™ï¼ˆ{DAILY_LOSS_LIMIT}ç¾å…ƒï¼‰ï¼Œç¦æ­¢å¼€ä»“")
        return False
    
    # 3. å•ç¬”äºæŸæ£€æŸ¥ï¼ˆä½¿ç”¨åŠ¨æ€ä¹˜æ•°ï¼‰
    stop_loss_price = price - STOP_LOSS_MULTIPLIER * atr_5m
    single_loss = (price - stop_loss_price) * FUTURE_MULTIPLIER
    if single_loss > SINGLE_TRADE_LOSS:
        print(f"âš ï¸ å•ç¬”LOSSè¶…é™ï¼ˆ{single_loss:.2f}ï¼{SINGLE_TRADE_LOSS}ï¼‰ï¼Œç¦æ­¢å¼€ä»“")
        return False
    
    return True

def place_tiger_order(side, quantity, price, stop_loss_price=None):
    """Place a futures order through `trade_client` (per API docs).

    This implementation tries to build a proper `contract` and `order` using
    tigeropen helper functions (constructed at runtime to keep import-time
    safety for tests). If the SDK helpers are unavailable or fail, it falls
    back to a simple namespace object and â€” in sandbox â€” simulates success.

    Production orders are refused unless ALLOW_REAL_TRADING=1 is set.
    """
    global current_position, daily_loss

    # Resolve account id
    account_id = getattr(client_config, 'account', None) or getattr(client_config, 'account_id', None)

    # refuse live orders unless explicitly allowed
    if RUN_ENV == 'production' and os.getenv('ALLOW_REAL_TRADING', '0') != '1':
        msg = "âš ï¸ å®ç›˜ä¸‹å•å—é™ï¼šç¯å¢ƒä¸º productionï¼Œæœªå¯ç”¨ ALLOW_REAL_TRADING=1ï¼Œè·³è¿‡ä¸‹å•"
        logger.warning(msg)
        print(msg)
        return False

    order_obj = None
    try:
        # Try to construct a proper Contract + Order via tigeropen helpers
        try:
            from tigeropen.common.util.contract_utils import future_contract
            from tigeropen.common.util.order_utils import limit_order, limit_order_with_legs, order_leg

            # Best-effort contract construction: prefer compact symbol like 'SIL2603'
            try:
                contract_symbol = _to_api_identifier(FUTURE_SYMBOL)
                contract = future_contract(symbol=contract_symbol, currency=FUTURE_CURRENCY)
            except Exception:
                # Fallback to base symbol
                base = FUTURE_SYMBOL.split('.')[0]
                contract = future_contract(symbol=base, currency=FUTURE_CURRENCY)

            # Build a limit order (LMT)
            order_obj = limit_order(account=account_id, contract=contract, action=side, limit_price=price, quantity=quantity)

            # If caller provided a stop loss, attach it as an order leg when helpers allow it
            if stop_loss_price:
                try:
                    stop_leg = order_leg('LOSS', float(stop_loss_price), time_in_force='DAY', outside_rth=False)
                    order_obj = limit_order_with_legs(account_id, contract, side, quantity, limit_price=price, order_legs=[stop_leg])
                except Exception:
                    # If adding legs fails, try to set aux_price/stop_price on the order
                    try:
                        setattr(order_obj, 'aux_price', float(stop_loss_price))
                    except Exception:
                        pass
        except Exception:
            # If tigeropen helpers are unavailable, fall back to a lightweight order-like object
            from types import SimpleNamespace
            order_obj = SimpleNamespace()
            order_obj.account = account_id
            order_obj.action = side
            order_obj.quantity = quantity
            order_obj.limit_price = price
            if stop_loss_price:
                order_obj.aux_price = stop_loss_price

        # Ensure trade_client exists and attempt to place the order
        if trade_client is None:
            raise RuntimeError('trade_client not configured')

        try:
            # The SDK may return an id or populate order_obj.id; capture both
            returned = trade_client.place_order(order_obj)
            order_id = getattr(order_obj, 'id', None) or returned or getattr(returned, 'id', None) or getattr(returned, 'order_id', None)

            env_tip = "[æ¨¡æ‹Ÿå•]" if RUN_ENV == 'sandbox' else "[å®ç›˜å•]"
            msg = f"âœ… {env_tip} ä¸‹å•æˆåŠŸ | {side} {quantity}æ‰‹ | ä»·æ ¼ï¼š{price:.2f} | è®¢å•IDï¼š{order_id if order_id else 'æœªçŸ¥'}"
            logger.info(msg)
            print(msg)

            # Update simple in-memory state consistent with previous behavior
            if side == 'BUY':
                current_position += quantity
            else:
                current_position -= quantity
                if stop_loss_price:
                    daily_loss += (price - stop_loss_price) * FUTURE_MULTIPLIER * quantity

            return True

        except Exception as e:
            # On failure, simulate success when in sandbox (keeps previous behaviour)
            print(f"âš ï¸ ä¸‹å•è°ƒç”¨å¤±è´¥ï¼š{e} â€” å°†åœ¨ sandbox ä¸­æ¨¡æ‹ŸæˆåŠŸå“åº”ï¼ˆå¦‚é€‚ç”¨ï¼‰")
            if RUN_ENV == 'sandbox':
                env_tip = "[æ¨¡æ‹Ÿå•]"
                msg = f"âœ… {env_tip} ä¸‹å•æˆåŠŸï¼ˆæ¨¡æ‹Ÿï¼‰ | {side} {quantity}æ‰‹ | ä»·æ ¼ï¼š{price:.2f} | è®¢å•IDï¼šSIMULATED"
                logger.info(msg)
                print(msg)
                if side == 'BUY':
                    current_position += quantity
                else:
                    current_position -= quantity
                    if stop_loss_price:
                        daily_loss += (price - stop_loss_price) * FUTURE_MULTIPLIER * quantity
                return True
            else:
                print(f"âŒ ä¸‹å•å¼‚å¸¸ï¼š{e}")
                return False

    except Exception as e:
        print(f"âŒ ä¸‹å•å¼‚å¸¸ï¼š{str(e)}")
        logger.exception('place_tiger_order failure')
        return False

def grid_trading_strategy():
    """æ ¸å¿ƒç½‘æ ¼ç­–ç•¥é€»è¾‘ï¼ˆé€»è¾‘ä¸å˜ï¼‰"""
    df_1m = get_kline_data([FUTURE_SYMBOL], '1min', count=30)
    df_5m = get_kline_data([FUTURE_SYMBOL], '5min', count=50)
    if df_1m.empty or df_5m.empty:
        print("âš ï¸ æ•°æ®ä¸è¶³ï¼Œè·³è¿‡æœ¬STEP 22")
        return
    
    indicators = calculate_indicators(df_1m, df_5m)
    if not indicators or '5m' not in indicators or '1m' not in indicators:
        print("âš ï¸ æŒ‡æ ‡è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡æœ¬æ¬¡å¾ªç¯33")
        return
    
    trend = judge_market_trend(indicators)
    adjust_grid_interval(trend, indicators)
    
    price_current = indicators['1m']['close']
    rsi_1m = indicators['1m']['rsi']
    rsi_5m = indicators['5m']['rsi']
    atr = indicators['5m']['atr']
    
    rsi_low_map = {
        'boll_divergence_down': 15,
        'osc_bear': 22,
        'osc_bull': 55,
        'bull_trend': 50,
        'osc_normal': 25
    }
    rsi_reverse_map = {
        'boll_divergence_down': 30,
        'osc_bear': 30,
        'osc_bull': 60,
        'bull_trend': 55,
        'osc_normal': 30
    }
    rsi_low = rsi_low_map.get(trend, 25)
    rsi_reverse = rsi_reverse_map.get(trend, 30)
    
    if price_current <= grid_lower and rsi_1m <= rsi_low and check_risk_control(price_current, 'BUY'):
        trend_check = (trend in ['osc_bull', 'bull_trend'] and rsi_5m > 50) or \
                      (trend in ['osc_bear', 'boll_divergence_down'] and rsi_5m < 50)
        # If trend check passes, place buy (removed impossible dual-RSI check present previously)
        if trend_check:
            stop_loss_price = price_current - STOP_LOSS_MULTIPLIER * atr
            place_tiger_order('BUY', 1, price_current, stop_loss_price)
    
    rsi_high_map = {
        'boll_divergence_up': 80,
        'osc_bull': 75,
        'bull_trend': 70,
        'osc_normal': 70
    }
    rsi_high = rsi_high_map.get(trend, 70)
    if price_current >= grid_upper and rsi_1m >= rsi_high and current_position > 0:
        place_tiger_order('SELL', 1, price_current)
    
    if current_position > 0:
        stop_loss_price = price_current - STOP_LOSS_MULTIPLIER * atr
        if price_current <= stop_loss_price:
            env_tip = "[æ¨¡æ‹Ÿæ­¢æŸ]" if RUN_ENV == 'sandbox' else "[å®ç›˜æ­¢æŸ]"
            print(f"âš ï¸ {env_tip} è§¦å‘æ­¢æŸï¼Œå¹³ä»“{current_position}æ‰‹")
            place_tiger_order('SELL', current_position, price_current)


def boll1m_grid_strategy():
    """1-minute Bollinger-based grid strategy (ç‹¬ç«‹å‡½æ•°) â€” ä¼˜åŒ–è¿‡çš„å¼€ä»“é€»è¾‘ã€‚

    åœºæ™¯åŒºåˆ†ï¼š
      - éœ‡è¡ä¸Šè¡Œï¼ˆosc_bull / osc_normalï¼‰: åœ¨ä»·æ ¼ä¸‹æ¢åˆ°ä¸‹è½¨å¹¶å‡ºç°åå¼¹ï¼ˆlast > prevï¼‰æ—¶å¼€ä»“
      - éœ‡è¡ä¸‹è¡Œï¼ˆosc_bearï¼‰æˆ–å•è¾¹ä¸‹è·Œï¼ˆbear_trend / boll_divergence_downï¼‰: åªåœ¨ä»·æ ¼ä»ä¸‹è½¨å›å‡å¹¶çªç ´ä¸‹è½¨æ—¶æ›´ä¸ºä¿å®ˆåœ°å¼€ä»“
      - å•è¾¹ä¸Šæ¶¨ï¼ˆbull_trend / boll_divergence_upï¼‰: å¯åœ¨ä¸‹æ¢å¹¶å‡ºç°åå¼¹æ—¶è¾ƒç§¯æå¼€ä»“

    å…·ä½“è§„åˆ™ï¼ˆç®€åŒ–ç‰ˆå®ç°ï¼‰:
      1. åœ¨æœ€è¿‘ 3 æ ¹ 1m K çº¿å†…å‡ºç°ä»·æ ¼ <= ä¸‹è½¨ï¼ˆdip_detectedï¼‰;
      2. æ ¹æ®è¶‹åŠ¿ç±»å‹è¦æ±‚ä¸åŒçš„åå¼¹ç¡®è®¤ï¼ˆå¦‚ last > prev æˆ– last >= boll_lowerï¼‰ï¼›
      3. é€šè¿‡é£æ§åä¸‹å•ï¼Œæ­¢æŸæŒ‰ ATR è®¡ç®—ã€‚

    å–å‡ºï¼šå½“æŒä»“ä¸”å½“å‰ä»·æ ¼ >= ä¸­è½¨æ—¶å–å‡º 1 æ‰‹ã€‚
    """
    global current_position

    # Fetch enough 1m bars for BOLL calculation
    df_1m = get_kline_data([FUTURE_SYMBOL], '1min', count=max(30, GRID_BOLL_PERIOD + 5))
    if df_1m.empty or len(df_1m) < GRID_BOLL_PERIOD:
        print("âš ï¸ boll1m_grid_strategy: æ•°æ®ä¸è¶³ï¼Œè·³è¿‡")
        return

    indicators = calculate_indicators(df_1m, df_1m)
    if '5m' not in indicators or '1m' not in indicators:
        print("âš ï¸ boll1m_grid_strategy: æŒ‡æ ‡è®¡ç®—å¤±è´¥ï¼Œè·³è¿‡")
        return

    boll_lower = indicators['5m']['boll_lower']
    boll_mid = indicators['5m']['boll_mid']
    price_current = indicators['1m']['close']
    atr = indicators['5m']['atr']

    # Determine market regime
    trend = judge_market_trend(indicators)

    # Gather recent closes for dip/rebound detection
    closes = None
    try:
        closes = df_1m['close'].dropna()
    except Exception:
        closes = pd.Series(dtype='float')

    if len(closes) < 2:
        print("âš ï¸ boll1m_grid_strategy: Kçº¿ä¸è¶³ä»¥åˆ¤æ–­åå¼¹ï¼Œè·³è¿‡")
        return

    last = float(closes.iloc[-1])
    prev = float(closes.iloc[-2]) if len(closes) >= 2 else None
    prev3_min = float(closes.tail(3).min()) if len(closes) >= 1 else None

    dip_detected = (boll_lower is not None and prev3_min is not None and prev3_min <= boll_lower)

    # Buy decision: require dip then rebound; stricter in downtrends
    buy_ok = False
    if dip_detected and price_current is not None and boll_lower is not None:
        if trend in ('osc_bull', 'osc_normal', 'bull_trend', 'boll_divergence_up'):
            # moderate: any rebound (last > prev) is acceptable
            if prev is not None and last > prev:
                buy_ok = True
        elif trend in ('osc_bear', 'bear_trend', 'boll_divergence_down'):
            # conservative: require rebound that reaches at least back to lower band
            if prev is not None and prev <= boll_lower and last >= boll_lower:
                buy_ok = True
        else:
            # default to moderate behaviour
            if prev is not None and last > prev:
                buy_ok = True

    if buy_ok:
        if check_risk_control(price_current, 'BUY'):
            stop_loss_price = price_current - STOP_LOSS_MULTIPLIER * (atr if atr else 0)
            print(f"ğŸ”§ boll1m_grid_strategy ({trend}): å‘ç°å›è°ƒ+åå¼¹ï¼Œå‡†å¤‡ä¹°å…¥ at {price_current:.2f} (boll_lower={boll_lower:.2f})")
            place_tiger_order('BUY', 1, price_current, stop_loss_price)
        else:
            print("ğŸ”§ boll1m_grid_strategy: é£æ§é˜»æ­¢ä¹°å…¥")
    else:
        print(f"ğŸ”§ boll1m_grid_strategy ({trend}): æœªæ»¡è¶³å›è°ƒç¡®è®¤æˆ–æœªæ£€æµ‹åˆ°dipï¼ˆdip_detected={dip_detected}, last={last}, prev={prev}ï¼‰")

    # Sell at mid band when holding (unchanged)
    if current_position > 0 and price_current is not None and boll_mid is not None and price_current >= boll_mid:
        print(f"ğŸ”§ boll1m_grid_strategy: è§¦å‘å–å‡º at {price_current:.2f} (boll_mid={boll_mid:.2f})")
        place_tiger_order('SELL', 1, price_current)


# ====================== ä¸»ç¨‹åº ======================
if __name__ == "__main__":
    # 1. éªŒè¯APIè¿æ¥
    if not verify_api_connection():
        exit(1)
    
    # 2. å¯åŠ¨ç½‘æ ¼ç­–ç•¥
    try:
        print("ğŸš€ å¯åŠ¨ç½‘æ ¼å¤„ç†ï¼‰...")
        while True:
            #grid_trading_strategy()
            boll1m_grid_strategy()
            time.sleep(20)  # 
    except KeyboardInterrupt:
        print("ğŸ›‘ ç”¨æˆ·ç»ˆæ­¢ç¨‹åº")
    except Exception as e:
        print(f"âŒ ç¨‹åºå¼‚å¸¸ï¼š{e}")
    finally:
        # å¹³ä»“æ‰€æœ‰æŒä»“ï¼ˆå¯é€‰ï¼Œå®ç›˜è°¨æ…æ“ä½œï¼‰
        '''
        if current_position > 0:
            print(f"âš ï¸ ç¨‹åºé€€å‡ºï¼Œå¹³ä»“{current_position}æ‰‹æŒä»“")
            latest_price = get_kline_data(FUTURE_SYMBOL, '1min', count=1)['close'].iloc[-1]
            place_tiger_order('SELL', current_position, latest_price)
        '''    
        print("âœ… ç¨‹åºç»“æŸ")