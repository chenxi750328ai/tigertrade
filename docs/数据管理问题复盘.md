# 数据管理问题复盘

**日期**: 2026-01-21  
**问题**: 找不到之前采集的6970条历史数据

---

## 🔍 问题根因分析

### 表面现象
回测脚本期望数据在：`/home/cx/tigertrade/data/large_dataset_real.csv`  
实际数据位置在：`/home/cx/trading_data/large_dataset/full_20260121_100827.csv`

### 深层原因

#### 1. **路径不统一** ❌
```
数据采集脚本:     /home/cx/trading_data/
训练脚本:         /home/cx/trading_data/
回测脚本:         /home/cx/tigertrade/data/  ← 不一致！
```

**为什么会这样？**
- 不同时间写的脚本，没有统一配置
- 每个脚本都硬编码了路径
- 缺少中央配置文件

#### 2. **没有文档记录数据位置** ❌
```
采集完成后没有记录：
  ✗ 数据保存在哪里？
  ✗ 数据文件名是什么？
  ✗ 有多少条记录？
  ✗ 什么时候采集的？
```

#### 3. **多个数据目录并存** ❌
```bash
/home/cx/tigertrade/data/           # 空的
/home/cx/trading_data/              # 实际数据在这里
/home/cx/tigertrade/archive/        # 也有一些数据
```

混乱的目录结构导致找不到文件。

#### 4. **没有使用版本管理** ❌
```
full_20260120_144703.csv
full_20260120_151714.csv
full_20260120_152358.csv
full_20260121_094500.csv
full_20260121_100827.csv  ← 哪个是最新的？
```

多个版本，没有明确标记哪个是"最新"或"生产"版本。

---

## ✅ 解决方案

### 立即措施（已完成）
1. ✅ 创建符号链接统一路径
2. ✅ 定位并确认数据文件（6970条）

### 长期方案

#### 1. **统一配置管理**
创建 `config/paths.py`:
```python
# 数据路径配置 - 所有脚本都使用这个
DATA_ROOT = "/home/cx/trading_data"
DATASET_DIR = f"{DATA_ROOT}/large_dataset"
MODELS_DIR = "/home/cx/tigertrade/models"
LOGS_DIR = "/home/cx/tigertrade/logs"

# 当前生产数据（符号链接）
PRODUCTION_DATA = f"{DATA_ROOT}/production/current.csv"
```

所有脚本都 `from config.paths import PRODUCTION_DATA`

#### 2. **数据清单文件**
每次采集后自动生成 `data_manifest.json`:
```json
{
  "latest": {
    "path": "/home/cx/trading_data/large_dataset/full_20260121_100827.csv",
    "records": 6970,
    "created_at": "2026-01-21 10:08:27",
    "symbol": "SIL2603",
    "hash": "sha256:abc123..."
  },
  "history": [...]
}
```

#### 3. **目录结构标准化**
```
/home/cx/trading_data/
├── production/
│   ├── current.csv           # 符号链接 → latest
│   └── manifest.json         # 数据清单
├── archive/
│   ├── 2026-01-20/
│   └── 2026-01-21/
└── backups/
```

#### 4. **自动化检查脚本**
```bash
# check_data.sh
#!/bin/bash
if [ ! -f "$PRODUCTION_DATA" ]; then
    echo "❌ 生产数据不存在！"
    echo "请运行: python scripts/setup_data_links.py"
    exit 1
fi
echo "✅ 数据文件: $(ls -lh $PRODUCTION_DATA)"
```

每个脚本开始前先检查。

#### 5. **README.md 文档**
在项目根目录创建清晰的说明：
```markdown
## 数据位置

**生产数据**: `/home/cx/trading_data/production/current.csv`
**数据采集**: `python scripts/collect_data.py`
**数据更新**: 自动更新符号链接

如果找不到数据，运行: `python scripts/find_data.py`
```

---

## 📋 预防措施清单

### 开发新脚本时
- [ ] 使用统一的配置文件（不要硬编码路径）
- [ ] 检查数据是否存在（失败时给出明确提示）
- [ ] 记录数据来源和位置到日志

### 数据采集时
- [ ] 更新 `data_manifest.json`
- [ ] 创建/更新符号链接到 `production/current.csv`
- [ ] 记录到 RAG 系统
- [ ] 输出清晰的"数据已保存到XXX"消息

### 项目管理时
- [ ] 定期清理旧版本数据
- [ ] 备份重要数据
- [ ] 更新文档
- [ ] RAG记录关键决策

---

## 💡 经验教训

### 1. **明确的约定 > 灵活性**
与其让每个脚本自己决定数据放哪里，不如统一规定：
> "所有生产数据必须通过 `config.paths.PRODUCTION_DATA` 访问"

### 2. **符号链接是好朋友**
```bash
ln -sf /actual/path/data.csv /standard/location/current.csv
```
既保留了历史版本，又有统一入口。

### 3. **失败时要响亮**
不要静默失败！找不到数据时：
```python
if not os.path.exists(data_path):
    print(f"❌ 数据文件不存在: {data_path}")
    print(f"💡 可能的位置:")
    for path in possible_locations:
        if os.path.exists(path):
            print(f"   ✓ {path}")
    sys.exit(1)
```

### 4. **自动化 > 人工记忆**
不要依赖"记住"数据在哪里，而是：
- 脚本自动寻找
- 清单文件记录
- RAG系统备份

### 5. **文档是代码的一部分**
README、配置说明、数据清单 = 和代码一样重要！

---

## 🎯 立即行动

1. ✅ 创建 `/home/cx/trading_data/production/` 目录
2. ✅ 符号链接最新数据到 `production/current.csv`
3. ✅ 生成 `data_manifest.json`
4. ✅ 更新所有脚本使用统一路径
5. ✅ 记录到 RAG 系统

---

**总结**: 数据"丢失"不是真的丢了，而是**没有建立统一的数据管理体系**。解决方案是：统一配置、清晰文档、自动化检查、RAG记录。
