# 改进实施顺序（1、2、3）

**实施时间**: 2026-01-27 13:50  
**顺序**: 按照优先级1、2、3依次实施

---

## 一、步骤1：数据层面改进

### 1.1 获取更多数据
- **目标**: 50K+样本
- **方法**: 通过API获取90天历史数据
- **状态**: 进行中

### 1.2 合并数据
- **方法**: 合并所有历史数据文件
- **去重**: 基于timestamp去重
- **状态**: 进行中

### 1.3 分析数据分布
- **方法**: 分析训练集和验证集的分布差异
- **目的**: 判断是过拟合还是分布偏移
- **状态**: 进行中

---

## 二、步骤2：训练策略改进

### 2.1 增强正则化
- ✅ **权重衰减**: 1e-3 → 5e-3
- ✅ **Dropout**: 已增加
- ✅ **早停**: patience=10

### 2.2 改进学习率调度
- ✅ **Warmup**: 前5个epoch
- ✅ **CosineAnnealingLR**: 平滑衰减

### 2.3 组合损失函数
- ✅ **Label Smoothing**: 0.2（70%）
- ✅ **Focal Loss**: gamma=2.0（30%）

### 2.4 高级数据增强
- ✅ **时间序列特定增强**: 时间扭曲、窗口切片、噪声、价格缩放
- ✅ **Mixup**: alpha=0.2

---

## 三、步骤3：模型架构改进

### 3.1 PEFT（参数高效微调）
- ✅ **策略**: 冻结Transformer层，只训练分类头和收益率头
- ✅ **可训练参数**: ~561K（2.09%）
- ✅ **数据/参数比例**: 1:13（合理）

### 3.2 MoE（混合专家模型）
- ✅ **专家数量**: 4个
- ✅ **稀疏激活率**: 50%（每次激活2个）
- ✅ **参数量**: ~5M（从19.5M减少）

### 3.3 稀疏注意力
- ✅ **局部窗口**: 20
- ✅ **注意力头dropout**: 10%

---

## 四、实施状态

**当前状态**: 按照1、2、3的顺序实施中

**步骤1（数据层面）**: 进行中
- 获取更多数据
- 合并数据
- 分析分布

**步骤2（训练策略）**: ✅ 已完成
- 增强正则化
- 改进学习率调度
- 组合损失函数
- 高级数据增强

**步骤3（模型架构）**: ✅ 已完成
- PEFT
- MoE
- 稀疏注意力

---

**下一步**: 等待步骤1完成，然后开始训练
