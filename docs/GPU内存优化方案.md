# GPU内存优化方案

**问题**: CUDA out of memory - 序列长度1000步导致GPU内存不足  
**解决时间**: 2026-01-27 13:00

---

## 一、问题分析

### 1.1 错误信息

```
torch.OutOfMemoryError: CUDA out of memory. Tried to allocate 978.00 MiB. 
GPU 0 has a total capacity of 23.99 GiB of which 0 bytes is free.
```

### 1.2 根本原因

**序列长度1000步导致内存占用过大**：
- 序列长度: 1000步
- 批次大小: 32
- MoE模型参数量: ~19.5M
- 总内存需求: >24GB（超过GPU容量）

---

## 二、优化方案

### 2.1 减少序列长度

**调整策略**：
- 中等数据集（<10K）: 最多300步（从500步减少）
- 大数据集（>10K）: 最多500步（从1000步减少）
- 仍然覆盖足够的历史信息（300步≈5小时，500步≈8.3小时）

### 2.2 动态批次大小

**根据序列长度调整批次大小**：
- 序列长度 ≥ 500: 批次大小 = 8
- 序列长度 ≥ 300: 批次大小 = 16
- 序列长度 < 300: 批次大小 = 32

### 2.3 MoE模型优化

**减少MoE模型参数量**：
- 层数: 8 → 6
- d_model: 512 → 256
- 专家数量: 8 → 4
- MoE批次大小: 使用一半的批次大小（进一步减少内存）

**优化效果**：
- 参数量: ~19.5M → ~5M（减少75%）
- 内存占用: 大幅减少

---

## 三、优化后的配置

### 3.1 序列长度

**当前数据（10,028个样本）**：
- 序列长度: 300步（从1000步减少）
- 覆盖历史: 5小时（仍然足够）
- 可用样本数: 9,728个
- 数据利用率: 97%

### 3.2 批次大小

- **LSTM/Transformer/GRU/PEFT**: 16（序列长度300）
- **MoE模型**: 8（进一步减少内存占用）

### 3.3 MoE模型配置

- 层数: 6（从8减少）
- d_model: 256（从512减少）
- 专家数量: 4（从8减少）
- 稀疏激活率: 50%（每次激活2/4个专家）

---

## 四、内存占用估算

### 4.1 优化前

- 序列长度: 1000步
- 批次大小: 32
- MoE参数量: ~19.5M
- 内存需求: >24GB

### 4.2 优化后

- 序列长度: 300步（减少70%）
- 批次大小: 8-16（减少50-75%）
- MoE参数量: ~5M（减少75%）
- 内存需求: ~8-12GB（减少50%+）

---

## 五、性能权衡

### 5.1 序列长度

**300步 vs 1000步**：
- 覆盖历史: 5小时 vs 16.7小时
- 仍然覆盖所有有显著相关性的历史信息（滞后81步）
- 内存占用: 减少70%

### 5.2 MoE模型

**优化后 vs 优化前**：
- 参数量: ~5M vs ~19.5M（减少75%）
- 稀疏激活率: 50% vs 25%（仍然有效）
- 内存占用: 大幅减少

---

## 六、后续优化方向

如果仍然内存不足，可以进一步：

1. **梯度累积**：
   - 使用更小的批次大小
   - 累积多个批次的梯度
   - 模拟大批次训练

2. **混合精度训练**：
   - 使用FP16/BF16
   - 减少50%的内存占用

3. **模型并行**：
   - 将模型分布到多个GPU
   - 适合超大模型

---

**优化状态**: 已实施  
**预期效果**: 内存占用减少50%+，训练可以正常进行
