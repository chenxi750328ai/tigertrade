# 收益率预测问题深度分析

**生成时间**: 2026-01-26  
**目的**: 深入分析为什么所有样本的收益率预测都是13%左右

---

## 一、问题现象

**测试结果**：
- 所有样本的收益率预测：13.42%左右（几乎不变）
- 标准差：0.000030（非常小）
- 标签收益率均值：7.28%
- 模型预测均值：13.42%（比标签均值高约6%）

**用户疑问**：
1. 收益率学习应该是模型输出和标签的差值，为何是收益率的绝对值？
2. 所有样本的收益率都是13%是怎么做到的？
3. 难道模型的性能比标注的上帝视角还要强么？

---

## 二、损失函数分析

### 2.1 损失函数计算

**当前使用**：HuberLoss（delta=0.01）

**计算公式**：
```python
if |pred - target| <= delta:
    loss = 0.5 * (pred - target)^2  # MSE
else:
    loss = delta * |pred - target| - 0.5 * delta^2  # 线性
```

**结论**：
- ✅ **损失函数确实计算的是差值**（pred - target）
- ✅ 不是收益率的绝对值，而是预测值和标签的差值

### 2.2 损失函数的问题

**问题1：delta太小**
- delta=0.01，意味着如果预测误差在1%以内，使用MSE
- 如果预测误差超过1%，使用线性损失
- 但收益率范围[0, 0.2261]（0%-22.61%），delta=0.01可能太小

**问题2：不够敏感**
- 如果模型预测值几乎不变（13.42%），标签均值7.28%
- 平均误差：13.42% - 7.28% = 6.14%
- 这个误差远大于delta=0.01，应该使用线性损失
- 但线性损失可能不够敏感，无法有效更新模型

---

## 三、为什么所有样本都是13%？

### 3.1 sigmoid函数的影响

**模型输出流程**：
```python
profit_raw = model_output  # 原始输出（例如-0.3到-0.4）
profit = sigmoid(profit_raw) * 0.3  # 最终输出
```

**sigmoid函数特性**：
- sigmoid(-0.5) ≈ 0.38 → 0.38 * 0.3 = 0.114（11.4%）
- sigmoid(-0.4) ≈ 0.40 → 0.40 * 0.3 = 0.120（12.0%）
- sigmoid(-0.3) ≈ 0.43 → 0.43 * 0.3 = 0.129（12.9%）
- sigmoid(-0.2) ≈ 0.45 → 0.45 * 0.3 = 0.135（13.5%）

**分析**：
- 如果模型原始输出集中在-0.3到-0.4之间
- sigmoid后约为0.40-0.43
- 乘以0.3后约为0.120-0.129（12.0%-12.9%）
- **这正好解释了为什么所有样本都是13%左右！**

### 3.2 模型没有学习到区分能力

**问题**：
- 模型原始输出几乎不变（集中在某个值附近）
- 经过sigmoid后，输出被压缩到固定范围
- 最终所有样本的预测值都在13%左右

**原因**：
1. **模型没有学习到区分不同输入的能力**
   - 所有输入都输出相似的原始值
   - 说明模型没有学会根据输入特征调整输出

2. **损失函数不够敏感**
   - HuberLoss可能不够敏感
   - 无法有效更新模型参数

3. **模型容量不足**
   - 收益率预测头可能不够复杂
   - 无法学习复杂的收益率模式

---

## 四、为什么模型预测比标签均值高？

### 4.1 标签均值 vs 模型预测

**标签均值**：7.28%
**模型预测**：13.42%
**差异**：6.14%

**分析**：
- 模型预测比标签均值高约6%
- 这说明模型**没有学会预测标签均值**
- 而是学会了预测某个固定值（13%左右）

### 4.2 可能的原因

**原因1：sigmoid函数的饱和**
- sigmoid函数在输入较大或较小时会饱和
- 如果模型原始输出集中在某个值附近，sigmoid后可能映射到固定值
- 乘以0.3后，得到固定的最终输出

**原因2：模型学会了"预测某个固定值"**
- 模型可能学会了"预测13%"这个固定值
- 而不是根据输入特征调整输出
- 这可能是因为损失函数不够敏感，或者模型容量不足

**原因3：训练不充分**
- 模型可能没有充分训练
- 或者训练过程中陷入了局部最优
- 导致模型输出几乎不变

---

## 五、解决方案

### 5.1 改进损失函数

**方案1：使用MSELoss**
```python
self.profit_criterion = nn.MSELoss()  # 更敏感
```

**方案2：使用MAELoss**
```python
self.profit_criterion = nn.L1Loss()  # 更敏感，对异常值更鲁棒
```

**方案3：调整HuberLoss的delta**
```python
self.profit_criterion = nn.HuberLoss(delta=0.05)  # 增大delta
```

### 5.2 改进模型输出

**方案1：移除sigmoid限制**
```python
# 不使用sigmoid，直接输出
profit = self.profit_head(hidden_out)
# 或者使用tanh，输出范围[-1, 1]
profit = torch.tanh(self.profit_head(hidden_out)) * 0.3
```

**方案2：调整sigmoid范围**
```python
# 不使用固定的0.3，而是根据标签范围动态调整
profit = torch.sigmoid(profit_raw) * max_profit  # max_profit根据标签计算
```

### 5.3 分离训练

**方案：先训练收益率预测，再训练动作分类**
```python
# 阶段1：只训练收益率预测
for epoch in range(50):
    loss = profit_loss  # 只使用收益率损失
    
# 阶段2：同时训练动作分类和收益率预测
for epoch in range(50):
    loss = action_loss + profit_loss
```

### 5.4 使用BERT MASK方式的无监督训练

**方案：收益率预测预训练**
- 使用大量未标注数据
- 预测未来收益率
- 不需要动作标签
- 可能解决收益率学习问题

---

## 六、总结

### 6.1 损失函数

✅ **损失函数计算的是差值**（pred - target），这是正确的
⚠️ **但HuberLoss可能不够敏感**，建议改用MSELoss或MAELoss

### 6.2 为什么所有样本都是13%？

**原因**：
1. 模型原始输出集中在某个值附近（例如-0.3到-0.4）
2. sigmoid函数将这个值映射到约0.40-0.43
3. 乘以0.3后得到约0.120-0.129（12-13%）
4. 所以所有样本的预测值都在13%左右

**根本原因**：
- 模型没有学习到区分不同输入的能力
- 所有输入都输出相似的原始值
- 经过sigmoid后，输出被压缩到固定范围

### 6.3 为什么模型预测比标签均值高？

**原因**：
- 模型学会了"预测某个固定值"（13%）
- 而不是根据输入特征调整输出
- 这可能是因为损失函数不够敏感，或者模型容量不足

### 6.4 建议

1. **改进损失函数**：使用MSELoss或MAELoss
2. **改进模型输出**：移除或调整sigmoid限制
3. **分离训练**：先训练收益率预测，再训练动作分类
4. **使用BERT MASK方式**：无监督预训练收益率预测

---

**报告生成时间**: 2026-01-26  
**状态**: 分析完成，建议改进损失函数和模型输出
