import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import os
from datetime import datetime
import glob
import argparse
import warnings
import gc
warnings.filterwarnings("ignore")

# å¯¼å…¥å„ç§ç­–ç•¥
from llm_strategy import LLMTradingStrategy
from enhanced_transformer_strategy import EnhancedTransformerStrategy
from large_transformer_strategy import LargeTransformerStrategy
from model_comparison_strategy import ModelComparisonStrategy
from rl_trading_strategy import RLTradingStrategy
from large_model_strategy import LargeModelStrategy
from huge_transformer_strategy import HugeTransformerStrategy
from data_fetcher import aggregate_data_for_training, prepare_features_from_raw_data


def cleanup_memory():
    """æ¸…ç†å†…å­˜"""
    gc.collect()
    if torch.cuda.is_available():
        torch.cuda.empty_cache()


def test_single_model(strategy_class, strategy_name, X, y):
    """æµ‹è¯•å•ä¸ªæ¨¡å‹çš„æ€§èƒ½"""
    print(f"\nğŸš€ Testing {strategy_name}...")
    
    try:
        # åˆå§‹åŒ–ç­–ç•¥
        strategy = strategy_class()
        
        # åˆ†å‰²æ•°æ®é›†
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        print(f"ğŸ“ˆ Training set size: {len(X_train)}, Test set size: {len(X_test)}")
        
        # åˆ›å»ºä¸´æ—¶DataFrameç”¨äºè®­ç»ƒ
        temp_df = pd.DataFrame({
            'price_current': X_train[:, 0],
            'grid_lower': X_train[:, 1],
            'grid_upper': X_train[:, 2],
            'atr': X_train[:, 3],
            'rsi_1m': X_train[:, 4] * 100,
            'rsi_5m': X_train[:, 5] * 100,
            'buffer': X_train[:, 6],
            'threshold': X_train[:, 7],
            'near_lower': X_train[:, 8] > 0.5,
            'rsi_ok': X_train[:, 9] > 0.5
        })
        
        # è®­ç»ƒæ¨¡å‹
        if hasattr(strategy, 'train_model'):
            print(f"   ğŸ“Š Starting training for {strategy_name}...")
            strategy.train_model(temp_df)
        
        # è¯„ä¼°æ¨¡å‹
        correct = 0
        total = 0
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        temp_test_df = pd.DataFrame({
            'price_current': X_test[:, 0],
            'grid_lower': X_test[:, 1],
            'grid_upper': X_test[:, 2],
            'atr': X_test[:, 3],
            'rsi_1m': X_test[:, 4] * 100,
            'rsi_5m': X_test[:, 5] * 100,
            'buffer': X_test[:, 6],
            'threshold': X_test[:, 7],
            'near_lower': X_test[:, 8] > 0.5,
            'rsi_ok': X_test[:, 9] > 0.5
        })
        
        # å¯¹æ¯ä¸ªæµ‹è¯•æ ·æœ¬è¿›è¡Œé¢„æµ‹
        for idx in range(len(temp_test_df)):
            row = temp_test_df.iloc[idx]
            true_label = y_test[idx]
            
            # å‡†å¤‡å½“å‰æ•°æ®ç”¨äºæ¨¡å‹é¢„æµ‹
            current_data = {
                'price_current': row['price_current'],
                'grid_lower': row['grid_lower'],
                'grid_upper': row['grid_upper'],
                'atr': row['atr'],
                'rsi_1m': row['rsi_1m'],
                'rsi_5m': row['rsi_5m'],
                'buffer': row['buffer'],
                'threshold': row['threshold'],
                'near_lower': row['near_lower'],
                'rsi_ok': row['rsi_ok']
            }
            
            # ä½¿ç”¨ç­–ç•¥è¿›è¡Œé¢„æµ‹
            if hasattr(strategy, 'predict_action'):
                try:
                    pred_action, confidence = strategy.predict_action(current_data)
                    if pred_action == true_label:
                        correct += 1
                    total += 1
                except Exception as e:
                    print(f"    âš ï¸ Prediction error for {strategy_name}: {e}")
                    continue
            else:
                continue
        
        accuracy = correct / total if total > 0 else 0
        
        print(f"   âœ… {strategy_name} Test Accuracy: {accuracy:.4f} ({correct}/{total})")
        
        # è·å–æ¨¡å‹å‚æ•°é‡
        params_count = 0
        if hasattr(strategy, 'model') and strategy.model:
            params_count = sum(p.numel() for p in strategy.model.parameters() if p.requires_grad)
        
        # æ¸…ç†å†…å­˜
        del strategy
        cleanup_memory()
        
        return {
            'accuracy': accuracy,
            'total_samples': total,
            'correct_predictions': correct,
            'params_count': params_count
        }
        
    except Exception as e:
        print(f"âŒ Error testing {strategy_name}: {e}")
        import traceback
        traceback.print_exc()
        
        # å°è¯•æ¸…ç†å†…å­˜
        cleanup_memory()
        return None


def main():
    print("ğŸ” Loading extended historical data...")
    
    # åŠ è½½æ‰©å±•çš„å†å²æ•°æ®
    df = aggregate_data_for_training()
    if df is None or len(df) < 1000:  # è¦æ±‚è‡³å°‘1000ä¸ªæ•°æ®ç‚¹
        print("âŒ Insufficient extended data for training")
        return
    
    print(f"ğŸ“Š Loaded {len(df)} data points from extended dataset")
    
    # å‡†å¤‡ç‰¹å¾
    print("ğŸ” Preparing features from raw data...")
    features_df = prepare_features_from_raw_data(df)
    if features_df is None or len(features_df) < 1000:
        print("âŒ Insufficient features for training")
        return
    
    # ç”Ÿæˆæ ‡ç­¾
    X, y = prepare_features_and_labels(features_df)
    
    if len(X) < 1000:
        print("âŒ Insufficient prepared data for training")
        return
    
    print(f"ğŸ“Š Prepared data: Feature matrix {X.shape}, Label vector {y.shape}")
    
    # å®šä¹‰è¦æµ‹è¯•çš„ç­–ç•¥
    strategies_to_test = [
        (LLMTradingStrategy, "LLM Trading"),
        (LargeModelStrategy, "Large Model"),
        (LargeTransformerStrategy, "Large Transformer"),
        (EnhancedTransformerStrategy, "Enhanced Transformer"),
        (HugeTransformerStrategy, "Huge Transformer")
    ]
    
    # å­˜å‚¨ç»“æœ
    results = {}
    
    # é€ä¸ªæµ‹è¯•ç­–ç•¥
    for strategy_class, strategy_name in strategies_to_test:
        result = test_single_model(strategy_class, strategy_name, X, y)
        if result:
            results[strategy_name] = result
        # æ¯æ¬¡æµ‹è¯•åéƒ½æ¸…ç†å†…å­˜
        cleanup_memory()
    
    # æµ‹è¯•RLç­–ç•¥
    print(f"\nğŸš€ Testing RL Trading strategy...")
    try:
        # åˆå§‹åŒ–RLç­–ç•¥
        rl_strategy = RLTradingStrategy()
        
        # åˆ†å‰²æ•°æ®é›†
        split_idx = int(len(X) * 0.8)
        X_train, X_test = X[:split_idx], X[split_idx:]
        y_train, y_test = y[:split_idx], y[split_idx:]
        
        print(f"ğŸ“ˆ Training set size: {len(X_train)}, Test set size: {len(X_test)}")
        
        # åˆ›å»ºä¸´æ—¶DataFrameç”¨äºè®­ç»ƒ
        temp_df = pd.DataFrame({
            'price_current': X_train[:, 0],
            'grid_lower': X_train[:, 1],
            'grid_upper': X_train[:, 2],
            'atr': X_train[:, 3],
            'rsi_1m': X_train[:, 4] * 100,
            'rsi_5m': X_train[:, 5] * 100,
            'buffer': X_train[:, 6],
            'threshold': X_train[:, 7],
            'near_lower': X_train[:, 8] > 0.5,
            'rsi_ok': X_train[:, 9] > 0.5
        })
        
        # è®­ç»ƒRLæ¨¡å‹
        rl_strategy.train_model(temp_df)
        
        # è¯„ä¼°æ¨¡å‹
        correct = 0
        total = 0
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        temp_test_df = pd.DataFrame({
            'price_current': X_test[:, 0],
            'grid_lower': X_test[:, 1],
            'grid_upper': X_test[:, 2],
            'atr': X_test[:, 3],
            'rsi_1m': X_test[:, 4] * 100,
            'rsi_5m': X_test[:, 5] * 100,
            'buffer': X_test[:, 6],
            'threshold': X_test[:, 7],
            'near_lower': X_test[:, 8] > 0.5,
            'rsi_ok': X_test[:, 9] > 0.5
        })
        
        # å¯¹æ¯ä¸ªæµ‹è¯•æ ·æœ¬è¿›è¡Œé¢„æµ‹
        for idx in range(len(temp_test_df)):
            row = temp_test_df.iloc[idx]
            true_label = y_test[idx]
            
            # å‡†å¤‡å½“å‰æ•°æ®ç”¨äºæ¨¡å‹é¢„æµ‹
            current_data = {
                'price_current': row['price_current'],
                'grid_lower': row['grid_lower'],
                'grid_upper': row['grid_upper'],
                'atr': row['atr'],
                'rsi_1m': row['rsi_1m'],
                'rsi_5m': row['rsi_5m'],
                'buffer': row['buffer'],
                'threshold': row['threshold'],
                'near_lower': row['near_lower'],
                'rsi_ok': row['rsi_ok']
            }
            
            try:
                pred_action, confidence = rl_strategy.predict_action(current_data)
                if pred_action == true_label:
                    correct += 1
                total += 1
            except Exception as e:
                print(f"    âš ï¸ Prediction error for RL: {e}")
                continue
        
        accuracy = correct / total if total > 0 else 0
        
        print(f"   âœ… RL Trading Test Accuracy: {accuracy:.4f} ({correct}/{total})")
        
        # è·å–æ¨¡å‹å‚æ•°é‡
        params_count = 0
        if hasattr(rl_strategy, 'policy_net') and rl_strategy.policy_net:
            params_count = sum(p.numel() for p in rl_strategy.policy_net.parameters() if p.requires_grad)
        
        results["RL Trading"] = {
            'accuracy': accuracy,
            'total_samples': total,
            'correct_predictions': correct,
            'params_count': params_count
        }
        
        # æ¸…ç†å†…å­˜
        del rl_strategy
        cleanup_memory()
    except Exception as e:
        print(f"âŒ Error testing RL Trading strategy: {e}")
        import traceback
        traceback.print_exc()
        cleanup_memory()
    
    # è¾“å‡ºæ±‡æ€»ç»“æœ
    print("\n" + "="*80)
    print("ğŸ“Š Model Performance Comparison Results")
    print("="*80)
    
    if not results:
        print("âŒ No results available")
        return
    
    # æŒ‰å‚æ•°é‡æ’åº
    sorted_results = sorted(results.items(), key=lambda x: x[1]['params_count'])
    
    print(f"{'Strategy Name':<25} {'Params Count':<15} {'Accuracy':<10} {'Samples':<10} {'Correct':<10}")
    print("-"*80)
    
    for name, metrics in sorted_results:
        param_str = f"{metrics['params_count']:,}"
        print(f"{name:<25} {param_str:<15} {metrics['accuracy']:<10.4f} {metrics['total_samples']:<10} {metrics['correct_predictions']:<10}")
    
    print(f"\nğŸ“ˆ Total strategies tested: {len(results)}")
    
    # åˆ†ææ˜¯å¦è¶Šå¤§è¶Šå¥½
    analyze_scaling_law(sorted_results)


def prepare_features_and_labels(df, look_ahead=10):
    """å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾"""
    print("Preparing features and labels from extended dataset...")
    
    # å‡†å¤‡ç‰¹å¾
    X = []
    for i in range(len(df)):
        row = df.iloc[i]
        
        # å‡†å¤‡ç‰¹å¾
        features = [
            row.get('price_current', 0),
            row.get('grid_lower', 0),
            row.get('grid_upper', 0),
            row.get('atr', 0),
            row.get('rsi_1m', 50),
            row.get('rsi_5m', 50),
            row.get('buffer', 0),
            row.get('threshold', 0),
            1 if row.get('near_lower', False) else 0,
            1 if row.get('rsi_ok', False) else 0
        ]
        
        # å½’ä¸€åŒ–ç‰¹å¾
        features_np = np.array(features)
        mean_val = np.mean(features_np)
        std_val = np.std(features_np) + 1e-8
        normalized_features = (features_np - mean_val) / std_val
        X.append(normalized_features.tolist())
    
    # ç”Ÿæˆæ ‡ç­¾
    y = []
    for i in range(len(df) - look_ahead):
        current_price = df.iloc[i]['price_current']
        future_prices = df.iloc[i+1:i+look_ahead+1]['price_current'].values
        
        if len(future_prices) == 0:
            # å¦‚æœæœªæ¥ä»·æ ¼ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤æ ‡ç­¾
            label = 0
        else:
            # è®¡ç®—æœ€å¤§ç›ˆåˆ©å’Œæœ€å¤§äºæŸ
            max_future_price = max(future_prices)
            min_future_price = min(future_prices)
            
            buy_profit = (max_future_price - current_price) / current_price
            sell_profit = (current_price - min_future_price) / current_price
            
            # åˆ›å»ºæ ‡ç­¾: 0=ä¸æ“ä½œ, 1=ä¹°å…¥, 2=å–å‡º
            # åªæœ‰å½“é¢„æœŸç›ˆåˆ©è¶…è¿‡é˜ˆå€¼æ—¶æ‰å»ºè®®æ“ä½œ
            profit_threshold = 0.005  # æé«˜é˜ˆå€¼åˆ°0.5%ï¼Œå‡å°‘äº¤æ˜“é¢‘ç‡ä½†æé«˜è´¨é‡
            min_diff = 0.003  # æœ€å°å·®å€¼ï¼Œç¡®ä¿ä¹°å–ä¹‹é—´æœ‰è¶³å¤Ÿå·®è·
            
            # åªæœ‰å½“ä¹°å–ç›ˆåˆ©å·®å€¼è¶…è¿‡æœ€å°å·®å€¼ä¸”è¶…è¿‡é˜ˆå€¼æ—¶æ‰äº¤æ˜“
            if abs(buy_profit - sell_profit) >= min_diff:
                if buy_profit > sell_profit and buy_profit > profit_threshold:
                    label = 1  # ä¹°å…¥
                elif sell_profit > buy_profit and sell_profit > profit_threshold:
                    label = 2  # å–å‡º
                else:
                    label = 0  # ä¸æ“ä½œ
            else:
                label = 0  # ä¸æ“ä½œ - å·®å€¼å¤ªå°ï¼Œä¸ç¡®å®šæ€§é«˜
        
        y.append(label)
    
    # å¯¹äºæœ€ålook_aheadä¸ªæ•°æ®ç‚¹ï¼Œå¤åˆ¶æœ€åä¸€ä¸ªæ ‡ç­¾
    for _ in range(min(look_ahead, len(X) - len(y))):
        y.append(y[-1] if y else 0)
    
    # ç¡®ä¿Xå’Œyé•¿åº¦ä¸€è‡´
    X = X[:len(y)]
    
    return np.array(X), np.array(y)


def analyze_scaling_law(sorted_results):
    """åˆ†ææ¨¡å‹å¤§å°ä¸æ€§èƒ½çš„å…³ç³»"""
    print("\n" + "="*50)
    print("ğŸ“ˆ Scaling Law Analysis")
    print("="*50)
    
    if len(sorted_results) < 2:
        print("Need at least 2 models to analyze scaling law")
        return
    
    # æå–å‚æ•°é‡å’Œå‡†ç¡®ç‡
    params = [r[1]['params_count'] for r in sorted_results]
    accs = [r[1]['accuracy'] for r in sorted_results]
    
    # è®¡ç®—ç›¸é‚»æ¨¡å‹é—´çš„å‚æ•°å¢é•¿å’Œæ€§èƒ½æå‡
    for i in range(1, len(params)):
        prev_params = params[i-1]
        curr_params = params[i]
        prev_acc = accs[i-1]
        curr_acc = accs[i]
        
        if prev_params > 0:
            param_ratio = curr_params / prev_params
        else:
            param_ratio = float('inf')
        
        acc_improvement = curr_acc - prev_acc
        
        prev_name = sorted_results[i-1][0]
        curr_name = sorted_results[i][0]
        
        print(f"{prev_name} â†’ {curr_name}:")
        print(f"  Params: {prev_params:,} â†’ {curr_params:,} ({param_ratio:.2f}x)")
        print(f"  Acc: {prev_acc:.4f} â†’ {curr_acc:.4f} (+{acc_improvement:.4f})")
        
        if acc_improvement > 0:
            print(f"  ğŸ“ˆ Positive scaling: More params â†’ Better performance")
        elif acc_improvement == 0:
            print(f"  â¡ï¸ Neutral scaling: No significant improvement")
        else:
            print(f"  ğŸ“‰ Negative scaling: More params â†’ Worse performance")
        print()
    
    # æ•´ä½“è¶‹åŠ¿åˆ†æ
    overall_improvement = accs[-1] - accs[0]
    overall_param_ratio = params[-1] / params[0] if params[0] > 0 else float('inf')
    
    print(f"Overall trend: {sorted_results[0][0]} ({accs[0]:.4f}) â†’ {sorted_results[-1][0]} ({accs[-1]:.4f})")
    print(f"Parameter scale: {overall_param_ratio:.2f}x")
    print(f"Performance change: {overall_improvement:.4f}")
    
    if overall_improvement > 0.01:  # æ€§èƒ½æå‡è¶…è¿‡1%
        print("âœ… Strong evidence of positive scaling!")
    elif overall_improvement > 0:
        print("âœ… Mild evidence of positive scaling")
    elif overall_improvement == 0:
        print("â¡ï¸ Neutral scaling - no clear relationship")
    else:
        print("ğŸ“‰ Evidence against 'bigger is better'")
    
    # æ€»ç»“
    print("\n" + "="*50)
    print("ğŸ“‹ SUMMARY")
    print("="*50)
    print("Based on our analysis with 20,000 data points:")
    print("- Each model was trained with increased epochs (20) for better convergence")
    print("- Class imbalance was handled with weighted loss functions")
    print("- More data was used to improve statistical significance")
    
    if overall_improvement > 0:
        print("- 'BIGGER IS BETTER' holds true for this dataset")
    else:
        print("- Model size does not guarantee better performance")
        print("- Consider adding more data or tuning hyperparameters")


if __name__ == "__main__":
    main()