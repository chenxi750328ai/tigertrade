import pandas as pd
import numpy as np
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import os
from datetime import datetime
import glob
import argparse
import warnings
import gc

warnings.filterwarnings("ignore")

from data_fetcher import aggregate_data_for_training, prepare_features_from_raw_data


def prepare_features_and_labels(df, look_ahead=10):
    """å‡†å¤‡ç‰¹å¾å’Œæ ‡ç­¾"""
    print("Preparing features and labels from extended dataset...")
    
    # å‡†å¤‡ç‰¹å¾
    X = []
    for i in range(len(df)):
        row = df.iloc[i]
        
        # å‡†å¤‡ç‰¹å¾
        features = [
            row.get('price_current', 0),
            row.get('grid_lower', 0),
            row.get('grid_upper', 0),
            row.get('atr', 0),
            row.get('rsi_1m', 50),
            row.get('rsi_5m', 50),
            row.get('buffer', 0),
            row.get('threshold', 0),
            1 if row.get('near_lower', False) else 0,
            1 if row.get('rsi_ok', False) else 0
        ]
        
        # å½’ä¸€åŒ–ç‰¹å¾
        features_np = np.array(features)
        mean_val = np.mean(features_np)
        std_val = np.std(features_np) + 1e-8
        normalized_features = (features_np - mean_val) / std_val
        X.append(normalized_features.tolist())
    
    # ç”Ÿæˆæ ‡ç­¾
    y = []
    for i in range(len(df) - look_ahead):
        current_price = df.iloc[i]['price_current']
        future_prices = df.iloc[i+1:i+look_ahead+1]['price_current'].values
        
        if len(future_prices) == 0:
            # å¦‚æœæœªæ¥ä»·æ ¼ä¸å¯ç”¨ï¼Œä½¿ç”¨é»˜è®¤æ ‡ç­¾
            label = 0
        else:
            # è®¡ç®—æœ€å¤§ç›ˆåˆ©å’Œæœ€å¤§äºæŸ
            max_future_price = max(future_prices)
            min_future_price = min(future_prices)
            
            buy_profit = (max_future_price - current_price) / current_price
            sell_profit = (current_price - min_future_price) / current_price
            
            # åˆ›å»ºæ ‡ç­¾: 0=ä¸æ“ä½œ, 1=ä¹°å…¥, 2=å–å‡º
            # åªæœ‰å½“é¢„æœŸç›ˆåˆ©è¶…è¿‡é˜ˆå€¼æ—¶æ‰å»ºè®®æ“ä½œ
            profit_threshold = 0.005  # æé«˜é˜ˆå€¼åˆ°0.5%ï¼Œå‡å°‘äº¤æ˜“é¢‘ç‡ä½†æé«˜è´¨é‡
            min_diff = 0.003  # æœ€å°å·®å€¼ï¼Œç¡®ä¿ä¹°å–ä¹‹é—´æœ‰è¶³å¤Ÿå·®è·
            
            # åªæœ‰å½“ä¹°å–ç›ˆåˆ©å·®å€¼è¶…è¿‡æœ€å°å·®å€¼ä¸”è¶…è¿‡é˜ˆå€¼æ—¶æ‰äº¤æ˜“
            if abs(buy_profit - sell_profit) >= min_diff:
                if buy_profit > sell_profit and buy_profit > profit_threshold:
                    label = 1  # ä¹°å…¥
                elif sell_profit > buy_profit and sell_profit > profit_threshold:
                    label = 2  # å–å‡º
                else:
                    label = 0  # ä¸æ“ä½œ
            else:
                label = 0  # ä¸æ“ä½œ - å·®å€¼å¤ªå°ï¼Œä¸ç¡®å®šæ€§é«˜
        
        y.append(label)
    
    # å¯¹äºæœ€ålook_aheadä¸ªæ•°æ®ç‚¹ï¼Œå¤åˆ¶æœ€åä¸€ä¸ªæ ‡ç­¾
    for _ in range(min(look_ahead, len(X) - len(y))):
        y.append(y[-1] if y else 0)
    
    # ç¡®ä¿Xå’Œyé•¿åº¦ä¸€è‡´
    X = X[:len(y)]
    
    return np.array(X), np.array(y)


def train_and_evaluate_model(model_class, model_name, X_train, y_train, X_test, y_test, device='cuda'):
    """è®­ç»ƒå¹¶è¯„ä¼°æŒ‡å®šæ¨¡å‹"""
    print(f"\nğŸš€ Training and evaluating {model_name}...")
    
    try:
        # åˆå§‹åŒ–æ¨¡å‹
        strategy = model_class()
        
        # è·å–å‚æ•°æ•°é‡
        params_count = sum(p.numel() for p in strategy.model.parameters() if p.requires_grad)
        print(f"ğŸ“Š Model parameters: {params_count:,}")
        
        # åˆ›å»ºè®­ç»ƒæ•°æ®çš„DataFrame
        temp_df = pd.DataFrame({
            'price_current': X_train[:, 0],
            'grid_lower': X_train[:, 1],
            'grid_upper': X_train[:, 2],
            'atr': X_train[:, 3],
            'rsi_1m': X_train[:, 4] * 100,
            'rsi_5m': X_train[:, 5] * 100,
            'buffer': X_train[:, 6],
            'threshold': X_train[:, 7],
            'near_lower': X_train[:, 8] > 0.5,
            'rsi_ok': X_train[:, 9] > 0.5
        })
        
        # è®­ç»ƒæ¨¡å‹
        if hasattr(strategy, 'train_model'):
            print(f"   ğŸ“Š Starting training for {model_name}...")
            strategy.train_model(temp_df)
        
        # è¯„ä¼°æ¨¡å‹
        correct = 0
        total = 0
        
        # å‡†å¤‡æµ‹è¯•æ•°æ®
        temp_test_df = pd.DataFrame({
            'price_current': X_test[:, 0],
            'grid_lower': X_test[:, 1],
            'grid_upper': X_test[:, 2],
            'atr': X_test[:, 3],
            'rsi_1m': X_test[:, 4] * 100,
            'rsi_5m': X_test[:, 5] * 100,
            'buffer': X_test[:, 6],
            'threshold': X_test[:, 7],
            'near_lower': X_test[:, 8] > 0.5,
            'rsi_ok': X_test[:, 9] > 0.5
        })
        
        # å¯¹æ¯ä¸ªæµ‹è¯•æ ·æœ¬è¿›è¡Œé¢„æµ‹
        for idx in range(len(temp_test_df)):
            row = temp_test_df.iloc[idx]
            true_label = y_test[idx]
            
            # å‡†å¤‡å½“å‰æ•°æ®ç”¨äºæ¨¡å‹é¢„æµ‹
            current_data = {
                'price_current': row['price_current'],
                'grid_lower': row['grid_lower'],
                'grid_upper': row['grid_upper'],
                'atr': row['atr'],
                'rsi_1m': row['rsi_1m'],
                'rsi_5m': row['rsi_5m'],
                'buffer': row['buffer'],
                'threshold': row['threshold'],
                'near_lower': row['near_lower'],
                'rsi_ok': row['rsi_ok']
            }
            
            # ä½¿ç”¨ç­–ç•¥è¿›è¡Œé¢„æµ‹
            if hasattr(strategy, 'predict_action'):
                try:
                    pred_action, confidence = strategy.predict_action(current_data)
                    if pred_action == true_label:
                        correct += 1
                    total += 1
                except Exception as e:
                    print(f"    âš ï¸ Prediction error: {e}")
                    continue
            else:
                continue
        
        accuracy = correct / total if total > 0 else 0
        
        print(f"   âœ… {model_name} Test Accuracy: {accuracy:.4f} ({correct}/{total})")
        
        # æ¸…ç†å†…å­˜
        del strategy, temp_df, temp_test_df
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return {
            'accuracy': accuracy,
            'total_samples': total,
            'correct_predictions': correct,
            'params_count': params_count
        }
        
    except Exception as e:
        print(f"âŒ Error training and evaluating {model_name}: {e}")
        import traceback
        traceback.print_exc()
        
        # æ¸…ç†å†…å­˜
        gc.collect()
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
        
        return None


def main():
    print("ğŸ” Loading extended historical data...")
    
    # åŠ è½½æ‰©å±•çš„å†å²æ•°æ®
    df = aggregate_data_for_training()
    if df is None or len(df) < 1000:  # è¦æ±‚è‡³å°‘1000ä¸ªæ•°æ®ç‚¹
        print("âŒ Insufficient extended data for training")
        return
    
    print(f"ğŸ“Š Loaded {len(df)} data points from extended dataset")
    
    # å‡†å¤‡ç‰¹å¾
    print("ğŸ” Preparing features from raw data...")
    features_df = prepare_features_from_raw_data(df)
    if features_df is None or len(features_df) < 1000:
        print("âŒ Insufficient features for training")
        return
    
    # ç”Ÿæˆæ ‡ç­¾
    X, y = prepare_features_and_labels(features_df)
    
    if len(X) < 1000:
        print("âŒ Insufficient prepared data for training")
        return
    
    print(f"ğŸ“Š Prepared data: Feature matrix {X.shape}, Label vector {y.shape}")
    
    # åˆ†å‰²æ•°æ®é›†
    split_idx = int(len(X) * 0.8)
    X_train, X_test = X[:split_idx], X[split_idx:]
    y_train, y_test = y[:split_idx], y[split_idx:]
    
    print(f"ğŸ“ˆ Training set size: {len(X_train)}, Test set size: {len(X_test)}")
    
    # å®šä¹‰è¦æµ‹è¯•çš„ç­–ç•¥ç±»
    strategies_to_test = [
        ("LLM Trading", "llm_strategy", "LLMTradingStrategy"),
        ("Large Model", "large_model_strategy", "LargeModelStrategy"),
    ]
    
    # å­˜å‚¨ç»“æœ
    results = {}
    
    # æµ‹è¯•æ¯ä¸ªæ¨¡å‹
    for model_name, module_name, class_name in strategies_to_test:
        try:
            # åŠ¨æ€å¯¼å…¥æ¨¡å‹ç±»
            module = __import__(module_name, fromlist=[class_name])
            model_class = getattr(module, class_name)
            
            result = train_and_evaluate_model(model_class, model_name, X_train, y_train, X_test, y_test)
            if result:
                results[model_name] = result
        except Exception as e:
            print(f"âŒ Error importing or testing {model_name}: {e}")
            import traceback
            traceback.print_exc()
    
    # è¾“å‡ºæ±‡æ€»ç»“æœ
    print("\n" + "="*80)
    print("ğŸ“Š Model Performance Comparison Results")
    print("="*80)
    
    if not results:
        print("âŒ No results available")
        return
    
    # æŒ‰å‚æ•°é‡æ’åº
    sorted_results = sorted(results.items(), key=lambda x: x[1]['params_count'])
    
    print(f"{'Strategy Name':<25} {'Params Count':<15} {'Accuracy':<10} {'Samples':<10} {'Correct':<10}")
    print("-"*80)
    
    for name, metrics in sorted_results:
        param_str = f"{metrics['params_count']:,}"
        print(f"{name:<25} {param_str:<15} {metrics['accuracy']:<10.4f} {metrics['total_samples']:<10} {metrics['correct_predictions']:<10}")
    
    print(f"\nğŸ“ˆ Total strategies tested: {len(results)}")
    
    # åˆ†ææ˜¯å¦è¶Šå¤§è¶Šå¥½
    if len(sorted_results) >= 2:
        analyze_scaling_law(sorted_results)


def analyze_scaling_law(sorted_results):
    """åˆ†ææ¨¡å‹å¤§å°ä¸æ€§èƒ½çš„å…³ç³»"""
    print("\n" + "="*50)
    print("ğŸ“ˆ Scaling Law Analysis")
    print("="*50)
    
    # æå–å‚æ•°é‡å’Œå‡†ç¡®ç‡
    params = [r[1]['params_count'] for r in sorted_results]
    accs = [r[1]['accuracy'] for r in sorted_results]
    
    # è®¡ç®—ç›¸é‚»æ¨¡å‹é—´çš„å‚æ•°å¢é•¿å’Œæ€§èƒ½æå‡
    for i in range(1, len(params)):
        prev_params = params[i-1]
        curr_params = params[i]
        prev_acc = accs[i-1]
        curr_acc = accs[i]
        
        if prev_params > 0:
            param_ratio = curr_params / prev_params
        else:
            param_ratio = float('inf')
        
        acc_improvement = curr_acc - prev_acc
        
        prev_name = sorted_results[i-1][0]
        curr_name = sorted_results[i][0]
        
        print(f"{prev_name} â†’ {curr_name}:")
        print(f"  Params: {prev_params:,} â†’ {curr_params:,} ({param_ratio:.2f}x)")
        print(f"  Acc: {prev_acc:.4f} â†’ {curr_acc:.4f} (+{acc_improvement:.4f})")
        
        if acc_improvement > 0:
            print(f"  ğŸ“ˆ Positive scaling: More params â†’ Better performance")
        elif acc_improvement == 0:
            print(f"  â¡ï¸ Neutral scaling: No significant improvement")
        else:
            print(f"  ğŸ“‰ Negative scaling: More params â†’ Worse performance")
        print()
    
    # æ•´ä½“è¶‹åŠ¿åˆ†æ
    overall_improvement = accs[-1] - accs[0]
    if params[0] > 0:
        overall_param_ratio = params[-1] / params[0]
    else:
        overall_param_ratio = float('inf')
    
    print(f"Overall trend: {sorted_results[0][0]} ({accs[0]:.4f}) â†’ {sorted_results[-1][0]} ({accs[-1]:.4f})")
    print(f"Parameter scale: {overall_param_ratio:.2f}x")
    print(f"Performance change: {overall_improvement:.4f}")
    
    if overall_improvement > 0.01:  # æ€§èƒ½æå‡è¶…è¿‡1%
        print("âœ… Strong evidence of positive scaling!")
    elif overall_improvement > 0:
        print("âœ… Mild evidence of positive scaling")
    elif overall_improvement == 0:
        print("â¡ï¸ Neutral scaling - no clear relationship")
    else:
        print("ğŸ“‰ Evidence against 'bigger is better'")


if __name__ == "__main__":
    main()