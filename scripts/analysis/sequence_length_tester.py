#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
åŠ¨æ€åºåˆ—é•¿åº¦æµ‹è¯•å™¨
è‡ªåŠ¨æµ‹è¯•ä¸åŒåºåˆ—é•¿åº¦ï¼Œæ‰¾åˆ°æœ€ä¼˜åºåˆ—é•¿åº¦
"""

import sys
import os
import numpy as np
import pandas as pd
import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
from typing import Dict, List, Tuple, Optional
import json
from datetime import datetime
import matplotlib.pyplot as plt
import glob

sys.path.insert(0, '/home/cx/tigertrade')

try:
    from src.strategies.llm_strategy import TradingLSTM, LLMTradingStrategy
except ImportError:
    print("âš ï¸ æ— æ³•å¯¼å…¥ç­–ç•¥æ¨¡å—")


class SequenceLengthTester:
    """åŠ¨æ€åºåˆ—é•¿åº¦æµ‹è¯•å™¨"""
    
    def __init__(self, data_dir='/home/cx/trading_data', 
                 min_length=10, max_length=500, step=50,  # å¢å¤§æ­¥é•¿ä»¥åŠ å¿«æµ‹è¯•
                 convergence_window=3, convergence_threshold=0.02):  # æ”¾å®½æ”¶æ•›æ¡ä»¶
        """
        åˆå§‹åŒ–æµ‹è¯•å™¨
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            min_length: æœ€å°åºåˆ—é•¿åº¦
            max_length: æœ€å¤§åºåˆ—é•¿åº¦
            step: æµ‹è¯•æ­¥é•¿
            convergence_window: æ”¶æ•›æ£€æµ‹çª—å£å¤§å°
            convergence_threshold: æ”¶æ•›é˜ˆå€¼ï¼ˆç›¸å¯¹å˜åŒ–ç‡ï¼‰
        """
        self.data_dir = data_dir
        self.min_length = min_length
        self.max_length = max_length
        self.step = step
        self.convergence_window = convergence_window
        self.convergence_threshold = convergence_threshold
        self.results = []
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    
    def prepare_features(self, row):
        """å‡†å¤‡å•ä¸ªæ—¶é—´ç‚¹çš„ç‰¹å¾"""
        try:
            features = [
                row['price_current'],
                row['atr'],
                row['rsi_1m'] if pd.notna(row['rsi_1m']) else 50,
                row['rsi_5m'] if pd.notna(row['rsi_5m']) else 50,
                row.get('boll_upper', 0),
                row.get('boll_mid', 0),
                row.get('boll_lower', 0),
                row.get('boll_position', 0.5),
                row.get('price_change_1', 0),
                row.get('price_change_5', 0),
                row.get('volatility', 0),
                row.get('volume_1m', 0)
            ]
            # å½’ä¸€åŒ–
            features_np = np.array(features)
            mean_val = np.mean(features_np)
            std_val = np.std(features_np) + 1e-8
            normalized_features = (features_np - mean_val) / std_val
            return normalized_features.tolist()
        except Exception as e:
            return [0.0] * 12
    
    def prepare_sequence_features(self, df, current_idx, seq_length):
        """
        å‡†å¤‡å†å²åºåˆ—ç‰¹å¾
        
        Args:
            df: æ•°æ®æ¡†
            current_idx: å½“å‰ç´¢å¼•
            seq_length: åºåˆ—é•¿åº¦
        
        Returns:
            sequence: (seq_length, 12) çš„æ•°ç»„
        """
        start_idx = max(0, current_idx - seq_length + 1)
        sequence_df = df.iloc[start_idx:current_idx+1]
        
        sequences = []
        for _, row in sequence_df.iterrows():
            features = self.prepare_features(row)
            sequences.append(features)
        
        # å¦‚æœåºåˆ—ä¸è¶³seq_lengthï¼Œç”¨ç¬¬ä¸€ä¸ªå€¼å¡«å……
        while len(sequences) < seq_length:
            if sequences:
                sequences.insert(0, sequences[0])
            else:
                sequences.insert(0, [0.0] * 12)
        
        return np.array(sequences, dtype=np.float32)
    
    def load_training_data(self):
        """åŠ è½½è®­ç»ƒæ•°æ®ï¼ˆä¼˜å…ˆä½¿ç”¨åŒ…å«price_currentçš„æ–‡ä»¶ï¼‰"""
        data_files = []
        
        # 1. ä¼˜å…ˆæŸ¥æ‰¾ä»Kçº¿ç”Ÿæˆçš„æ•°æ®æ–‡ä»¶ï¼ˆæ•°æ®é‡å¤§ï¼‰
        kline_data_files = glob.glob(os.path.join(self.data_dir, 'training_data_from_klines_*.csv'))
        for csv_file in kline_data_files:
            try:
                df_test = pd.read_csv(csv_file, nrows=1)
                if 'price_current' in df_test.columns:
                    total_rows = len(pd.read_csv(csv_file))
                    data_files.append((csv_file, total_rows))
            except:
                pass
        
        # 2. æŸ¥æ‰¾åŒ…å«price_currentçš„æ•°æ®æ–‡ä»¶ï¼ˆæœ€æ–°çš„trading_dataæ–‡ä»¶ï¼‰
        date_dirs = [d for d in os.listdir(self.data_dir) 
                     if os.path.isdir(os.path.join(self.data_dir, d)) and d.startswith('2026')]
        date_dirs.sort(reverse=True)
        
        for date_dir in date_dirs[:7]:  # æœ€è¿‘7å¤©
            date_path = os.path.join(self.data_dir, date_dir)
            csv_files = glob.glob(os.path.join(date_path, 'trading_data_*.csv'))
            for csv_file in csv_files:
                try:
                    df_test = pd.read_csv(csv_file, nrows=1)
                    if 'price_current' in df_test.columns:
                        total_rows = len(pd.read_csv(csv_file))
                        data_files.append((csv_file, total_rows))
                except:
                    pass
        
        # 3. æŸ¥æ‰¾å…¶ä»–è®­ç»ƒæ•°æ®æ–‡ä»¶ï¼ˆproductionç­‰ï¼‰
        if not data_files:
            for root, dirs, files in os.walk(self.data_dir):
                for file in files:
                    if file.endswith('.csv') and ('train' in file.lower() or 'trading_data' in file.lower()):
                        file_path = os.path.join(root, file)
                        try:
                            df_test = pd.read_csv(file_path, nrows=1)
                            if 'price_current' in df_test.columns or 'close' in df_test.columns:
                                data_files.append(file_path)
                        except:
                            pass
        
        if not data_files:
            print("âš ï¸ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶")
            return None
        
        # ä½¿ç”¨æ•°æ®é‡æœ€å¤§çš„æ–‡ä»¶ï¼ˆä¼˜å…ˆï¼‰æˆ–æœ€æ–°çš„æ–‡ä»¶
        if isinstance(data_files[0], tuple):
            # å¦‚æœdata_filesæ˜¯(æ–‡ä»¶è·¯å¾„, æ•°æ®é‡)çš„åˆ—è¡¨
            data_files.sort(key=lambda x: x[1], reverse=True)  # æŒ‰æ•°æ®é‡æ’åº
            latest_file = data_files[0][0]
            print(f"ğŸ“Š é€‰æ‹©æ•°æ®é‡æœ€å¤§çš„æ–‡ä»¶: {data_files[0][1]}æ¡æ•°æ®")
        else:
            # å¦‚æœdata_filesæ˜¯æ–‡ä»¶è·¯å¾„åˆ—è¡¨
            latest_file = max(data_files, key=os.path.getmtime)
        print(f"ğŸ“‚ åŠ è½½è®­ç»ƒæ•°æ®: {latest_file}")
        
        try:
            df = pd.read_csv(latest_file)
            print(f"âœ… åŠ è½½æˆåŠŸï¼Œå…±{len(df)}æ¡æ•°æ®")
            
            # å¦‚æœæ•°æ®ä½¿ç”¨'close'è€Œä¸æ˜¯'price_current'ï¼Œè¿›è¡Œè½¬æ¢
            if 'close' in df.columns and 'price_current' not in df.columns:
                df['price_current'] = df['close']
                print("ğŸ“ å·²å°†'close'åˆ—æ˜ å°„ä¸º'price_current'")
            
            # æ£€æŸ¥å¿…éœ€çš„åˆ—
            required_cols = ['price_current', 'atr', 'rsi_1m', 'rsi_5m']
            missing_cols = [col for col in required_cols if col not in df.columns]
            if missing_cols:
                print(f"âš ï¸ ç¼ºå°‘åˆ—: {missing_cols}ï¼Œå°†ä½¿ç”¨é»˜è®¤å€¼")
                for col in missing_cols:
                    if 'rsi' in col:
                        df[col] = 50.0
                    else:
                        df[col] = 0.0
            
            return df
        except Exception as e:
            print(f"âŒ åŠ è½½å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()
            return None
    
    def prepare_data_with_sequence(self, df, seq_length, look_ahead=10):
        """
        å‡†å¤‡å¸¦åºåˆ—çš„è®­ç»ƒæ•°æ®
        
        Args:
            df: åŸå§‹æ•°æ®æ¡†
            seq_length: åºåˆ—é•¿åº¦
            look_ahead: å‘å‰çœ‹çš„æ­¥æ•°ï¼ˆç”¨äºç”Ÿæˆæ ‡ç­¾ï¼‰
        
        Returns:
            X: åºåˆ—ç‰¹å¾ (n_samples, seq_length, 12)
            y: æ ‡ç­¾ (n_samples,)
        """
        X, y = [], []
        
        # éœ€è¦è‡³å°‘seq_length + look_aheadä¸ªæ•°æ®ç‚¹
        min_required = seq_length + look_ahead
        
        for i in range(min_required, len(df)):
            # ç”Ÿæˆæ ‡ç­¾ï¼ˆåŸºäºæœªæ¥look_aheadæ­¥çš„ç›ˆåˆ©ï¼‰
            current_price = df.iloc[i]['price_current']
            future_prices = df.iloc[i+1:i+look_ahead+1]['price_current'].values
            
            if len(future_prices) < look_ahead:
                continue  # å¦‚æœæœªæ¥æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è¿™ä¸ªæ ·æœ¬
            
            # å‡†å¤‡åºåˆ—ç‰¹å¾ï¼ˆåœ¨ç¡®è®¤æœ‰æœªæ¥æ•°æ®åå†å‡†å¤‡ï¼‰
            sequence = self.prepare_sequence_features(df, i, seq_length)
            X.append(sequence)
            
            max_future_price = max(future_prices)
            min_future_price = min(future_prices)
            
            buy_profit = (max_future_price - current_price) / current_price
            sell_profit = (current_price - min_future_price) / current_price
            
            profit_threshold = 0.005
            min_diff = 0.003
            
            if abs(buy_profit - sell_profit) >= min_diff:
                if buy_profit > sell_profit and buy_profit > profit_threshold:
                    label = 1  # ä¹°å…¥
                elif sell_profit > buy_profit and sell_profit > profit_threshold:
                    label = 2  # å–å‡º
                else:
                    label = 0  # æŒæœ‰
            else:
                label = 0  # æŒæœ‰
            
            y.append(label)
        
        return np.array(X, dtype=np.float32), np.array(y, dtype=np.int64)
    
    def train_and_evaluate(self, seq_length, X_train, y_train, X_val, y_val):
        """
        è®­ç»ƒå¹¶è¯„ä¼°æ¨¡å‹
        
        Args:
            seq_length: åºåˆ—é•¿åº¦
            X_train: è®­ç»ƒç‰¹å¾ (n_samples, seq_length, 12)
            y_train: è®­ç»ƒæ ‡ç­¾
            X_val: éªŒè¯ç‰¹å¾
            y_val: éªŒè¯æ ‡ç­¾
        
        Returns:
            results: è¯„ä¼°ç»“æœå­—å…¸
        """
        # åˆå§‹åŒ–æ¨¡å‹
        model = TradingLSTM(
            input_size=12,
            hidden_size=64,
            num_layers=2,
            output_size=3
        ).to(self.device)
        
        optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-5)
        criterion = nn.CrossEntropyLoss()
        
        # è½¬æ¢ä¸ºå¼ é‡
        X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(self.device)
        y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(self.device)
        X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(self.device)
        y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(self.device)
        
        # åˆ›å»ºæ•°æ®åŠ è½½å™¨
        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)
        val_dataset = TensorDataset(X_val_tensor, y_val_tensor)
        train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
        val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
        
        # è®­ç»ƒæ¨¡å‹ï¼ˆå¿«é€Ÿæµ‹è¯•æ¨¡å¼ï¼šå‡å°‘epochsï¼‰
        best_val_acc = 0.0
        best_val_loss = float('inf')
        no_improvement = 0
        max_epochs = 15  # å¢åŠ åˆ°15ä¸ªepochä»¥è·å¾—æ›´å¯é çš„ç»“æœ
        patience = 5  # å¢åŠ patience
        
        for epoch in range(max_epochs):
            # è®­ç»ƒé˜¶æ®µ
            model.train()
            train_loss = 0.0
            for batch_x, batch_y in train_loader:
                optimizer.zero_grad()
                outputs = model(batch_x)
                loss = criterion(outputs, batch_y)
                loss.backward()
                optimizer.step()
                train_loss += loss.item()
            
            # éªŒè¯é˜¶æ®µ
            model.eval()
            val_loss = 0.0
            correct = 0
            total = 0
            predictions = []
            
            with torch.no_grad():
                for batch_x, batch_y in val_loader:
                    outputs = model(batch_x)
                    loss = criterion(outputs, batch_y)
                    val_loss += loss.item()
                    
                    _, predicted = torch.max(outputs.data, 1)
                    total += batch_y.size(0)
                    correct += (predicted == batch_y).sum().item()
                    
                    predictions.extend(predicted.cpu().numpy())
            
            val_acc = correct / total if total > 0 else 0.0
            avg_val_loss = val_loss / len(val_loader)
            
            # æ—©åœ
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                best_val_loss = avg_val_loss
                no_improvement = 0
            else:
                no_improvement += 1
                if no_improvement >= patience:
                    break
        
        # è®¡ç®—é¢„æµ‹ç¨³å®šæ€§ï¼ˆæ–¹å·®ï¼‰
        prediction_variance = np.var(predictions) if len(predictions) > 0 else 0.0
        
        # è®¡ç®—ç»¼åˆè¯„åˆ†
        composite_score = self.calculate_composite_score({
            'accuracy': best_val_acc,
            'loss': best_val_loss,
            'prediction_variance': prediction_variance
        })
        
        return {
            'accuracy': best_val_acc,
            'loss': best_val_loss,
            'prediction_variance': prediction_variance,
            'composite_score': composite_score
        }
    
    def calculate_composite_score(self, results):
        """è®¡ç®—ç»¼åˆè¯„åˆ†"""
        accuracy_score = results['accuracy'] * 0.4
        loss_score = (1 - min(results['loss'], 1.0)) * 0.3
        stability_score = (1 - min(results['prediction_variance'] / 2.0, 1.0)) * 0.3
        
        composite_score = accuracy_score + loss_score + stability_score
        return composite_score
    
    def check_convergence(self):
        """æ£€æŸ¥æ˜¯å¦æ”¶æ•›"""
        if len(self.results) < self.convergence_window * 2:
            return False, None
        
        # ä½¿ç”¨ç»¼åˆè¯„åˆ†åˆ¤æ–­æ”¶æ•›
        recent_scores = [r['composite_score'] for r in self.results[-self.convergence_window:]]
        prev_scores = [r['composite_score'] for r in self.results[-self.convergence_window*2:-self.convergence_window]]
        
        recent_avg = np.mean(recent_scores)
        prev_avg = np.mean(prev_scores)
        
        relative_change = abs(recent_avg - prev_avg) / (abs(prev_avg) + 1e-8)
        
        is_converged = relative_change < self.convergence_threshold
        
        if is_converged:
            # æ‰¾åˆ°æ€§èƒ½æœ€é«˜çš„åºåˆ—é•¿åº¦
            best_result = max(self.results, key=lambda x: x['composite_score'])
            optimal_length = best_result['seq_length']
        else:
            optimal_length = None
        
        return is_converged, optimal_length
    
    def test_sequence_lengths(self):
        """æµ‹è¯•ä¸åŒåºåˆ—é•¿åº¦"""
        print("ğŸš€ å¼€å§‹åŠ¨æ€åºåˆ—é•¿åº¦æµ‹è¯•")
        print(f"æµ‹è¯•èŒƒå›´: {self.min_length} - {self.max_length}, æ­¥é•¿: {self.step}")
        print(f"æ”¶æ•›çª—å£: {self.convergence_window}, æ”¶æ•›é˜ˆå€¼: {self.convergence_threshold}")
        
        # åŠ è½½æ•°æ®
        df = self.load_training_data()
        if df is None:
            return None, None
        
        # æ£€æŸ¥æ•°æ®é‡æ˜¯å¦è¶³å¤Ÿ
        min_required = self.max_length + 20  # è‡³å°‘éœ€è¦max_length + 20ä¸ªæ•°æ®ç‚¹
        if len(df) < min_required:
            print(f"âš ï¸ æ•°æ®é‡ä¸è¶³: éœ€è¦è‡³å°‘{min_required}æ¡ï¼Œå®é™…{len(df)}æ¡")
            print("ğŸ’¡ å»ºè®®: ä½¿ç”¨å†å²Kçº¿æ•°æ®ç”Ÿæˆè®­ç»ƒæ•°æ®ï¼Œæˆ–æ”¶é›†æ›´å¤šæ•°æ®")
            return None, None
        
        # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›†
        split_idx = int(len(df) * 0.8)
        df_train = df.iloc[:split_idx].reset_index(drop=True)
        df_val = df.iloc[split_idx:].reset_index(drop=True)
        
        print(f"ğŸ“Š æ•°æ®åˆ†å‰²: è®­ç»ƒé›†{len(df_train)}æ¡, éªŒè¯é›†{len(df_val)}æ¡")
        
        seq_lengths = range(self.min_length, self.max_length + 1, self.step)
        
        for seq_len in seq_lengths:
            print(f"\n{'='*60}")
            print(f"æµ‹è¯•åºåˆ—é•¿åº¦: {seq_len}")
            print(f"{'='*60}")
            
            try:
                # å‡†å¤‡æ•°æ®
                print("ğŸ“Š å‡†å¤‡åºåˆ—æ•°æ®...")
                X_train, y_train = self.prepare_data_with_sequence(df_train, seq_len)
                X_val, y_val = self.prepare_data_with_sequence(df_val, seq_len)
                
                print(f"è®­ç»ƒé›†: {len(X_train)} æ ·æœ¬, éªŒè¯é›†: {len(X_val)} æ ·æœ¬")
                
                # è®­ç»ƒå¹¶è¯„ä¼°
                print("ğŸ”¬ è®­ç»ƒå’Œè¯„ä¼°æ¨¡å‹...")
                results = self.train_and_evaluate(seq_length=seq_len,
                                                  X_train=X_train, y_train=y_train,
                                                  X_val=X_val, y_val=y_val)
                
                # è®°å½•ç»“æœ
                result_record = {
                    'seq_length': seq_len,
                    'accuracy': results['accuracy'],
                    'loss': results['loss'],
                    'prediction_variance': results['prediction_variance'],
                    'composite_score': results['composite_score']
                }
                self.results.append(result_record)
                
                print(f"âœ… ç»“æœ: å‡†ç¡®ç‡={results['accuracy']:.4f}, "
                      f"æŸå¤±={results['loss']:.4f}, "
                      f"ç»¼åˆè¯„åˆ†={results['composite_score']:.4f}")
                
                # æ£€æŸ¥æ”¶æ•›
                is_converged, optimal_length = self.check_convergence()
                if is_converged and optimal_length:
                    print(f"\nğŸ¯ åºåˆ—é•¿åº¦æ”¶æ•›äº: {optimal_length}")
                    print(f"   æœ€ä½³ç»¼åˆè¯„åˆ†: {max(r['composite_score'] for r in self.results):.4f}")
                    break
                
            except Exception as e:
                print(f"âŒ æµ‹è¯•åºåˆ—é•¿åº¦ {seq_len} æ—¶å‡ºé”™: {e}")
                import traceback
                traceback.print_exc()
                continue
        
        # æ‰¾åˆ°æœ€ä¼˜é•¿åº¦
        if self.results:
            best_result = max(self.results, key=lambda x: x['composite_score'])
            optimal_length = best_result['seq_length']
            print(f"\nğŸ† æœ€ä¼˜åºåˆ—é•¿åº¦: {optimal_length}")
            print(f"   æœ€ä½³ç»¼åˆè¯„åˆ†: {best_result['composite_score']:.4f}")
            print(f"   å‡†ç¡®ç‡: {best_result['accuracy']:.4f}")
        else:
            optimal_length = None
        
        return self.results, optimal_length
    
    def plot_results(self, output_file=None):
        """ç»˜åˆ¶æµ‹è¯•ç»“æœ"""
        if not self.results:
            print("âš ï¸ æ²¡æœ‰ç»“æœå¯ç»˜åˆ¶")
            return
        
        seq_lengths = [r['seq_length'] for r in self.results]
        accuracies = [r['accuracy'] for r in self.results]
        composite_scores = [r['composite_score'] for r in self.results]
        
        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))
        
        # å‡†ç¡®ç‡å›¾
        ax1.plot(seq_lengths, accuracies, 'b-o', label='å‡†ç¡®ç‡')
        ax1.set_xlabel('åºåˆ—é•¿åº¦')
        ax1.set_ylabel('å‡†ç¡®ç‡')
        ax1.set_title('åºåˆ—é•¿åº¦ vs å‡†ç¡®ç‡')
        ax1.grid(True)
        ax1.legend()
        
        # ç»¼åˆè¯„åˆ†å›¾
        ax2.plot(seq_lengths, composite_scores, 'r-o', label='ç»¼åˆè¯„åˆ†')
        ax2.set_xlabel('åºåˆ—é•¿åº¦')
        ax2.set_ylabel('ç»¼åˆè¯„åˆ†')
        ax2.set_title('åºåˆ—é•¿åº¦ vs ç»¼åˆè¯„åˆ†')
        ax2.grid(True)
        ax2.legend()
        
        plt.tight_layout()
        
        if output_file:
            plt.savefig(output_file)
            print(f"ğŸ“Š å›¾è¡¨å·²ä¿å­˜åˆ°: {output_file}")
        else:
            plt.savefig(f'/home/cx/trading_data/sequence_length_test_{datetime.now().strftime("%Y%m%d_%H%M%S")}.png')
        
        plt.close()
    
    def save_results(self, output_file=None):
        """ä¿å­˜æµ‹è¯•ç»“æœ"""
        if not self.results:
            return
        
        if output_file is None:
            output_file = f'/home/cx/trading_data/sequence_length_test_{datetime.now().strftime("%Y%m%d_%H%M%S")}.json'
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        
        print(f"ğŸ’¾ ç»“æœå·²ä¿å­˜åˆ°: {output_file}")


def main():
    """ä¸»å‡½æ•°"""
    tester = SequenceLengthTester(
        data_dir='/home/cx/trading_data',
        min_length=10,
        max_length=500,
        step=20,
        convergence_window=5,
        convergence_threshold=0.01
    )
    
    results, optimal_length = tester.test_sequence_lengths()
    
    if results:
        tester.plot_results()
        tester.save_results()
        
        print("\n" + "="*60)
        print("ğŸ“Š æµ‹è¯•æ€»ç»“")
        print("="*60)
        print(f"æµ‹è¯•äº† {len(results)} ä¸ªä¸åŒçš„åºåˆ—é•¿åº¦")
        if optimal_length:
            print(f"æœ€ä¼˜åºåˆ—é•¿åº¦: {optimal_length}")
            best_result = max(results, key=lambda x: x['composite_score'])
            print(f"æœ€ä½³ç»¼åˆè¯„åˆ†: {best_result['composite_score']:.4f}")
            print(f"æœ€ä½³å‡†ç¡®ç‡: {best_result['accuracy']:.4f}")


if __name__ == "__main__":
    main()
