#!/usr/bin/env python3
"""åˆå¹¶è¿‘æœŸç™½é“¶æ•°æ®ï¼ˆå«æš´è·Œè¡Œæƒ…ï¼‰å¹¶è¿è¡Œé¢„å¤„ç†+è®­ç»ƒå‡†å¤‡"""
import sys
import os
import glob
import pandas as pd
from datetime import datetime
from pathlib import Path

sys.path.insert(0, '/home/cx/tigertrade')

def main():
    base = Path('/home/cx/trading_data')
    large_dir = base / 'large_dataset'
    out_merged = large_dir / f'full_merged_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'

    # 1. æ”¶é›†è¿‘æœŸæ¯æ—¥æ•°æ® (1æœˆ26æ—¥è‡³ä»Š)
    daily_dirs = sorted([d for d in base.iterdir() if d.is_dir() and d.name.startswith('2026-')])
    recent_dirs = [d for d in daily_dirs if d.name >= '2026-01-26']

    dfs = []
    for d in recent_dirs:
        for f in d.glob('trading_data_*.csv'):
            try:
                df = pd.read_csv(f)
                if 'timestamp' in df.columns and 'price_current' in df.columns and len(df) > 0:
                    dfs.append(df)
                    print(f"  âœ… {f.relative_to(base)}: {len(df)} æ¡")
            except Exception as e:
                print(f"  âš ï¸ {f.name}: {e}")

    if not dfs:
        print("âŒ æœªæ‰¾åˆ°è¿‘æœŸæ¯æ—¥æ•°æ®ï¼Œå°è¯•ä½¿ç”¨ large_dataset æœ€æ–° full_*.csv")
        full_files = sorted(large_dir.glob('full_*.csv'), key=lambda p: p.stat().st_mtime, reverse=True)
        if full_files:
            latest = full_files[0]
            print(f"  ä½¿ç”¨: {latest.name}")
            input_file = str(latest)
        else:
            print("âŒ æ— å¯ç”¨æ•°æ®")
            return 1
    else:
        merged = pd.concat(dfs, ignore_index=True)
        if 'timestamp' in merged.columns:
            merged['timestamp'] = pd.to_datetime(merged['timestamp'], errors='coerce')
            merged = merged.dropna(subset=['timestamp'])
            merged = merged.sort_values('timestamp').drop_duplicates(subset=['timestamp'], keep='last')
        merged.to_csv(out_merged, index=False)
        print(f"\nâœ… åˆå¹¶å®Œæˆ: {out_merged} ({len(merged)} æ¡)")
        input_file = str(out_merged)

    # 2. ä¸å†å² full_ åˆå¹¶ï¼ˆå»é‡ï¼‰
    hist_full = large_dir / 'full_20260121_100827.csv'
    if hist_full.exists() and input_file != str(hist_full):
        hist = pd.read_csv(hist_full)
        new_df = pd.read_csv(input_file)
        # ç»Ÿä¸€åˆ—ï¼šå–äº¤é›† + è¡¥å…¨
        common = [c for c in hist.columns if c in new_df.columns]
        for c in hist.columns:
            if c not in new_df.columns and c != 'Unnamed: 0':
                new_df[c] = None
        hist_sel = hist[[c for c in common if c in hist.columns]]
        new_sel = new_df[[c for c in common if c in new_df.columns]]
        combined = pd.concat([hist_sel, new_sel], ignore_index=True)
        if 'timestamp' in combined.columns:
            combined['timestamp'] = pd.to_datetime(combined['timestamp'], errors='coerce')
            combined = combined.dropna(subset=['timestamp'])
            combined = combined.sort_values('timestamp').drop_duplicates(subset=['timestamp'], keep='last')
        final_path = large_dir / f'full_with_recent_{datetime.now().strftime("%Y%m%d_%H%M%S")}.csv'
        combined.to_csv(final_path, index=False)
        print(f"âœ… ä¸å†å²åˆå¹¶: {final_path} ({len(combined)} æ¡)")
        input_file = str(final_path)

    # 3. è¿è¡Œæ•°æ®é¢„å¤„ç†
    print("\n" + "="*60)
    print("ğŸ”„ è¿è¡Œæ•°æ®é¢„å¤„ç†...")
    print("="*60)
    from scripts.data_preprocessing import TigerTradeDataProcessor, _ensure_sample_data
    # ä½¿ç”¨åˆå¹¶åçš„æ–‡ä»¶
    output_dir = '/home/cx/tigertrade/data/processed'
    processor = TigerTradeDataProcessor(input_file, output_dir)
    (processor
     .load_data()
     .clean_data()
     .add_technical_indicators()
     .add_custom_features()
     .create_target()
     .split_data(train_ratio=0.7, val_ratio=0.15)
     .save_data()
     .generate_report())

    print("\n" + "="*60)
    print("ğŸ‰ æ•°æ®å·²æ›´æ–°ï¼Œå¯ç”¨äºè®­ç»ƒ")
    print("="*60)
    return 0

if __name__ == '__main__':
    sys.exit(main())
