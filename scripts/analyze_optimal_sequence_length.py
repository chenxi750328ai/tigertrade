"""
åˆ†ææœ€ä¼˜åºåˆ—é•¿åº¦
æ ¹æ®æ•°æ®é‡å’Œå†å²æˆäº¤æƒ…å†µï¼ŒåŠ¨æ€ç¡®å®šåºåˆ—é•¿åº¦
"""
import pandas as pd
import numpy as np
import os
import glob
from datetime import datetime


def analyze_data_and_sequence_length(data_dir='/home/cx/trading_data'):
    """åˆ†ææ•°æ®é‡å’Œæœ€ä¼˜åºåˆ—é•¿åº¦"""
    print("="*70)
    print("åˆ†ææ•°æ®é‡å’Œæœ€ä¼˜åºåˆ—é•¿åº¦")
    print("="*70)
    
    # æŸ¥æ‰¾æœ€æ–°çš„åˆå¹¶æ•°æ®æ–‡ä»¶
    data_files = glob.glob(os.path.join(data_dir, 'training_data_multitimeframe_merged_*.csv'))
    if not data_files:
        print("âŒ æœªæ‰¾åˆ°è®­ç»ƒæ•°æ®æ–‡ä»¶")
        return None
    
    # ä½¿ç”¨æœ€æ–°çš„æ–‡ä»¶
    latest_file = max(data_files, key=os.path.getmtime)
    print(f"\nğŸ“Š ä½¿ç”¨æ•°æ®æ–‡ä»¶: {os.path.basename(latest_file)}")
    
    # åŠ è½½æ•°æ®
    try:
        df = pd.read_csv(latest_file)
        print(f"âœ… æ•°æ®åŠ è½½æˆåŠŸ")
    except Exception as e:
        print(f"âŒ æ•°æ®åŠ è½½å¤±è´¥: {e}")
        return None
    
    # åˆ†ææ•°æ®
    total_samples = len(df)
    print(f"\næ•°æ®ç»Ÿè®¡:")
    print(f"  æ€»æ ·æœ¬æ•°: {total_samples:,}")
    
    # æ£€æŸ¥æ—¶é—´æˆ³
    if 'timestamp' in df.columns:
        df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')
        df = df.dropna(subset=['timestamp']).sort_values('timestamp')
        
        time_span = (df['timestamp'].max() - df['timestamp'].min()).total_seconds() / 3600
        print(f"  æ—¶é—´è·¨åº¦: {time_span:.1f} å°æ—¶")
        
        # ä¼°ç®—æ—¶é—´é—´éš”ï¼ˆå‡è®¾æ•°æ®æ˜¯1åˆ†é’ŸKçº¿ï¼‰
        if len(df) > 1:
            time_diffs = df['timestamp'].diff().dropna()
            avg_interval_minutes = time_diffs.median().total_seconds() / 60
            print(f"  å¹³å‡æ—¶é—´é—´éš”: {avg_interval_minutes:.1f} åˆ†é’Ÿ")
    
    # åˆ†æä»·æ ¼å†å²æˆäº¤æƒ…å†µ
    if 'price_current' in df.columns:
        prices = df['price_current'].values
        
        # è®¡ç®—ä»·æ ¼å˜åŒ–çš„ç›¸å…³æ€§
        print(f"\nä»·æ ¼åˆ†æ:")
        print(f"  ä»·æ ¼èŒƒå›´: {prices.min():.2f} - {prices.max():.2f}")
        print(f"  ä»·æ ¼æ ‡å‡†å·®: {prices.std():.4f}")
        
        # è®¡ç®—è‡ªç›¸å…³ï¼ˆä»·æ ¼ä¸å†å²ä»·æ ¼çš„ç›¸å…³æ€§ï¼‰
        max_lag = min(500, len(prices) // 2)  # æœ€å¤šçœ‹500æ­¥
        autocorrelations = []
        
        for lag in range(1, min(100, max_lag), 10):  # æ¯10æ­¥é‡‡æ ·ä¸€æ¬¡
            if lag < len(prices):
                corr = np.corrcoef(prices[:-lag], prices[lag:])[0, 1]
                if not np.isnan(corr):
                    autocorrelations.append((lag, corr))
        
        if autocorrelations:
            print(f"\nä»·æ ¼è‡ªç›¸å…³åˆ†æï¼ˆæ»åæ­¥æ•° vs ç›¸å…³ç³»æ•°ï¼‰:")
            for lag, corr in autocorrelations[:10]:  # æ˜¾ç¤ºå‰10ä¸ª
                print(f"  æ»å {lag:3d} æ­¥: {corr:.4f}")
            
            # æ‰¾åˆ°ç›¸å…³æ€§ä»ç„¶è¾ƒé«˜çš„æœ€å¤§æ»å
            significant_lags = [lag for lag, corr in autocorrelations if abs(corr) > 0.1]
            if significant_lags:
                max_significant_lag = max(significant_lags)
                print(f"\n  ä»æœ‰æ˜¾è‘—ç›¸å…³æ€§ï¼ˆ|r|>0.1ï¼‰çš„æœ€å¤§æ»å: {max_significant_lag} æ­¥")
            else:
                max_significant_lag = 50
    
    # æ¨èåºåˆ—é•¿åº¦
    print(f"\n" + "="*70)
    print("åºåˆ—é•¿åº¦æ¨è")
    print("="*70)
    
    # åŸºäºæ•°æ®é‡çš„æ¨è
    if total_samples < 1000:
        recommended_seq_short = min(50, total_samples // 10)
        recommended_seq_long = min(100, total_samples // 5)
    elif total_samples < 10000:
        recommended_seq_short = 100
        recommended_seq_long = 200
    else:
        recommended_seq_short = 200
        recommended_seq_long = 500
    
    print(f"\nåŸºäºæ•°æ®é‡çš„æ¨è:")
    print(f"  ä¿å®ˆæ¨è: {recommended_seq_short} æ­¥")
    print(f"  æ¿€è¿›æ¨è: {recommended_seq_long} æ­¥")
    print(f"  æ•°æ®é‡/åºåˆ—é•¿åº¦æ¯”ä¾‹: {total_samples/recommended_seq_long:.1f}:1")
    
    # åŸºäºä»·æ ¼ç›¸å…³æ€§çš„æ¨è
    if 'price_current' in df.columns and autocorrelations:
        # æ‰¾åˆ°ç›¸å…³æ€§é™åˆ°0.1ä»¥ä¸‹çš„æ»å
        low_corr_lags = [lag for lag, corr in autocorrelations if abs(corr) < 0.1]
        if low_corr_lags:
            correlation_based_seq = min(low_corr_lags)
        else:
            correlation_based_seq = max_significant_lag if 'max_significant_lag' in locals() else 200
        
        print(f"\nåŸºäºä»·æ ¼ç›¸å…³æ€§çš„æ¨è:")
        print(f"  æ¨èåºåˆ—é•¿åº¦: {correlation_based_seq} æ­¥")
    
    # ç†è®ºåˆ†æï¼šè¦†ç›–æ‰€æœ‰å†å²æˆäº¤æƒ…å†µ
    print(f"\nç†è®ºåˆ†æï¼ˆè¦†ç›–æ‰€æœ‰å†å²æˆäº¤æƒ…å†µï¼‰:")
    print(f"  å¦‚æœè¦è¦†ç›–æ‰€æœ‰å†å²æˆäº¤æƒ…å†µï¼Œåºåˆ—é•¿åº¦åº”è¯¥ = æ€»æ ·æœ¬æ•°")
    print(f"  ä½†è¿™ä¼šå¯¼è‡´:")
    print(f"    - æ¯ä¸ªæ ·æœ¬éƒ½éœ€è¦ {total_samples} æ­¥å†å²")
    print(f"    - å®é™…å¯ç”¨æ ·æœ¬æ•°: {total_samples - total_samples} = 0")
    print(f"    - è¿™æ˜¯ä¸å¯è¡Œçš„")
    
    print(f"\n  æ›´åˆç†çš„æ–¹æ¡ˆ:")
    print(f"    - ä½¿ç”¨å°½å¯èƒ½é•¿çš„åºåˆ—ï¼Œä½†ä¸è¶…è¿‡æ•°æ®é‡çš„80%")
    print(f"    - æ¨èåºåˆ—é•¿åº¦: {int(total_samples * 0.8)} æ­¥")
    print(f"    - å®é™…å¯ç”¨æ ·æœ¬æ•°: {int(total_samples * 0.2)} ä¸ª")
    
    # åŠ¨æ€åºåˆ—é•¿åº¦ç­–ç•¥
    print(f"\n" + "="*70)
    print("åŠ¨æ€åºåˆ—é•¿åº¦ç­–ç•¥")
    print("="*70)
    
    print(f"\næ–¹æ¡ˆ1: å›ºå®šé•¿åºåˆ—ï¼ˆæ¨èç”¨äºå¤§æ¨¡å‹ï¼‰")
    print(f"  åºåˆ—é•¿åº¦: {recommended_seq_long} æ­¥")
    print(f"  ä¼˜åŠ¿: ç®€å•ï¼Œè¦†ç›–æ›´å¤šå†å²ä¿¡æ¯")
    print(f"  åŠ£åŠ¿: è®¡ç®—é‡å¤§ï¼Œå¯èƒ½è¿‡æ‹Ÿåˆ")
    
    print(f"\næ–¹æ¡ˆ2: è‡ªé€‚åº”åºåˆ—é•¿åº¦")
    print(f"  æ ¹æ®æ•°æ®é‡åŠ¨æ€è°ƒæ•´:")
    print(f"    - æ•°æ®é‡ < 5K: åºåˆ—é•¿åº¦ = æ•°æ®é‡ / 10")
    print(f"    - æ•°æ®é‡ 5K-20K: åºåˆ—é•¿åº¦ = 200-500")
    print(f"    - æ•°æ®é‡ > 20K: åºåˆ—é•¿åº¦ = 500-1000")
    
    print(f"\næ–¹æ¡ˆ3: åˆ†å±‚åºåˆ—é•¿åº¦ï¼ˆå¤šæ—¶é—´å°ºåº¦ï¼‰")
    print(f"  çŸ­æœŸåºåˆ—: 50-100 æ­¥ï¼ˆ1-2å°æ—¶ï¼‰")
    print(f"  ä¸­æœŸåºåˆ—: 200-500 æ­¥ï¼ˆ4-10å°æ—¶ï¼‰")
    print(f"  é•¿æœŸåºåˆ—: 1000+ æ­¥ï¼ˆ20+å°æ—¶ï¼‰")
    print(f"  æ¨¡å‹åŒæ—¶ä½¿ç”¨å¤šä¸ªåºåˆ—é•¿åº¦")
    
    return {
        'total_samples': total_samples,
        'recommended_seq_short': recommended_seq_short,
        'recommended_seq_long': recommended_seq_long,
        'max_sequence': int(total_samples * 0.8)
    }


if __name__ == '__main__':
    result = analyze_data_and_sequence_length()
    if result:
        print(f"\nâœ… åˆ†æå®Œæˆ")
        print(f"\nå»ºè®®ä½¿ç”¨çš„åºåˆ—é•¿åº¦: {result['recommended_seq_long']} æ­¥")
