#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯¼å‡º run/order_log.jsonl ä¸º CSV å¹¶ç”Ÿæˆåˆ†ææŠ¥å‘Šã€‚
è¯´æ˜ï¼šmode=mock è¡¨ç¤ºæ¨¡æ‹Ÿå•ï¼ˆæœªæäº¤è‡³è€è™åå°ï¼‰ï¼›mode=real ä¸” status=success è¡¨ç¤ºå·²æäº¤è‡³è€è™ï¼ˆDEMO/å®ç›˜è´¦æˆ·ï¼‰ï¼›mode=real ä¸” status=fail è¡¨ç¤º API æ‹’ç»ï¼Œä¸ä¼šå‡ºç°åœ¨åå°ã€‚

ç”¨æ³•:
  python scripts/export_order_log_and_analyze.py
  python scripts/export_order_log_and_analyze.py --out-dir docs/reports
"""
import json
import csv
import argparse
from pathlib import Path
from datetime import datetime
from collections import defaultdict

ROOT = Path(__file__).resolve().parents[1]
ORDER_LOG = ROOT / "run" / "order_log.jsonl"
DEFAULT_CSV = ROOT / "run" / "order_log_export.csv"
DEFAULT_REPORT = ROOT / "docs" / "reports"


def load_records(path):
    records = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                records.append(json.loads(line))
            except json.JSONDecodeError:
                continue
    return records


def export_csv(records, out_path):
    if not records:
        return
    fieldnames = [
        "ts", "side", "symbol", "source", "order_type", "qty", "price",
        "order_id", "status", "mode", "stop_loss", "take_profit", "reason", "error"
    ]
    with open(out_path, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=fieldnames, extrasaction="ignore")
        w.writeheader()
        for r in records:
            row = {k: r.get(k, "") for k in fieldnames}
            w.writerow(row)


def _date_from_ts(ts):
    """ä»æ—¶é—´æˆ³å–æ—¥æœŸ YYYY-MM-DDï¼Œä¾¿äºæŒ‰æ—¥ç»Ÿè®¡ã€‚"""
    if not ts:
        return ""
    s = str(ts).strip()
    if len(s) >= 10 and s[4] == "-" and s[7] == "-":
        return s[:10]
    try:
        dt = datetime.fromisoformat(s.replace("Z", "+00:00"))
        return dt.strftime("%Y-%m-%d")
    except Exception:
        return ""


def analyze(records):
    by_mode_status = defaultdict(int)
    by_source = defaultdict(int)
    real_errors = defaultdict(int)
    real_success_ts = []
    # æŒ‰æ—¥æœŸï¼šæ¯æ—¥çš„ (realæˆåŠŸ, realå¤±è´¥, mockæˆåŠŸ, æ€»æ¡æ•°)
    by_date = defaultdict(lambda: {"real_success": 0, "real_fail": 0, "mock_success": 0, "total": 0})
    for r in records:
        m = r.get("mode", "")
        s = r.get("status", "")
        by_mode_status[(m, s)] += 1
        by_source[r.get("source", "auto")] += 1
        day = _date_from_ts(r.get("ts", ""))
        if day:
            by_date[day]["total"] += 1
            if m == "real":
                if s == "success":
                    by_date[day]["real_success"] += 1
                else:
                    by_date[day]["real_fail"] += 1
            elif m == "mock" and s == "success":
                by_date[day]["mock_success"] += 1
        if m == "real":
            if s == "fail":
                err = (r.get("error") or "").strip() or "unknown"
                if len(err) > 80:
                    err = err[:77] + "..."
                real_errors[err] += 1
            else:
                real_success_ts.append(r.get("ts", ""))
    # æŒ‰æ—¥æœŸæ’åºï¼Œæœ€è¿‘åœ¨å‰
    by_date_sorted = dict(sorted(by_date.items(), reverse=True))
    return {
        "total": len(records),
        "by_mode_status": dict(by_mode_status),
        "by_source": dict(by_source),
        "by_date": by_date_sorted,
        "real_errors": dict(sorted(real_errors.items(), key=lambda x: -x[1])),
        "real_success_count": len(real_success_ts),
        "real_success_ts_sample": sorted(real_success_ts)[-10:] if real_success_ts else [],
    }


def write_report(records, stats, out_dir, report_name="order_log_analysis.md"):
    out_dir = Path(out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    path = out_dir / report_name

    lines = [
        "# è®¢å•æ—¥å¿—å¯¼å‡ºä¸åˆ†æ",
        "",
        f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"**æ•°æ®æº**: `run/order_log.jsonl`",
        f"**æ€»æ¡æ•°**: {stats['total']}",
        "",
        "## ä¸€ã€ç»“è®ºï¼ˆæ˜¯å¦ã€ŒçœŸçš„ã€åœ¨è€è™åå°ï¼‰",
        "",
        "| ç±»å‹ | å«ä¹‰ | æ˜¯å¦ä¼šåœ¨è€è™åå°å‡ºç° |",
        "|------|------|----------------------|",
        "| **mode=mock** | æ¨¡æ‹Ÿå•ï¼Œæœªè°ƒç”¨è€è™ API | **ä¸ä¼š** |",
        "| **mode=real, status=success** | å·²æˆåŠŸæäº¤è‡³è€è™ API | **ä¼š**ï¼ˆè¯·åœ¨è€è™ DEMO/å®ç›˜è´¦æˆ·å¯¹åº”æ—¶é—´ã€åˆçº¦ä¸‹æŸ¥è¯¢ï¼‰ |",
        "| **mode=real, status=fail** | è°ƒç”¨è€è™ API ä½†è¢«æ‹’ç»ï¼ˆå¦‚éäº¤æ˜“æ—¶æ®µã€è´¦æˆ·é™åˆ¶ï¼‰ | **ä¸ä¼š** |",
        "",
        "å› æ­¤ï¼šè‹¥åå°æŸ¥ä¸åˆ°è®¢å•ï¼Œè¯·å…ˆçœ‹ä¸‹æ–¹ç»Ÿè®¡ä¸­ **mode=real ä¸” status=success** çš„æ•°é‡ä¸æ—¶é—´ï¼›è‹¥å¤šä¸º mock æˆ– real å¤šä¸º failï¼Œåˆ™åå°æ— å¯¹åº”è®°å½•æ˜¯é¢„æœŸè¡Œä¸ºã€‚",
        "",
        "## äºŒã€ç»Ÿè®¡æ±‡æ€»",
        "",
    ]

    # æŒ‰ mode/status æ±‡æ€»
    lines.append("### æŒ‰ mode ä¸ status")
    lines.append("")
    for (m, s), cnt in sorted(stats["by_mode_status"].items(), key=lambda x: -x[1]):
        lines.append(f"- mode=**{m}**, status=**{s}**: {cnt} æ¡")
    lines.append("")

    lines.append("### æŒ‰ source")
    lines.append("")
    for src, cnt in sorted(stats["by_source"].items(), key=lambda x: -x[1]):
        lines.append(f"- source=**{src}**: {cnt} æ¡")
    lines.append("")

    # æŒ‰æ—¥æœŸç»Ÿè®¡ï¼šçœ‹æ¸…ã€Œ60 å¤šå•ã€ç­‰æ˜¯å“ªå¤©çš„
    by_date = stats.get("by_date") or {}
    if by_date:
        lines.append("### æŒ‰æ—¥æœŸï¼ˆè®¢å•æ•°ï¼‰")
        lines.append("")
        lines.append("| æ—¥æœŸ | æ€»æ¡æ•° | realæˆåŠŸï¼ˆä¼šå‡ºç°åœ¨è€è™ï¼‰ | realå¤±è´¥ | mockæˆåŠŸ |")
        lines.append("| --- | --- | --- | --- | --- |")
        for day, v in by_date.items():
            lines.append(f"| {day} | {v['total']} | {v['real_success']} | {v['real_fail']} | {v['mock_success']} |")
        lines.append("")
        lines.append("*æ”¶ç›Šç‡æŒ‰æ—¥ç»Ÿè®¡éœ€è€è™åå°æˆäº¤æ˜ç»†æˆ– API æ‹‰å–ï¼›æœ¬è¡¨ä»…è®¢å•æ¡æ•°æŒ‰æ—¥ã€‚*")
        lines.append("")

    if stats["real_errors"]:
        lines.append("### mode=real ä¸” status=fail çš„å…¸å‹é”™è¯¯ï¼ˆå‰ 15 æ¡ï¼‰")
        lines.append("")
        for err, cnt in list(stats["real_errors"].items())[:15]:
            lines.append(f"- `{err}`: {cnt} æ¬¡")
        lines.append("")

    if stats["real_success_ts_sample"]:
        lines.append("### mode=real ä¸” status=success æœ€è¿‘ 10 æ¡æ—¶é—´æˆ³ï¼ˆä¾›ä¸è€è™åå°æ ¸å¯¹ï¼‰")
        lines.append("")
        for ts in stats["real_success_ts_sample"]:
            lines.append(f"- {ts}")
        lines.append("")

    lines.append("## ä¸‰ã€è¯´æ˜")
    lines.append("")
    lines.append("- å®Œæ•´æ˜ç»†å·²å¯¼å‡ºä¸º CSVï¼š`run/order_log_export.csv`ï¼ˆæˆ–é€šè¿‡ `--csv` æŒ‡å®šè·¯å¾„ï¼‰ã€‚")
    lines.append("- DEMO è¿è¡Œï¼ˆ`tiger1 d moe`ï¼‰æ—¶ï¼šè‹¥ SDK åˆå§‹åŒ–æˆåŠŸåˆ™ä½¿ç”¨çœŸå® APIï¼ˆopenapicfg_demï¼‰ï¼Œè®¢å•ä¸º mode=realï¼›è‹¥åˆå§‹åŒ–å¤±è´¥åˆ™èµ°æ¨¡æ‹Ÿï¼Œè®¢å•ä¸º mode=mockã€‚")
    lines.append("- è€è™åå°è¯·ä½¿ç”¨ **DEMO è´¦æˆ·** å¯¹åº”è´¦æˆ·ä¸æ—¶é—´èŒƒå›´æŸ¥è¯¢ï¼›å®ç›˜è´¦æˆ·ä¸ DEMO è´¦æˆ·è®¢å•åˆ†ç¦»ã€‚")
    lines.append("")

    path.write_text("\n".join(lines), encoding="utf-8")
    return path


def write_order_execution_status(stats, docs_dir):
    """å†™å…¥ docs/order_execution_status.jsonï¼Œä¾›çŠ¶æ€é¡µå±•ç¤ºã€Œè®¢å•æ‰§è¡Œï¼šæˆåŠŸ/å¤±è´¥ï¼ˆå«APIè¢«æ‹’ï¼‰ã€ï¼›å¤±è´¥å¤šåˆ™æ— å®ç›˜æ”¶ç›Šç‡ã€‚"""
    docs_dir = Path(docs_dir)
    docs_dir.mkdir(parents=True, exist_ok=True)
    real_ok = stats.get("real_success_count", 0)
    real_fail = stats.get("by_mode_status", {}).get(("real", "fail"), 0)
    obj = {
        "real_success_count": real_ok,
        "real_fail_count": real_fail,
        "note": "æ”¶ç›Šç‡ä»…æ¥è‡ªè€è™åå°æˆäº¤ï¼›æ‰§è¡Œå¤±è´¥ï¼ˆå«APIè¢«æ‹’ï¼‰æ—¶æ— å®ç›˜æ”¶ç›Šç‡ã€‚",
        "updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }
    path = docs_dir / "order_execution_status.json"
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)
    return path


def main():
    ap = argparse.ArgumentParser(description="å¯¼å‡º order_log.jsonl ä¸º CSV å¹¶ç”Ÿæˆåˆ†ææŠ¥å‘Š")
    ap.add_argument("--file", type=Path, default=ORDER_LOG, help="order_log.jsonl è·¯å¾„")
    ap.add_argument("--csv", type=Path, default=DEFAULT_CSV, help="å¯¼å‡º CSV è·¯å¾„")
    ap.add_argument("--out-dir", type=Path, default=DEFAULT_REPORT, help="æŠ¥å‘Šè¾“å‡ºç›®å½•")
    ap.add_argument("--report-name", type=str, default="order_log_analysis.md", help="æŠ¥å‘Šæ–‡ä»¶å")
    ap.add_argument("--no-status-json", action="store_true", help="ä¸å†™å…¥ docs/order_execution_status.json")
    args = ap.parse_args()

    if not args.file.exists():
        print(f"ğŸ“­ æ–‡ä»¶ä¸å­˜åœ¨: {args.file}")
        return 1

    records = load_records(args.file)
    if not records:
        print("ğŸ“­ æ— æœ‰æ•ˆè®°å½•")
        return 0

    args.csv.parent.mkdir(parents=True, exist_ok=True)
    export_csv(records, args.csv)
    print(f"ğŸ“„ CSV å·²å¯¼å‡º: {args.csv} ({len(records)} æ¡)")

    stats = analyze(records)
    report_path = write_report(records, stats, args.out_dir, args.report_name)
    print(f"ğŸ“„ åˆ†ææŠ¥å‘Š: {report_path}")
    if not args.no_status_json:
        status_path = write_order_execution_status(stats, ROOT / "docs")
        print(f"ğŸ“„ è®¢å•æ‰§è¡ŒçŠ¶æ€: {status_path}")

    print("\n--- ç»Ÿè®¡æ‘˜è¦ ---")
    print(f"  total: {stats['total']}")
    for (m, s), cnt in sorted(stats["by_mode_status"].items(), key=lambda x: -x[1]):
        print(f"  mode={m}, status={s}: {cnt}")
    print(f"  real success æ¡æ•°ï¼ˆåº”å‡ºç°åœ¨è€è™åå°ï¼‰: {stats['real_success_count']}")
    return 0


if __name__ == "__main__":
    exit(main())
