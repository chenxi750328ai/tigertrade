#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
å¯¼å‡º run/order_log.jsonl ä¸º CSV å¹¶ç”Ÿæˆåˆ†ææŠ¥å‘Šã€‚
è¯´æ˜ï¼šmode=mock è¡¨ç¤ºæ¨¡æ‹Ÿå•ï¼ˆæœªæäº¤è‡³è€è™åå°ï¼‰ï¼›mode=real ä¸” status=success è¡¨ç¤ºå·²æäº¤è‡³è€è™ï¼ˆDEMO/å®ç›˜è´¦æˆ·ï¼‰ï¼›mode=real ä¸” status=fail è¡¨ç¤º API æ‹’ç»ï¼Œä¸ä¼šå‡ºç°åœ¨åå°ã€‚

ç”¨æ³•:
  python scripts/export_order_log_and_analyze.py
  python scripts/export_order_log_and_analyze.py --out-dir docs/reports
"""
import json
import csv
import argparse
from pathlib import Path
from datetime import datetime
from collections import defaultdict

ROOT = Path(__file__).resolve().parents[1]
ORDER_LOG = ROOT / "run" / "order_log.jsonl"
DEFAULT_CSV = ROOT / "run" / "order_log_export.csv"
DEFAULT_REPORT = ROOT / "docs" / "reports"
CONFIG_PATH = ROOT / "openapicfg_dem"


def load_records(path):
    records = []
    with open(path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            if not line:
                continue
            try:
                records.append(json.loads(line))
            except json.JSONDecodeError:
                continue
    return records


def export_csv(records, out_path):
    if not records:
        return
    fieldnames = [
        "ts", "side", "symbol", "source", "order_type", "qty", "price",
        "order_id", "status", "mode", "stop_loss", "take_profit", "reason", "error"
    ]
    with open(out_path, "w", newline="", encoding="utf-8") as f:
        w = csv.DictWriter(f, fieldnames=fieldnames, extrasaction="ignore")
        w.writeheader()
        for r in records:
            row = {k: r.get(k, "") for k in fieldnames}
            w.writerow(row)


def _date_from_ts(ts):
    """ä»æ—¶é—´æˆ³å–æ—¥æœŸ YYYY-MM-DDï¼Œä¾¿äºæŒ‰æ—¥ç»Ÿè®¡ã€‚"""
    if not ts:
        return ""
    s = str(ts).strip()
    if len(s) >= 10 and s[4] == "-" and s[7] == "-":
        return s[:10]
    try:
        dt = datetime.fromisoformat(s.replace("Z", "+00:00"))
        return dt.strftime("%Y-%m-%d")
    except Exception:
        return ""


def analyze(records):
    by_mode_status = defaultdict(int)
    by_source = defaultdict(int)
    real_errors = defaultdict(int)
    real_success_ts = []
    local_reject_count = 0
    api_reject_count = 0
    local_reject_keywords = ("ALLOW_REAL_TRADING", "æŒä»“ç¡¬é¡¶", "pos=", "order_idæ— æ•ˆ", "æ¥è‡ªmock", "æ¥è‡ªæµ‹è¯•")
    # æŒ‰æ—¥æœŸï¼šæ¯æ—¥çš„ (realæˆåŠŸ, realå¤±è´¥, mockæˆåŠŸ, æ€»æ¡æ•°)
    by_date = defaultdict(lambda: {"real_success": 0, "real_fail": 0, "mock_success": 0, "total": 0})
    for r in records:
        m = r.get("mode", "")
        s = r.get("status", "")
        by_mode_status[(m, s)] += 1
        by_source[r.get("source", "auto")] += 1
        day = _date_from_ts(r.get("ts", ""))
        if day:
            by_date[day]["total"] += 1
            if m == "real":
                if s == "success":
                    by_date[day]["real_success"] += 1
                else:
                    by_date[day]["real_fail"] += 1
            elif m == "mock" and s == "success":
                by_date[day]["mock_success"] += 1
        if m == "real":
            if s == "fail":
                err = (r.get("error") or "").strip() or "unknown"
                if len(err) > 80:
                    err = err[:77] + "..."
                real_errors[err] += 1
                # åŒºåˆ†ï¼šæœ¬åœ°é£æ§æ‹’ç» vs çœŸå® API è¢«æ‹’
                err_raw = r.get("error") or ""
                if any(kw in err_raw for kw in local_reject_keywords):
                    local_reject_count += 1
                else:
                    api_reject_count += 1
            else:
                real_success_ts.append(r.get("ts", ""))
    # real+success ä¸­åŒºåˆ†ï¼šorder_id ç–‘ä¼¼æµ‹è¯•/mockï¼ˆä¸è€è™å¯¹ä¸ä¸Šï¼‰vs å¯èƒ½ä¸ºçœŸå®å•ï¼ˆçº¯æ•°å­—ï¼‰
    real_success_likely_mock = 0
    real_success_likely_real = 0
    for r in records:
        if r.get("mode") != "real" or r.get("status") != "success":
            continue
        oid = str(r.get("order_id") or "").strip()
        if not oid:
            real_success_likely_mock += 1
            continue
        if "Mock" in oid or oid.startswith("TEST_") or oid == "TEST123" or oid.startswith("ORDER_"):
            real_success_likely_mock += 1
        elif oid.isdigit() and len(oid) >= 10:
            real_success_likely_real += 1
        else:
            real_success_likely_mock += 1
    by_date_sorted = dict(sorted(by_date.items(), reverse=True))
    return {
        "total": len(records),
        "by_mode_status": dict(by_mode_status),
        "by_source": dict(by_source),
        "by_date": by_date_sorted,
        "real_errors": dict(sorted(real_errors.items(), key=lambda x: -x[1])),
        "real_success_count": len(real_success_ts),
        "local_reject_count": local_reject_count,
        "api_reject_count": api_reject_count,
        "real_success_likely_mock": real_success_likely_mock,
        "real_success_likely_real": real_success_likely_real,
        "real_success_ts_sample": sorted(real_success_ts)[-10:] if real_success_ts else [],
    }


def write_report(records, stats, out_dir, report_name="order_log_analysis.md", with_backend=False):
    out_dir = Path(out_dir)
    out_dir.mkdir(parents=True, exist_ok=True)
    path = out_dir / report_name

    lines = [
        "# è®¢å•æ—¥å¿—å¯¼å‡ºä¸åˆ†æ",
        "",
        f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}",
        f"**æ•°æ®æº**: `run/order_log.jsonl`",
        f"**æ€»æ¡æ•°**: {stats['total']}",
        "",
        "## ä¸€ã€ç»“è®ºï¼ˆæ˜¯å¦ã€ŒçœŸçš„ã€åœ¨è€è™åå°ï¼‰",
        "",
        "| ç±»å‹ | å«ä¹‰ | æ˜¯å¦ä¼šåœ¨è€è™åå°å‡ºç° |",
        "|------|------|----------------------|",
        "| **mode=mock** | æ¨¡æ‹Ÿå•ï¼Œæœªè°ƒç”¨è€è™ API | **ä¸ä¼š** |",
        "| **mode=real, status=success** | order_log è®°å½•ï¼ˆæœ¬ç³»ç»Ÿè®¤ä¸ºå·²æäº¤ï¼‰ | **æœªå¿…ä¼š**ï¼šå«æµ‹è¯•/mock æ±¡æŸ“ï¼Œä¸è€è™åå°å¯¹ä¸ä¸Šæ˜¯å¸¸æ€ï¼Œ**æˆåŠŸæ•°ä»…ä»¥è€è™åå°ä¸ºå‡†** |",
        "| **mode=real, status=fail** | è°ƒç”¨è€è™ API ä½†è¢«æ‹’ç»ï¼ˆå¦‚éäº¤æ˜“æ—¶æ®µã€è´¦æˆ·é™åˆ¶ï¼‰ | **ä¸ä¼š** |",
        "",
        "å› æ­¤ï¼šè‹¥åå°æŸ¥ä¸åˆ°è®¢å•ï¼Œè¯·å…ˆçœ‹ä¸‹æ–¹ç»Ÿè®¡ä¸­ **mode=real ä¸” status=success** çš„æ•°é‡ä¸æ—¶é—´ï¼›è‹¥å¤šä¸º mock æˆ– real å¤šä¸º failï¼Œåˆ™åå°æ— å¯¹åº”è®°å½•æ˜¯é¢„æœŸè¡Œä¸ºã€‚",
        "",
    ]
    # è‹¥ real+success é‡Œå¤šæ•°ä¸º Mock/TEST ç­‰ï¼Œè¯´æ˜ä¸è€è™å¯¹ä¸ä¸Šçš„åŸå› 
    likely_mock = stats.get("real_success_likely_mock", 0)
    likely_real = stats.get("real_success_likely_real", 0)
    total_rs = stats.get("real_success_count", 0)
    if total_rs > 0 and likely_mock > 0:
        lines.append("**âš ï¸ å…³äºã€Œä¸è€è™åå°å¯¹ä¸ä¸Šã€**ï¼šå½“å‰ mode=real ä¸” status=success çš„æ¡æ•°ä¸­ï¼Œ**å¤šæ•° order_id ä¸º Mockã€TEST_ã€ORDER_ ç­‰**ï¼Œè¯´æ˜æ¥è‡ª**æµ‹è¯•æˆ– mock ç¯å¢ƒ**ï¼ˆå½“æ—¶æœªçœŸæ­£èµ°è€è™ APIï¼Œæˆ– API è¢« mock åæŠŠ mock è¿”å›å€¼å†™è¿›äº† order_logï¼‰ã€‚è¿™ç±»è®°å½•**ä¸æ˜¯è€è™çœŸå®æˆäº¤**ï¼Œä¸è€è™åå°å¯¹ä¸ä¸Šæ˜¯é¢„æœŸã€‚åªæœ‰ order_id ä¸º**çº¯æ•°å­—ä¸”è¾ƒé•¿**ï¼ˆè€è™è¿”å›æ ¼å¼ï¼‰çš„ï¼Œæ‰å¯èƒ½æ˜¯çœŸå®å•ã€‚è¯¦è§ä¸‹æ–¹ã€Œreal success ä¸­ï¼šç–‘ä¼¼æµ‹è¯•/mock ä¸å¯èƒ½çœŸå®å•ã€ã€‚")
        lines.append("")
    lines.append("## äºŒã€ç»Ÿè®¡æ±‡æ€»")
    lines.append("")

    # æŒ‰ mode/status æ±‡æ€»
    lines.append("### æŒ‰ mode ä¸ status")
    lines.append("")
    for (m, s), cnt in sorted(stats["by_mode_status"].items(), key=lambda x: -x[1]):
        lines.append(f"- mode=**{m}**, status=**{s}**: {cnt} æ¡")
    lines.append("")
    if total_rs > 0:
        lines.append("### mode=real ä¸” status=success ä¸­ï¼šç–‘ä¼¼æµ‹è¯•/mock ä¸å¯èƒ½çœŸå®å•")
        lines.append("")
        lines.append("| ç±»å‹ | æ¡æ•° | è¯´æ˜ |")
        lines.append("| --- | --- | --- |")
        lines.append(f"| ç–‘ä¼¼æµ‹è¯•/mockï¼ˆorder_id å« Mockã€TEST_ã€ORDER_ ç­‰ï¼‰ | {likely_mock} | æ¥è‡ªæµ‹è¯•æˆ– mock ç¯å¢ƒï¼Œ**éè€è™çœŸå®æˆäº¤**ï¼Œä¸è€è™åå°å¯¹ä¸ä¸Šæ˜¯é¢„æœŸã€‚ |")
        lines.append(f"| å¯èƒ½ä¸ºè€è™çœŸå®å•ï¼ˆorder_id ä¸ºçº¯æ•°å­—ï¼‰ | {likely_real} | **æœªä¸è€è™æ ¸å¯¹**ï¼Œå¯èƒ½å«æµ‹è¯•æ±¡æŸ“ï¼›çœŸå®æˆåŠŸæ•°ä»…ä»¥è€è™åå°ä¸ºå‡†ã€‚ |")
        lines.append("")
    lines.append("### æŒ‰ source")
    lines.append("")
    for src, cnt in sorted(stats["by_source"].items(), key=lambda x: -x[1]):
        lines.append(f"- source=**{src}**: {cnt} æ¡")
    lines.append("")

    # æŒ‰æ—¥æœŸç»Ÿè®¡ï¼šçœ‹æ¸…ã€Œ60 å¤šå•ã€ç­‰æ˜¯å“ªå¤©çš„
    by_date = stats.get("by_date") or {}
    if by_date:
        lines.append("### æŒ‰æ—¥æœŸï¼ˆè®¢å•æ•°ï¼‰")
        lines.append("")
        lines.append("| æ—¥æœŸ | æ€»æ¡æ•° | order_log è®°æˆåŠŸï¼ˆæœªæ ¸å¯¹ï¼‰ | realå¤±è´¥ | mockæˆåŠŸ |")
        lines.append("| --- | --- | --- | --- | --- |")
        for day, v in by_date.items():
            lines.append(f"| {day} | {v['total']} | {v['real_success']} | {v['real_fail']} | {v['mock_success']} |")
        lines.append("")
        lines.append("*æ”¶ç›Šç‡æŒ‰æ—¥ç»Ÿè®¡éœ€è€è™åå°æˆäº¤æ˜ç»†æˆ– API æ‹‰å–ï¼›æœ¬è¡¨ä»…è®¢å•æ¡æ•°æŒ‰æ—¥ã€‚*")
        lines.append("")

    # å¤±è´¥åˆ†ç±»ï¼šæœ¬åœ°é£æ§ vs API è¢«æ‹’
    local_reject = stats.get("local_reject_count", 0)
    api_reject = stats.get("api_reject_count", 0)
    if local_reject or api_reject:
        lines.append("### mode=real ä¸” status=fail åˆ†ç±»")
        lines.append("")
        lines.append(f"- **æœ¬åœ°é£æ§æ‹’ç»**ï¼ˆæœªå‘ APIï¼‰ï¼š{local_reject} æ¡ï¼ˆå¦‚ ALLOW_REAL_TRADINGã€æŒä»“ç¡¬é¡¶ï¼‰")
        lines.append(f"- **çœŸå® API è¢«æ‹’**ï¼ˆè€è™æ‹’ç»ï¼‰ï¼š{api_reject} æ¡ï¼ˆå¦‚ 1010/1200/account ä¸ºç©ºï¼‰")
        lines.append("")
    if stats["real_errors"]:
        lines.append("### mode=real ä¸” status=fail çš„å…¸å‹é”™è¯¯ï¼ˆå‰ 15 æ¡ï¼‰")
        lines.append("")
        for err, cnt in list(stats["real_errors"].items())[:15]:
            lines.append(f"- `{err}`: {cnt} æ¬¡")
        lines.append("")

    if stats["real_success_ts_sample"]:
        lines.append("### mode=real ä¸” status=success æœ€è¿‘ 10 æ¡æ—¶é—´æˆ³ï¼ˆä¾›ä¸è€è™åå°æ ¸å¯¹ï¼‰")
        lines.append("")
        for ts in stats["real_success_ts_sample"]:
            lines.append(f"- {ts}")
        lines.append("")

    if with_backend:
        backend_orders, match_map = _fetch_backend_orders_and_match(records)
        lines.append("## å››ã€åå°è®¢å•ä¸ order_logï¼ˆDFXï¼‰å¯¹ç…§")
        lines.append("")
        lines.append("ï¼ˆç”±æœ¬è„šæœ¬ `--with-backend` æ‹‰å–è€è™è®¢å•ï¼Œä¸ order_log æŒ‰ order_id å¯¹ï¼›å¯åˆ¤æ–­æ¯ç¬”åå°å•æ˜¯å¦æ¥è‡ªæœ¬æœº order_logã€‚ï¼‰")
        lines.append("")
        if not backend_orders:
            lines.append("æœªæ‹‰å–åˆ°åå°è®¢å•æˆ– openapicfg_dem ä¸å¯ç”¨ã€‚")
        else:
            lines.append("| åå° order_id | symbol | side | status | limit_price | order_log æ¡æ•° | order_log ts/source/error |")
            lines.append("|--------------|--------|------|--------|-------------|----------------|---------------------------|")
            for o in backend_orders[:50]:
                oid = getattr(o, "order_id", None) or getattr(o, "id", None)
                sym = getattr(o, "symbol", None) or getattr(getattr(o, "contract", None), "symbol", None)
                side = getattr(o, "side", None)
                st = getattr(o, "status", None)
                lp = getattr(o, "limit_price", None) or getattr(o, "price", None)
                log_rows = match_map.get(str(oid), [])
                log_info = ""
                if log_rows:
                    r0 = log_rows[0]
                    log_info = "ts=%s source=%s" % (r0.get("ts", "")[:19], r0.get("source", ""))
                    if r0.get("error"):
                        log_info += " error=%s" % (str(r0.get("error"))[:40])
                else:
                    log_info = "æ— ï¼ˆå¯èƒ½æ‰‹å·¥å•æˆ–åˆ«è¿›ç¨‹ï¼‰"
                lines.append("| %s | %s | %s | %s | %s | %s | %s |" % (oid, sym, side, st, lp, len(log_rows), log_info[:50]))
            if len(backend_orders) > 50:
                lines.append("| ... | å…± %s æ¡ï¼Œä»…åˆ—å‰ 50 |" % len(backend_orders))
        lines.append("")
        reason = _today_demo_zero_fill_reason(records, stats)
        lines.append("## äº”ã€DEMO ä»Šæ—¥ 0 æˆäº¤åŸå› ï¼ˆå®šä½ï¼‰")
        lines.append("")
        lines.append(reason)
        lines.append("")

    lines.append("## %sã€è¯´æ˜" % ("å…­" if with_backend else "ä¸‰"))
    lines.append("")
    lines.append("- å®Œæ•´æ˜ç»†å·²å¯¼å‡ºä¸º CSVï¼š`run/order_log_export.csv`ï¼ˆæˆ–é€šè¿‡ `--csv` æŒ‡å®šè·¯å¾„ï¼‰ã€‚")
    lines.append("- DEMO è¿è¡Œï¼ˆ`tiger1 d moe`ï¼‰æ—¶ï¼šè‹¥ SDK åˆå§‹åŒ–æˆåŠŸåˆ™ä½¿ç”¨çœŸå® APIï¼ˆopenapicfg_demï¼‰ï¼Œè®¢å•ä¸º mode=realï¼›è‹¥åˆå§‹åŒ–å¤±è´¥åˆ™èµ°æ¨¡æ‹Ÿï¼Œè®¢å•ä¸º mode=mockã€‚")
    lines.append("- è€è™åå°è¯·ä½¿ç”¨ **DEMO è´¦æˆ·** å¯¹åº”è´¦æˆ·ä¸æ—¶é—´èŒƒå›´æŸ¥è¯¢ï¼›å®ç›˜è´¦æˆ·ä¸ DEMO è´¦æˆ·è®¢å•åˆ†ç¦»ã€‚")
    lines.append("")

    path.write_text("\n".join(lines), encoding="utf-8")
    return path


def _fetch_backend_orders_and_match(records):
    """æ‹‰å–è€è™åå°è®¢å•ï¼Œä¸ order_log æŒ‰ order_id å¯¹ç…§ã€‚è¿”å› (backend_list, match_map)ã€‚"""
    try:
        from scripts.fetch_tiger_yield_for_demo import fetch_orders_from_tiger, _today_range_local
    except Exception:
        return [], {}
    if not CONFIG_PATH.exists():
        return [], {}
    account = None
    try:
        from tigeropen.tiger_open_config import TigerOpenClientConfig
        cfg = TigerOpenClientConfig(props_path=str(CONFIG_PATH))
        account = getattr(cfg, "account", None)
    except Exception:
        pass
    if not account:
        return [], {}
    start_time, end_time = _today_range_local()
    orders = []
    for sym in ("SIL2603", "SIL2605"):
        orders.extend(fetch_orders_from_tiger(account, sym, limit=300, start_time=start_time, end_time=end_time) or [])
    if not orders:
        for sym in ("SIL2603", "SIL2605"):
            orders.extend(fetch_orders_from_tiger(account, sym, limit=200) or [])
    seen = set()
    unique = []
    for o in orders:
        oid = getattr(o, "order_id", None) or getattr(o, "id", None)
        if oid is not None and oid not in seen:
            seen.add(oid)
            unique.append(o)
    log_by_oid = defaultdict(list)
    for r in records:
        oid = str(r.get("order_id") or "").strip()
        if oid:
            log_by_oid[oid].append(r)
    match_map = {}
    for o in unique:
        oid = str(getattr(o, "order_id", None) or getattr(o, "id", None) or "")
        match_map[oid] = log_by_oid.get(oid, [])
    return unique, match_map


def _today_demo_zero_fill_reason(records, stats):
    """æ ¹æ® order_log ä»Šæ—¥ç»Ÿè®¡ï¼Œç»™å‡º DEMO ä»Šæ—¥ 0 æˆäº¤åŸå› ï¼ˆå¯å®šä½åˆ° DFX/é£æ§ï¼‰ã€‚"""
    today = datetime.now().strftime("%Y-%m-%d")
    by_date = stats.get("by_date") or {}
    day = by_date.get(today, {})
    real_ok = day.get("real_success", 0)
    real_fail = day.get("real_fail", 0)
    total_today = day.get("total", 0)
    if total_today == 0:
        return "ä»Šæ—¥ order_log æ— ä»»ä½•è®°å½• â†’ DEMO æœªè¿è¡Œæˆ–æœªè§¦å‘ä¸‹å•ï¼ˆæ—  DFX æ—¥å¿—å¯å¯¹ï¼‰ã€‚"
    if real_ok == 0 and real_fail == 0:
        return "ä»Šæ—¥ä»…æœ‰ mock æˆåŠŸè®°å½•ï¼Œæ—  real å• â†’ DEMO æœªç”¨çœŸå® API ä¸‹å•ï¼ˆæˆ– SDK åˆå§‹åŒ–å¤±è´¥èµ° mockï¼‰ã€‚"
    if real_ok == 0 and real_fail > 0:
        today_errors = []
        for r in records:
            if _date_from_ts(r.get("ts")) != today or r.get("mode") != "real" or r.get("status") != "fail":
                continue
            today_errors.append((r.get("error") or "").strip() or "unknown")
        from collections import Counter
        top = Counter(today_errors).most_common(5)
        err_text = "; ".join("%s(%sæ¬¡)" % (e[:60], c) for e, c in top)
        return "ä»Šæ—¥æœ‰ real ä¸‹å•å°è¯•ä½†å…¨éƒ¨å¤±è´¥ â†’ åŸå› è§ DFX/order_log çš„ errorï¼š%sã€‚å¯æ®æ­¤å®šä½é£æ§æˆ– API æ‹’å•ã€‚" % (err_text or "â€”")
    if real_ok > 0:
        return "ä»Šæ—¥ order_log æœ‰ %s ç¬” real successï¼›è‹¥è€è™åå°ä»æ˜¾ç¤º 0 æˆäº¤ï¼Œå¯èƒ½ä¸ºæ—¶é—´/åˆçº¦è¿‡æ»¤æˆ– order_id éè€è™è¿”å›ï¼ˆè§ã€Œåå°è®¢å•ä¸ order_log å¯¹ç…§ã€ï¼‰ã€‚" % real_ok
    return "ä»Šæ—¥ç»Ÿè®¡æ— æ³•æ¨æ–­ï¼›è§ä¸Šæ–¹æŒ‰æ—¥æœŸä¸å¤±è´¥åŸå› ã€‚"


def _fetch_tiger_verified_count():
    """ä»è€è™åå°æ‹‰å–ä»Šæ—¥æˆäº¤æ•°ï¼Œä½œä¸ºå”¯ä¸€å¯ä¿¡çš„ã€ŒæˆåŠŸã€æ•°ã€‚order_log å«æµ‹è¯•æ±¡æŸ“ï¼Œä¸å¯ç”¨ã€‚"""
    try:
        r = __import__("subprocess").run(
            [__import__("sys").executable, str(ROOT / "scripts" / "fetch_tiger_yield_for_demo.py")],
            cwd=str(ROOT),
            capture_output=True,
            text=True,
            timeout=15,
        )
        if r.returncode != 0:
            return None
        data = __import__("json").loads(r.stdout.strip())
        return data.get("filled_count", 0) if data.get("is_today_only") else None
    except Exception:
        return None


def write_order_execution_status(stats, docs_dir):
    """å†™å…¥ docs/order_execution_status.jsonã€‚æˆåŠŸæ•°ä»…ä»¥è€è™åå°ä¸ºå‡†ï¼Œorder_log å«æµ‹è¯•æ±¡æŸ“ä¸å±•ç¤ºã€‚"""
    docs_dir = Path(docs_dir)
    docs_dir.mkdir(parents=True, exist_ok=True)
    # æˆåŠŸæ•°ï¼šåªä¿¡è€è™åå°ï¼Œorder_log çš„ 638 å«æµ‹è¯•/mock æ±¡æŸ“ï¼Œä¸å±•ç¤º
    tiger_ok = _fetch_tiger_verified_count()
    real_ok = tiger_ok if tiger_ok is not None else None  # None æ—¶å‰ç«¯æ˜¾ç¤º â€”
    real_fail = stats.get("by_mode_status", {}).get(("real", "fail"), 0)
    local_reject = stats.get("local_reject_count", 0)
    api_reject = stats.get("api_reject_count", 0)
    obj = {
        "real_success_count": real_ok,  # è€è™åå°ä»Šæ—¥æˆäº¤æ•°ï¼›None æ—¶å‰ç«¯æ˜¾ç¤º â€”
        "real_fail_count": real_fail,
        "local_reject_count": local_reject,
        "api_reject_count": api_reject,
        "note": "æˆåŠŸæ•°=è€è™åå°ä»Šæ—¥æˆäº¤ï¼›order_logå«æµ‹è¯•æ±¡æŸ“ä¸å±•ç¤ºï¼›å¤±è´¥=æœ¬åœ°é£æ§æˆ–APIè¢«æ‹’ã€‚",
        "updated": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
    }
    path = docs_dir / "order_execution_status.json"
    with open(path, "w", encoding="utf-8") as f:
        json.dump(obj, f, ensure_ascii=False, indent=2)
    return path


def main():
    ap = argparse.ArgumentParser(description="å¯¼å‡º order_log.jsonl ä¸º CSV å¹¶ç”Ÿæˆåˆ†ææŠ¥å‘Š")
    ap.add_argument("--file", type=Path, default=ORDER_LOG, help="order_log.jsonl è·¯å¾„")
    ap.add_argument("--csv", type=Path, default=DEFAULT_CSV, help="å¯¼å‡º CSV è·¯å¾„")
    ap.add_argument("--out-dir", type=Path, default=DEFAULT_REPORT, help="æŠ¥å‘Šè¾“å‡ºç›®å½•")
    ap.add_argument("--report-name", type=str, default="order_log_analysis.md", help="æŠ¥å‘Šæ–‡ä»¶å")
    ap.add_argument("--no-status-json", action="store_true", help="ä¸å†™å…¥ docs/order_execution_status.json")
    ap.add_argument("--with-backend", action="store_true", help="æ‹‰å–è€è™åå°è®¢å•å¹¶ä¸ order_log å¯¹ç…§ï¼Œå¹¶è¾“å‡º DEMO ä»Šæ—¥ 0 æˆäº¤åŸå› ")
    args = ap.parse_args()

    if not args.file.exists():
        print(f"ğŸ“­ æ–‡ä»¶ä¸å­˜åœ¨: {args.file}")
        return 1

    records = load_records(args.file)
    if not records:
        print("ğŸ“­ æ— æœ‰æ•ˆè®°å½•")
        return 0

    args.csv.parent.mkdir(parents=True, exist_ok=True)
    export_csv(records, args.csv)
    print(f"ğŸ“„ CSV å·²å¯¼å‡º: {args.csv} ({len(records)} æ¡)")

    stats = analyze(records)
    report_path = write_report(records, stats, args.out_dir, args.report_name, with_backend=args.with_backend)
    print(f"ğŸ“„ åˆ†ææŠ¥å‘Š: {report_path}")
    if not args.no_status_json:
        status_path = write_order_execution_status(stats, ROOT / "docs")
        print(f"ğŸ“„ è®¢å•æ‰§è¡ŒçŠ¶æ€: {status_path}")

    print("\n--- ç»Ÿè®¡æ‘˜è¦ ---")
    print(f"  total: {stats['total']}")
    for (m, s), cnt in sorted(stats["by_mode_status"].items(), key=lambda x: -x[1]):
        print(f"  mode={m}, status={s}: {cnt}")
    print(f"  è€è™åå°ä»Šæ—¥æˆäº¤ï¼ˆorder_execution_statusï¼‰: è§ docs/order_execution_status.json")
    return 0


if __name__ == "__main__":
    exit(main())
