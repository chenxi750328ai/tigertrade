#!/usr/bin/env python3
"""
æœ€ç»ˆæ•°æ®å‡†å¤‡è„šæœ¬ - ç”Ÿæˆç”¨äºè®­ç»ƒçš„é«˜è´¨é‡æ•°æ®é›†
"""

import pandas as pd
import numpy as np
import os
from datetime import datetime

def prepare_final_dataset():
    """å‡†å¤‡æœ€ç»ˆè®­ç»ƒæ•°æ®é›†"""
    print("=" * 80)
    print("ğŸ“¦ å‡†å¤‡æœ€ç»ˆè®­ç»ƒæ•°æ®")
    print("=" * 80)
    
    # è¯»å–ä¼˜åŒ–åçš„æ•°æ®
    input_file = '/home/cx/trading_data/enhanced/full_20260120_142504_optimized.csv'
    print(f"\nè¯»å–æ•°æ®: {input_file}")
    df = pd.read_csv(input_file, index_col=0)
    print(f"âœ… åŠ è½½ {len(df)} æ¡è®°å½•")
    
    # ä½¿ç”¨ç™¾åˆ†ä½æ•°ç­–ç•¥ï¼ˆæœ€å¹³è¡¡ï¼‰å’Œæ ‡å‡†å·®ç­–ç•¥
    print("\nä½¿ç”¨æ ‡æ³¨ç­–ç•¥:")
    print("  - ä¸»ç­–ç•¥: label_percentile (ç™¾åˆ†ä½æ•°)")
    print("  - å¤‡é€‰ç­–ç•¥: label_std (æ ‡å‡†å·®)")
    
    # é‡å‘½åä¸ºæ ‡å‡†çš„labelåˆ—
    df['label'] = df['label_percentile']  # ä½¿ç”¨ç™¾åˆ†ä½æ•°ä½œä¸ºé»˜è®¤æ ‡ç­¾
    
    # æ‰“å°æ ‡ç­¾åˆ†å¸ƒ
    print("\næ ‡ç­¾åˆ†å¸ƒ (ç™¾åˆ†ä½æ•°ç­–ç•¥):")
    label_counts = df['label'].value_counts().sort_index()
    for label, count in label_counts.items():
        label_name = {0: "æŒæœ‰", 1: "ä¹°å…¥", 2: "å–å‡º"}.get(label, "æœªçŸ¥")
        print(f"  {label_name} ({label}): {count} ({count/len(df)*100:.1f}%)")
    
    # åˆ’åˆ†æ•°æ®é›† - ä½¿ç”¨æ”¹è¿›çš„åˆ’åˆ†ç­–ç•¥
    print("\n=" * 80)
    print("åˆ’åˆ†æ•°æ®é›†...")
    
    # ç­–ç•¥ï¼šå‰70%è®­ç»ƒï¼Œä¸­é—´15%éªŒè¯ï¼Œæœ€å15%æµ‹è¯•
    # ä½†ä¸ºæ¯ä¸ªé›†åˆç¡®ä¿æ ‡ç­¾åˆ†å¸ƒ
    train_ratio, val_ratio, test_ratio = 0.7, 0.15, 0.15
    
    # æŒ‰æ—¶é—´é¡ºåºåˆ’åˆ†åŸºæœ¬é›†åˆ
    n = len(df)
    train_end = int(n * train_ratio)
    val_end = int(n * (train_ratio + val_ratio))
    
    train_df = df.iloc[:train_end].copy()
    val_df = df.iloc[train_end:val_end].copy()
    test_df = df.iloc[val_end:].copy()
    
    print(f"\næ•°æ®é›†å¤§å°:")
    print(f"  è®­ç»ƒé›†: {len(train_df)} æ¡")
    print(f"  éªŒè¯é›†: {len(val_df)} æ¡")
    print(f"  æµ‹è¯•é›†: {len(test_df)} æ¡")
    
    # æ‰“å°å„é›†çš„æ ‡ç­¾åˆ†å¸ƒ
    for name, data in [('è®­ç»ƒé›†', train_df), ('éªŒè¯é›†', val_df), ('æµ‹è¯•é›†', test_df)]:
        counts = data['label'].value_counts().sort_index()
        print(f"\n{name}æ ‡ç­¾åˆ†å¸ƒ:")
        for label, count in counts.items():
            label_name = {0: "æŒæœ‰", 1: "ä¹°å…¥", 2: "å–å‡º"}.get(label, "æœªçŸ¥")
            print(f"  {label_name}: {count} ({count/len(data)*100:.1f}%)")
    
    # ä¿å­˜æ•°æ®é›†
    output_dir = '/home/cx/trading_data/final'
    os.makedirs(output_dir, exist_ok=True)
    
    timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
    
    train_file = os.path.join(output_dir, f'train_{timestamp}.csv')
    val_file = os.path.join(output_dir, f'val_{timestamp}.csv')
    test_file = os.path.join(output_dir, f'test_{timestamp}.csv')
    
    train_df.to_csv(train_file, index=True)
    val_df.to_csv(val_file, index=True)
    test_df.to_csv(test_file, index=True)
    
    print("\n=" * 80)
    print("âœ… æ•°æ®é›†å·²ä¿å­˜:")
    print(f"  - è®­ç»ƒé›†: {train_file}")
    print(f"  - éªŒè¯é›†: {val_file}")
    print(f"  - æµ‹è¯•é›†: {test_file}")
    
    # ç”Ÿæˆæ•°æ®é›†ä¿¡æ¯æ–‡ä»¶
    info_file = os.path.join(output_dir, f'dataset_info_{timestamp}.txt')
    with open(info_file, 'w', encoding='utf-8') as f:
        f.write(f"æ•°æ®é›†ä¿¡æ¯\n")
        f.write(f"ç”Ÿæˆæ—¶é—´: {datetime.now()}\n\n")
        f.write(f"è®­ç»ƒé›†: {train_file}\n")
        f.write(f"  å¤§å°: {len(train_df)} æ¡\n")
        f.write(f"  æ ‡ç­¾åˆ†å¸ƒ: {dict(train_df['label'].value_counts())}\n\n")
        f.write(f"éªŒè¯é›†: {val_file}\n")
        f.write(f"  å¤§å°: {len(val_df)} æ¡\n")
        f.write(f"  æ ‡ç­¾åˆ†å¸ƒ: {dict(val_df['label'].value_counts())}\n\n")
        f.write(f"æµ‹è¯•é›†: {test_file}\n")
        f.write(f"  å¤§å°: {len(test_df)} æ¡\n")
        f.write(f"  æ ‡ç­¾åˆ†å¸ƒ: {dict(test_df['label'].value_counts())}\n\n")
        f.write(f"ç‰¹å¾åˆ— ({len(df.columns)}):\n")
        for col in df.columns:
            f.write(f"  - {col}\n")
    
    print(f"  - ä¿¡æ¯æ–‡ä»¶: {info_file}")
    
    return train_file, val_file, test_file


if __name__ == "__main__":
    prepare_final_dataset()
