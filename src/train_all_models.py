#!/usr/bin/env python3
"""
è®­ç»ƒæ‰€æœ‰æ¨¡å‹å¹¶æ¯”è¾ƒç»“æœ
"""

import sys
import os
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from datetime import datetime
import argparse
import json

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import TrainingConfig, FeatureConfig
from train_with_detailed_logging import TradingDataset, DetailedLogger, train_epoch, validate

# å¯¼å…¥æ‰€æœ‰ç­–ç•¥æ¨¡å‹
from strategies.llm_strategy import LLMTradingStrategy
from strategies.large_model_strategy import LargeModelStrategy
from strategies.huge_transformer_strategy import HugeTransformerStrategy
from strategies.enhanced_transformer_strategy import EnhancedTransformerStrategy
from strategies.rl_trading_strategy import RLTradingStrategy
from strategies.large_transformer_strategy import LargeTransformerStrategy
from strategies import model_comparison_strategy


def get_all_models():
    """è·å–æ‰€æœ‰å¯è®­ç»ƒçš„æ¨¡å‹"""
    models = {
        'LLMç­–ç•¥': LLMTradingStrategy,
        'å¤§æ¨¡å‹ç­–ç•¥': LargeModelStrategy,
        'è¶…å¤§Transformerç­–ç•¥': HugeTransformerStrategy,
        'å¢å¼ºå‹Transformerç­–ç•¥': EnhancedTransformerStrategy,
        'å¼ºåŒ–å­¦ä¹ ç­–ç•¥': RLTradingStrategy,
        'å¤§å‹Transformerç­–ç•¥': LargeTransformerStrategy,
        'æ¨¡å‹å¯¹æ¯”ç­–ç•¥': model_comparison_strategy.ModelComparisonStrategy,
    }
    return models


def train_single_model(model_name, model_class, train_loader, val_loader, device, logger, output_dir):
    """è®­ç»ƒå•ä¸ªæ¨¡å‹"""
    logger.log(f"\n{'='*80}")
    logger.log(f"ğŸš€ å¼€å§‹è®­ç»ƒ: {model_name}")
    logger.log(f"{'='*80}")
    
    try:
        # è·å–æ­£ç¡®çš„ç‰¹å¾æ•°é‡
        num_features = len(FeatureConfig.get_all_features())
        
        # åˆ›å»ºç­–ç•¥å®ä¾‹ï¼ˆä¼ é€’æ­£ç¡®çš„input_sizeï¼‰
        try:
            strategy = model_class(input_size=num_features)
        except TypeError:
            # å¦‚æœç­–ç•¥ç±»ä¸æ¥å—input_sizeå‚æ•°ï¼Œä½¿ç”¨é»˜è®¤æ„é€ 
            strategy = model_class()
        
        # æ£€æŸ¥æ˜¯å¦æ˜¯å¼ºåŒ–å­¦ä¹ ç­–ç•¥ï¼ˆéœ€è¦ç‰¹æ®Šè®­ç»ƒé€»è¾‘ï¼‰
        if model_name == 'å¼ºåŒ–å­¦ä¹ ç­–ç•¥':
            logger.log(f"âš ï¸ {model_name} éœ€è¦ç‰¹æ®Šçš„å¼ºåŒ–å­¦ä¹ è®­ç»ƒæµç¨‹ï¼Œå½“å‰è·³è¿‡")
            logger.log(f"ğŸ’¡ æç¤ºï¼šå¼ºåŒ–å­¦ä¹ ç­–ç•¥éœ€è¦ç¯å¢ƒäº¤äº’è®­ç»ƒï¼Œä¸é€‚åˆç›‘ç£å­¦ä¹ æµç¨‹")
            return None
        
        # è·å–å†…éƒ¨çš„PyTorchæ¨¡å‹
        if hasattr(strategy, 'model'):
            model = strategy.model
            model = model.to(device)
        elif hasattr(strategy, 'network'):
            # æŸäº›ç­–ç•¥ä½¿ç”¨networkå±æ€§
            model = strategy.network
            model = model.to(device)
        elif hasattr(strategy, 'lstm_model'):
            # ModelComparisonStrategyä½¿ç”¨lstm_modelä½œä¸ºä¸»æ¨¡å‹
            model = strategy.lstm_model
            model = model.to(device)
        elif hasattr(strategy, 'to'):
            # å¦‚æœç­–ç•¥æœ¬èº«å°±æ˜¯æ¨¡å‹
            model = strategy
            model = model.to(device)
        else:
            # ç­–ç•¥ä¸æ˜¯æ ‡å‡†æ¨¡å‹
            logger.log(f"âš ï¸ {model_name} æ²¡æœ‰å¯è®­ç»ƒçš„æ¨¡å‹ï¼Œè·³è¿‡æ ‡å‡†è®­ç»ƒæµç¨‹")
            return None
        
        # è®¾ç½®ä¼˜åŒ–å™¨å’ŒæŸå¤±å‡½æ•°
        optimizer = optim.Adam(model.parameters(), lr=TrainingConfig.LEARNING_RATE)
        criterion = nn.CrossEntropyLoss()
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, mode='max', factor=0.5, patience=TrainingConfig.PATIENCE // 2
        )
        
        # è®­ç»ƒ
        best_val_acc = 0
        patience_counter = 0
        results = {
            'model_name': model_name,
            'epochs': [],
            'best_val_acc': 0,
            'best_epoch': 0,
            'total_time': 0
        }
        
        start_time = time.time()
        
        for epoch in range(1, TrainingConfig.MAX_EPOCHS + 1):
            logger.log(f"\nEpoch {epoch}/{TrainingConfig.MAX_EPOCHS}")
            logger.log("-" * 80)
            
            # è®­ç»ƒ
            train_loss, train_acc = train_epoch(
                model, train_loader, criterion, optimizer, device, logger, epoch
            )
            
            # éªŒè¯
            val_loss, val_acc = validate(model, val_loader, criterion, device, logger, epoch)
            
            # å­¦ä¹ ç‡è°ƒåº¦
            scheduler.step(val_acc)
            current_lr = optimizer.param_groups[0]['lr']
            
            # è®°å½•ç»“æœ
            epoch_result = {
                'epoch': epoch,
                'train_loss': train_loss,
                'train_acc': train_acc,
                'val_loss': val_loss,
                'val_acc': val_acc,
                'lr': current_lr
            }
            results['epochs'].append(epoch_result)
            
            logger.log(f"Epoch {epoch} - Train: Loss={train_loss:.4f}, Acc={train_acc:.4f}")
            logger.log(f"Epoch {epoch} - Val: Loss={val_loss:.4f}, Acc={val_acc:.4f}")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                results['best_val_acc'] = best_val_acc
                results['best_epoch'] = epoch
                
                model_path = os.path.join(output_dir, f'{model_name}_best.pth')
                torch.save(model.state_dict(), model_path)
                logger.log(f"ğŸ† æ–°çš„æœ€ä½³å‡†ç¡®ç‡: {best_val_acc:.4f}, æ¨¡å‹å·²ä¿å­˜")
                patience_counter = 0
            else:
                patience_counter += 1
                
            # æ—©åœ
            if patience_counter >= TrainingConfig.PATIENCE:
                logger.log(f"â¹ï¸ æ—©åœè§¦å‘ï¼Œåœæ­¢è®­ç»ƒ")
                break
        
        total_time = time.time() - start_time
        results['total_time'] = total_time
        
        logger.log(f"\nâœ… {model_name} è®­ç»ƒå®Œæˆ!")
        logger.log(f"æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f} (Epoch {results['best_epoch']})")
        logger.log(f"è®­ç»ƒè€—æ—¶: {total_time:.2f}ç§’")
        
        return results
        
    except Exception as e:
        logger.log_error(f"âŒ {model_name} è®­ç»ƒå¤±è´¥: {e}", e)
        import traceback
        traceback.print_exc()
        return None


def main():
    """ä¸»å‡½æ•°"""
    parser = argparse.ArgumentParser(description='è®­ç»ƒæ‰€æœ‰æ¨¡å‹')
    parser.add_argument('--train-file', type=str, required=True, help='è®­ç»ƒæ•°æ®æ–‡ä»¶')
    parser.add_argument('--val-file', type=str, required=True, help='éªŒè¯æ•°æ®æ–‡ä»¶')
    parser.add_argument('--output-dir', type=str, default='/home/cx/trading_data/all_models', help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    # åˆ›å»ºè¾“å‡ºç›®å½•
    os.makedirs(args.output_dir, exist_ok=True)
    log_dir = os.path.join(args.output_dir, 'logs')
    os.makedirs(log_dir, exist_ok=True)
    
    # åˆ›å»ºæ—¥å¿—
    logger = DetailedLogger(log_dir)
    
    logger.log("="*80)
    logger.log("ğŸš€ å¼€å§‹è®­ç»ƒæ‰€æœ‰æ¨¡å‹")
    logger.log("="*80)
    
    # è®¾ç½®è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() and TrainingConfig.DEVICE == 'cuda' else 'cpu')
    logger.log(f"ä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ•°æ®
    logger.log(f"\nåŠ è½½æ•°æ®...")
    logger.log(f"è®­ç»ƒé›†: {args.train_file}")
    logger.log(f"éªŒè¯é›†: {args.val_file}")
    
    train_df = pd.read_csv(args.train_file, index_col=0)
    val_df = pd.read_csv(args.val_file, index_col=0)
    
    logger.log(f"è®­ç»ƒé›†å¤§å°: {len(train_df)}")
    logger.log(f"éªŒè¯é›†å¤§å°: {len(val_df)}")
    
    # å‡†å¤‡æ•°æ®é›†
    feature_cols = FeatureConfig.get_all_features()
    train_dataset = TradingDataset(train_df, feature_cols)
    val_dataset = TradingDataset(val_df, feature_cols)
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=TrainingConfig.BATCH_SIZE,
        shuffle=True
    )
    val_loader = DataLoader(
        val_dataset,
        batch_size=TrainingConfig.BATCH_SIZE,
        shuffle=False
    )
    
    # è·å–æ‰€æœ‰æ¨¡å‹
    all_models = get_all_models()
    logger.log(f"\næ‰¾åˆ° {len(all_models)} ä¸ªæ¨¡å‹:")
    for name in all_models.keys():
        logger.log(f"  - {name}")
    
    # è®­ç»ƒæ‰€æœ‰æ¨¡å‹
    all_results = []
    
    for model_name, model_class in all_models.items():
        result = train_single_model(
            model_name, 
            model_class, 
            train_loader, 
            val_loader, 
            device, 
            logger,
            args.output_dir
        )
        
        if result:
            all_results.append(result)
    
    # ä¿å­˜æ‰€æœ‰ç»“æœ
    results_file = os.path.join(args.output_dir, 'all_models_results.json')
    with open(results_file, 'w', encoding='utf-8') as f:
        json.dump(all_results, f, indent=2, ensure_ascii=False)
    
    logger.log(f"\n{'='*80}")
    logger.log("ğŸ“Š æ‰€æœ‰æ¨¡å‹è®­ç»ƒå®Œæˆï¼")
    logger.log(f"{'='*80}")
    
    # æ’åºå¹¶æ˜¾ç¤ºç»“æœ
    all_results.sort(key=lambda x: x['best_val_acc'], reverse=True)
    
    logger.log(f"\næ’åç»“æœ:")
    logger.log("-" * 80)
    for i, result in enumerate(all_results, 1):
        logger.log(f"{i}. {result['model_name']}: {result['best_val_acc']:.4f} (Epoch {result['best_epoch']}, {result['total_time']:.1f}s)")
    
    logger.log(f"\nç»“æœå·²ä¿å­˜åˆ°: {results_file}")


if __name__ == "__main__":
    main()
