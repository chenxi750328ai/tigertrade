#!/usr/bin/env python3
"""
å¸¦è¯¦ç»†è¿­ä»£æ—¥å¿—å’Œé”™è¯¯æ£€æµ‹çš„è®­ç»ƒè„šæœ¬
è§£å†³inplaceæ“ä½œé”™è¯¯å’Œå…¶ä»–PyTorché—®é¢˜
"""

import sys
import os
import time
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import numpy as np
from datetime import datetime
import argparse
import traceback as tb

# æ·»åŠ å½“å‰ç›®å½•åˆ°è·¯å¾„
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import TrainingConfig, FeatureConfig


# è®¾ç½®PyTorchä»¥æ£€æµ‹å¼‚å¸¸
torch.autograd.set_detect_anomaly(True)


class TradingDataset(Dataset):
    """äº¤æ˜“æ•°æ®é›†"""
    
    def __init__(self, dataframe, feature_cols, label_col='label'):
        self.features = dataframe[feature_cols].values.astype(np.float32)
        self.labels = dataframe[label_col].values.astype(np.int64)
        
        # æ ‡å‡†åŒ– - é¿å…inplaceæ“ä½œ
        self.mean = self.features.mean(axis=0)
        self.std = self.features.std(axis=0) + 1e-8
        self.features = (self.features - self.mean) / self.std
        
        # æ£€æŸ¥NaN
        if np.isnan(self.features).any():
            print("âš ï¸ è­¦å‘Šï¼šç‰¹å¾ä¸­å­˜åœ¨NaNå€¼ï¼Œå·²æ›¿æ¢ä¸º0")
            self.features = np.nan_to_num(self.features)
    
    def __len__(self):
        return len(self.labels)
    
    def __getitem__(self, idx):
        # è¿”å›æ–°å¼ é‡ï¼Œé¿å…inplaceæ“ä½œ
        return (
            torch.tensor(self.features[idx].copy()),
            torch.tensor(self.labels[idx])
        )


class ImprovedTransformer(nn.Module):
    """æ”¹è¿›çš„Transformeræ¨¡å‹ - é¿å…inplaceæ“ä½œ"""
    
    def __init__(self, input_dim, hidden_dim=128, num_heads=4, num_layers=2, 
                 num_classes=3, dropout=0.1):
        super(ImprovedTransformer, self).__init__()
        
        self.input_dim = input_dim
        self.hidden_dim = hidden_dim
        
        # è¾“å…¥åµŒå…¥
        self.embedding = nn.Linear(input_dim, hidden_dim)
        self.embedding_norm = nn.LayerNorm(hidden_dim)
        
        # Transformerç¼–ç å™¨
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=hidden_dim,
            nhead=num_heads,
            dim_feedforward=hidden_dim * 4,
            dropout=dropout,
            batch_first=True,
            norm_first=True  # ä½¿ç”¨Pre-LNï¼Œæ›´ç¨³å®š
        )
        # ç¦ç”¨nested tensoré¿å…è­¦å‘Š
        self.transformer = nn.TransformerEncoder(
            encoder_layer, 
            num_layers=num_layers,
            enable_nested_tensor=False
        )
        
        # åˆ†ç±»å¤´
        self.classifier = nn.Sequential(
            nn.Linear(hidden_dim, hidden_dim // 2),
            nn.LayerNorm(hidden_dim // 2),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(hidden_dim // 2, num_classes)
        )
        
        self._init_weights()
    
    def _init_weights(self):
        """åˆå§‹åŒ–æƒé‡"""
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
    
    def forward(self, x):
        """
        å‰å‘ä¼ æ’­ - é¿å…æ‰€æœ‰inplaceæ“ä½œ
        
        Args:
            x: (batch, features)
        
        Returns:
            (batch, num_classes)
        """
        # åµŒå…¥ - åˆ›å»ºæ–°å¼ é‡
        x = self.embedding(x)
        x = self.embedding_norm(x)
        
        # æ·»åŠ åºåˆ—ç»´åº¦
        x = x.unsqueeze(1)  # (batch, 1, hidden)
        
        # Transformerç¼–ç 
        x = self.transformer(x)  # (batch, 1, hidden)
        
        # ç§»é™¤åºåˆ—ç»´åº¦
        x = x.squeeze(1)  # (batch, hidden)
        
        # åˆ†ç±»
        x = self.classifier(x)  # (batch, num_classes)
        
        return x


class DetailedLogger:
    """è¯¦ç»†æ—¥å¿—è®°å½•å™¨"""
    
    def __init__(self, log_dir=None):
        """åˆå§‹åŒ–æ—¥å¿—è®°å½•å™¨"""
        if log_dir is None:
            log_dir = TrainingConfig.LOG_DIR
        
        self.log_dir = log_dir
        os.makedirs(log_dir, exist_ok=True)
        
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        self.log_file = os.path.join(log_dir, f'training_{timestamp}.log')
        self.metrics_file = os.path.join(log_dir, f'metrics_{timestamp}.csv')
        self.error_file = os.path.join(log_dir, f'errors_{timestamp}.log')
        
        # åˆå§‹åŒ–metricsæ–‡ä»¶
        with open(self.metrics_file, 'w') as f:
            f.write('epoch,batch,phase,loss,accuracy,lr,grad_norm,time\n')
        
        self.log("=" * 80)
        self.log("è®­ç»ƒæ—¥å¿—åˆå§‹åŒ–")
        self.log("=" * 80)
        self.log(f"æ—¥å¿—æ–‡ä»¶: {self.log_file}")
        self.log(f"æŒ‡æ ‡æ–‡ä»¶: {self.metrics_file}")
        self.log(f"é”™è¯¯æ–‡ä»¶: {self.error_file}")
        self.log("=" * 80)
    
    def log(self, message, level='INFO'):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S.%f')[:-3]
        log_message = f"[{timestamp}] [{level}] {message}"
        print(log_message)
        
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_message + '\n')
    
    def log_error(self, error_message, exception=None):
        """è®°å½•é”™è¯¯"""
        self.log(f"âŒ ERROR: {error_message}", level='ERROR')
        
        error_details = f"\n{'='*80}\n"
        error_details += f"[{datetime.now()}] ERROR\n"
        error_details += f"{'-'*80}\n"
        error_details += f"{error_message}\n"
        
        if exception:
            error_details += f"\n{tb.format_exc()}\n"
        
        error_details += f"{'='*80}\n"
        
        with open(self.error_file, 'a', encoding='utf-8') as f:
            f.write(error_details)
    
    def log_batch(self, epoch, batch, phase, loss, acc, lr, grad_norm, elapsed):
        """è®°å½•æ‰¹æ¬¡æŒ‡æ ‡"""
        with open(self.metrics_file, 'a') as f:
            f.write(f'{epoch},{batch},{phase},{loss:.6f},{acc:.4f},'
                   f'{lr:.8f},{grad_norm:.6f},{elapsed:.4f}\n')
    
    def log_iteration_details(self, epoch, batch, total_batches, loss, acc, lr, 
                             grad_norm, elapsed):
        """è®°å½•è¯¦ç»†çš„è¿­ä»£ä¿¡æ¯"""
        message = (f"Epoch {epoch:3d} | Batch {batch:4d}/{total_batches:4d} | "
                  f"Loss: {loss:.6f} | Acc: {acc:.4f} | "
                  f"LR: {lr:.8f} | GradNorm: {grad_norm:.6f} | "
                  f"Time: {elapsed*1000:.2f}ms")
        self.log(message)
    
    def log_gradient_stats(self, model):
        """è®°å½•æ¢¯åº¦ç»Ÿè®¡ä¿¡æ¯"""
        total_norm = 0.0
        max_grad = 0.0
        min_grad = float('inf')
        
        for name, param in model.named_parameters():
            if param.grad is not None:
                param_norm = param.grad.data.norm(2).item()
                total_norm += param_norm ** 2
                max_grad = max(max_grad, param.grad.abs().max().item())
                min_grad = min(min_grad, param.grad.abs().min().item())
        
        total_norm = total_norm ** 0.5
        
        self.log(f"  æ¢¯åº¦ç»Ÿè®¡: Norm={total_norm:.6f}, Max={max_grad:.6f}, Min={min_grad:.6f}")
        
        return total_norm
    
    def log_model_info(self, model):
        """è®°å½•æ¨¡å‹ä¿¡æ¯"""
        total_params = sum(p.numel() for p in model.parameters())
        trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        
        self.log("\n" + "=" * 80)
        self.log("æ¨¡å‹ä¿¡æ¯")
        self.log("=" * 80)
        self.log(f"æ€»å‚æ•°é‡: {total_params:,}")
        self.log(f"å¯è®­ç»ƒå‚æ•°: {trainable_params:,}")
        self.log(f"æ¨¡å‹æ¶æ„:\n{model}")
        self.log("=" * 80 + "\n")
    
    def check_tensors(self, batch_data, batch_labels, logger_prefix=""):
        """æ£€æŸ¥å¼ é‡æ˜¯å¦æœ‰é—®é¢˜"""
        issues = []
        
        # æ£€æŸ¥NaN
        if torch.isnan(batch_data).any():
            issues.append(f"{logger_prefix}è¾“å…¥æ•°æ®åŒ…å«NaN")
        if torch.isnan(batch_labels).any():
            issues.append(f"{logger_prefix}æ ‡ç­¾æ•°æ®åŒ…å«NaN")
        
        # æ£€æŸ¥Inf
        if torch.isinf(batch_data).any():
            issues.append(f"{logger_prefix}è¾“å…¥æ•°æ®åŒ…å«Inf")
        
        if issues:
            for issue in issues:
                self.log_error(issue)
            return False
        
        return True


def train_epoch(model, dataloader, criterion, optimizer, device, logger, epoch):
    """è®­ç»ƒä¸€ä¸ªepoch - å¸¦è¯¦ç»†æ—¥å¿—"""
    model.train()
    total_loss = 0
    correct = 0
    total = 0
    
    for batch_idx, (features, labels) in enumerate(dataloader):
        batch_start_time = time.time()
        
        try:
            # æ•°æ®ç§»åˆ°è®¾å¤‡
            features = features.to(device)
            labels = labels.to(device)
            
            # æ£€æŸ¥æ•°æ®
            if TrainingConfig.DEBUG_MODE:
                if not logger.check_tensors(features, labels, f"Batch {batch_idx}: "):
                    logger.log_error(f"Batch {batch_idx} æ•°æ®æ£€æŸ¥å¤±è´¥ï¼Œè·³è¿‡")
                    continue
            
            # å‰å‘ä¼ æ’­
            optimizer.zero_grad()
            
            try:
                # ä¸ºTransformeræ¨¡å‹æ·»åŠ seq_lenç»´åº¦
                if len(features.shape) == 2:
                    features = features.unsqueeze(1)  # (batch, features) -> (batch, 1, features)
                outputs = model(features)
            except RuntimeError as e:
                logger.log_error(f"å‰å‘ä¼ æ’­é”™è¯¯ (Batch {batch_idx}): {str(e)}", e)
                continue
            
            # è®¡ç®—æŸå¤±
            try:
                loss = criterion(outputs, labels)
            except RuntimeError as e:
                logger.log_error(f"æŸå¤±è®¡ç®—é”™è¯¯ (Batch {batch_idx}): {str(e)}", e)
                continue
            
            # æ£€æŸ¥æŸå¤±
            if torch.isnan(loss) or torch.isinf(loss):
                logger.log_error(f"Batch {batch_idx}: æŸå¤±ä¸ºNaNæˆ–Inf: {loss.item()}")
                continue
            
            # åå‘ä¼ æ’­
            try:
                loss.backward()
            except RuntimeError as e:
                logger.log_error(f"åå‘ä¼ æ’­é”™è¯¯ (Batch {batch_idx}): {str(e)}", e)
                logger.log_error("è¿™é€šå¸¸æ˜¯ç”±inplaceæ“ä½œå¼•èµ·çš„", e)
                continue
            
            # æ¢¯åº¦è£å‰ª
            if TrainingConfig.GRAD_CLIP > 0:
                grad_norm = torch.nn.utils.clip_grad_norm_(
                    model.parameters(), 
                    TrainingConfig.GRAD_CLIP
                )
            else:
                grad_norm = 0.0
            
            # æ£€æŸ¥æ¢¯åº¦
            if TrainingConfig.CHECK_GRADIENTS and batch_idx % 50 == 0:
                grad_norm_detailed = logger.log_gradient_stats(model)
            
            # ä¼˜åŒ–æ­¥éª¤
            try:
                optimizer.step()
            except RuntimeError as e:
                logger.log_error(f"ä¼˜åŒ–å™¨æ­¥éª¤é”™è¯¯ (Batch {batch_idx}): {str(e)}", e)
                continue
            
            # ç»Ÿè®¡
            total_loss += loss.item()
            _, predicted = outputs.max(1)
            correct += predicted.eq(labels).sum().item()
            total += labels.size(0)
            
            # æ‰¹æ¬¡è€—æ—¶
            batch_time = time.time() - batch_start_time
            
            # è®°å½•æ‰¹æ¬¡æŒ‡æ ‡
            batch_acc = 100. * predicted.eq(labels).sum().item() / labels.size(0)
            current_lr = optimizer.param_groups[0]['lr']
            logger.log_batch(epoch, batch_idx, 'train', loss.item(), 
                           batch_acc/100, current_lr, grad_norm, batch_time)
            
            # å®šæœŸæ‰“å°è¯¦ç»†ä¿¡æ¯
            if (batch_idx + 1) % TrainingConfig.LOG_INTERVAL == 0:
                logger.log_iteration_details(
                    epoch, batch_idx + 1, len(dataloader),
                    loss.item(), batch_acc/100, current_lr,
                    grad_norm, batch_time
                )
        
        except Exception as e:
            logger.log_error(f"Batch {batch_idx} å¤„ç†å¼‚å¸¸", e)
            continue
    
    if total > 0:
        return total_loss / len(dataloader), correct / total
    else:
        return 0.0, 0.0


def validate(model, dataloader, criterion, device, logger, epoch):
    """éªŒè¯æ¨¡å‹ - å¸¦è¯¦ç»†æ—¥å¿—"""
    model.eval()
    total_loss = 0
    correct = 0
    total = 0
    
    with torch.no_grad():
        for batch_idx, (features, labels) in enumerate(dataloader):
            batch_start_time = time.time()
            
            try:
                features, labels = features.to(device), labels.to(device)
                
                # ä¸ºTransformeræ¨¡å‹æ·»åŠ seq_lenç»´åº¦
                if len(features.shape) == 2:
                    features = features.unsqueeze(1)  # (batch, features) -> (batch, 1, features)
                    
                outputs = model(features)
                loss = criterion(outputs, labels)
                
                total_loss += loss.item()
                _, predicted = outputs.max(1)
                correct += predicted.eq(labels).sum().item()
                total += labels.size(0)
                
                batch_time = time.time() - batch_start_time
                batch_acc = 100. * predicted.eq(labels).sum().item() / labels.size(0)
                
                logger.log_batch(epoch, batch_idx, 'val', loss.item(),
                               batch_acc/100, 0.0, 0.0, batch_time)
            
            except Exception as e:
                logger.log_error(f"éªŒè¯Batch {batch_idx} å¤„ç†å¼‚å¸¸", e)
                continue
    
    if total > 0:
        return total_loss / len(dataloader), correct / total
    else:
        return 0.0, 0.0


def main():
    """ä¸»è®­ç»ƒæµç¨‹"""
    parser = argparse.ArgumentParser(description='å¸¦è¯¦ç»†æ—¥å¿—çš„æ¨¡å‹è®­ç»ƒ')
    parser.add_argument('--train-file', type=str, required=True, help='è®­ç»ƒæ•°æ®æ–‡ä»¶')
    parser.add_argument('--val-file', type=str, required=True, help='éªŒè¯æ•°æ®æ–‡ä»¶')
    parser.add_argument('--config-file', type=str, help='é…ç½®æ–‡ä»¶ï¼ˆå¯é€‰ï¼‰')
    
    args = parser.parse_args()
    
    # åˆå§‹åŒ–æ—¥å¿—
    logger = DetailedLogger()
    logger.log("=" * 80)
    logger.log("ğŸš€ å¼€å§‹è®­ç»ƒæµç¨‹ï¼ˆè¯¦ç»†æ—¥å¿—æ¨¡å¼ï¼‰")
    logger.log("=" * 80)
    
    # æ‰“å°é…ç½®
    TrainingConfig.print_config()
    FeatureConfig.print_config()
    
    try:
        # 1. åŠ è½½æ•°æ®
        logger.log("\næ­¥éª¤ 1: åŠ è½½æ•°æ®")
        logger.log(f"  è®­ç»ƒæ•°æ®: {args.train_file}")
        logger.log(f"  éªŒè¯æ•°æ®: {args.val_file}")
        
        train_df = pd.read_csv(args.train_file, index_col=0)
        val_df = pd.read_csv(args.val_file, index_col=0)
        
        logger.log(f"  è®­ç»ƒé›†å¤§å°: {len(train_df)}")
        logger.log(f"  éªŒè¯é›†å¤§å°: {len(val_df)}")
        
        # 2. å‡†å¤‡ç‰¹å¾
        logger.log("\næ­¥éª¤ 2: å‡†å¤‡ç‰¹å¾")
        feature_cols = FeatureConfig.get_selected_features()
        logger.log(f"  ä½¿ç”¨ {len(feature_cols)} ä¸ªç‰¹å¾")
        
        # æ£€æŸ¥ç‰¹å¾æ˜¯å¦å­˜åœ¨
        missing_features = [f for f in feature_cols if f not in train_df.columns]
        if missing_features:
            logger.log_error(f"ç¼ºå°‘ç‰¹å¾: {missing_features}")
            return
        
        # 3. åˆ›å»ºæ•°æ®é›†
        logger.log("\næ­¥éª¤ 3: åˆ›å»ºæ•°æ®åŠ è½½å™¨")
        train_dataset = TradingDataset(train_df, feature_cols, 'label')
        val_dataset = TradingDataset(val_df, feature_cols, 'label')
        
        train_loader = DataLoader(
            train_dataset, 
            batch_size=TrainingConfig.BATCH_SIZE,
            shuffle=True,
            num_workers=0,  # é¿å…å¤šè¿›ç¨‹é—®é¢˜
            pin_memory=True if TrainingConfig.DEVICE == 'cuda' else False
        )
        val_loader = DataLoader(
            val_dataset,
            batch_size=TrainingConfig.BATCH_SIZE,
            shuffle=False,
            num_workers=0,
            pin_memory=True if TrainingConfig.DEVICE == 'cuda' else False
        )
        
        logger.log(f"  è®­ç»ƒæ‰¹æ¬¡æ•°: {len(train_loader)}")
        logger.log(f"  éªŒè¯æ‰¹æ¬¡æ•°: {len(val_loader)}")
        
        # 4. åˆ›å»ºæ¨¡å‹
        logger.log("\næ­¥éª¤ 4: åˆ›å»ºæ¨¡å‹")
        device = torch.device(TrainingConfig.DEVICE if torch.cuda.is_available() else 'cpu')
        logger.log(f"  ä½¿ç”¨è®¾å¤‡: {device}")
        
        if device.type == 'cuda':
            logger.log(f"  GPU: {torch.cuda.get_device_name(0)}")
            logger.log(f"  æ˜¾å­˜: {torch.cuda.get_device_properties(0).total_memory / 1e9:.2f} GB")
        
        model = ImprovedTransformer(
            input_dim=len(feature_cols),
            hidden_dim=TrainingConfig.HIDDEN_DIM,
            num_heads=TrainingConfig.NUM_HEADS,
            num_layers=TrainingConfig.NUM_LAYERS,
            num_classes=3,
            dropout=TrainingConfig.DROPOUT
        ).to(device)
        
        logger.log_model_info(model)
        
        # 5. è®¾ç½®è®­ç»ƒå‚æ•°
        logger.log("æ­¥éª¤ 5: è®¾ç½®è®­ç»ƒå‚æ•°")
        
        # è®¡ç®—ç±»åˆ«æƒé‡
        label_counts = train_df['label'].value_counts().sort_index()
        total = len(train_df)
        weights = torch.tensor(
            [total / (len(label_counts) * count) for count in label_counts],
            dtype=torch.float32
        ).to(device)
        logger.log(f"  ç±»åˆ«æƒé‡: {weights.cpu().numpy()}")
        
        criterion = nn.CrossEntropyLoss(weight=weights)
        optimizer = optim.Adam(model.parameters(), lr=TrainingConfig.LEARNING_RATE)
        scheduler = optim.lr_scheduler.ReduceLROnPlateau(
            optimizer, 
            mode='min',
            patience=TrainingConfig.LR_PATIENCE,
            factor=TrainingConfig.LR_FACTOR,
            verbose=True
        )
        
        best_val_acc = 0
        best_model_path = os.path.join(TrainingConfig.MODEL_DIR, 'best_model.pth')
        os.makedirs(TrainingConfig.MODEL_DIR, exist_ok=True)
        
        patience_counter = 0
        
        # 6. è®­ç»ƒå¾ªç¯
        logger.log("\n" + "=" * 80)
        logger.log("æ­¥éª¤ 6: å¼€å§‹è®­ç»ƒ")
        logger.log("=" * 80 + "\n")
        
        for epoch in range(1, TrainingConfig.NUM_EPOCHS + 1):
            epoch_start_time = time.time()
            
            logger.log(f"\nEpoch {epoch}/{TrainingConfig.NUM_EPOCHS}")
            logger.log("-" * 80)
            
            # è®­ç»ƒ
            train_loss, train_acc = train_epoch(
                model, train_loader, criterion, optimizer, device, logger, epoch
            )
            
            # éªŒè¯
            val_loss, val_acc = validate(
                model, val_loader, criterion, device, logger, epoch
            )
            
            # å­¦ä¹ ç‡è°ƒæ•´
            scheduler.step(val_loss)
            current_lr = optimizer.param_groups[0]['lr']
            
            # è®¡ç®—è€—æ—¶
            elapsed_time = time.time() - epoch_start_time
            
            # æ±‡æ€»æ—¥å¿—
            logger.log(f"\nEpoch {epoch} æ€»ç»“:")
            logger.log(f"  è®­ç»ƒ - Loss: {train_loss:.6f}, Acc: {train_acc:.4f}")
            logger.log(f"  éªŒè¯ - Loss: {val_loss:.6f}, Acc: {val_acc:.4f}")
            logger.log(f"  å­¦ä¹ ç‡: {current_lr:.8f}")
            logger.log(f"  è€—æ—¶: {elapsed_time:.2f}s")
            
            # ä¿å­˜æœ€ä½³æ¨¡å‹
            if val_acc > best_val_acc:
                best_val_acc = val_acc
                patience_counter = 0
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'val_acc': val_acc,
                    'val_loss': val_loss,
                }, best_model_path)
                logger.log(f"  ğŸ† æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {val_acc:.4f}, æ¨¡å‹å·²ä¿å­˜")
            else:
                patience_counter += 1
                logger.log(f"  è€å¿ƒå€¼: {patience_counter}/{TrainingConfig.EARLY_STOP_PATIENCE}")
            
            # æ—©åœ
            if patience_counter >= TrainingConfig.EARLY_STOP_PATIENCE:
                logger.log(f"\nâ¹ï¸ æ—©åœè§¦å‘ï¼Œåœæ­¢è®­ç»ƒ")
                break
            
            # å®šæœŸä¿å­˜
            if epoch % TrainingConfig.SAVE_INTERVAL == 0:
                checkpoint_path = os.path.join(
                    TrainingConfig.MODEL_DIR, 
                    f'checkpoint_epoch_{epoch}.pth'
                )
                torch.save({
                    'epoch': epoch,
                    'model_state_dict': model.state_dict(),
                    'optimizer_state_dict': optimizer.state_dict(),
                    'val_acc': val_acc,
                    'val_loss': val_loss,
                }, checkpoint_path)
                logger.log(f"  ğŸ’¾ Checkpointå·²ä¿å­˜: {checkpoint_path}")
        
        # 7. è®­ç»ƒå®Œæˆ
        logger.log("\n" + "=" * 80)
        logger.log("âœ… è®­ç»ƒå®Œæˆï¼")
        logger.log("=" * 80)
        logger.log(f"\næœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.4f}")
        logger.log(f"æœ€ä½³æ¨¡å‹: {best_model_path}")
        logger.log(f"\næ—¥å¿—æ–‡ä»¶:")
        logger.log(f"  - è®­ç»ƒæ—¥å¿—: {logger.log_file}")
        logger.log(f"  - æŒ‡æ ‡CSV: {logger.metrics_file}")
        logger.log(f"  - é”™è¯¯æ—¥å¿—: {logger.error_file}")
    
    except Exception as e:
        logger.log_error("è®­ç»ƒè¿‡ç¨‹å‡ºç°å¼‚å¸¸", e)
        raise


if __name__ == "__main__":
    main()
