"""
MoE Transformeräº¤æ˜“ç­–ç•¥
ä½¿ç”¨æœ€ä½³æ¨¡å‹ï¼ˆMoE Transformerï¼‰è¿›è¡Œäº¤æ˜“é¢„æµ‹
"""
import torch
import torch.nn as nn
import numpy as np
import pandas as pd
import os
import threading
from typing import Tuple, Optional, Dict, Any
import sys
sys.path.insert(0, '/home/cx/tigertrade')

from src.strategies.moe_transformer import MoETradingTransformerWithProfit
from src.strategies.llm_strategy import LLMTradingStrategy
from src.strategies.base_strategy import BaseTradingStrategy


class MoETradingStrategy(BaseTradingStrategy):
    """MoE Transformeräº¤æ˜“ç­–ç•¥ï¼ˆåŸºäºLLMTradingStrategyï¼Œä½†ä½¿ç”¨MoE Transformeræ¨¡å‹ï¼‰"""
    
    def __init__(self, data_dir='/home/cx/trading_data', model_path=None, seq_length=500):
        """
        åˆå§‹åŒ–MoE Transformeräº¤æ˜“ç­–ç•¥
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            model_path: æ¨¡å‹è·¯å¾„ï¼ˆé»˜è®¤ä½¿ç”¨æœ€ä½³MoEæ¨¡å‹ï¼‰
            seq_length: åºåˆ—é•¿åº¦ï¼ˆé»˜è®¤500ï¼Œä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰
        """
        # æ£€æŸ¥GPUå¯ç”¨æ€§
        if torch.cuda.is_available():
            self.device = torch.device('cuda')
            print(f"Using device: {self.device}")
        else:
            self.device = torch.device('cpu')
            print(f"Using device: {self.device}")
        
        self.data_dir = data_dir
        self._seq_length = seq_length
        self._historical_data = None
        
        # åˆå§‹åŒ–MoE Transformeræ¨¡å‹ï¼ˆéœ€è¦å…ˆæ£€æŸ¥ä¿å­˜çš„æ¨¡å‹é…ç½®ï¼‰
        input_size = 46  # å¤šæ—¶é—´å°ºåº¦ç‰¹å¾ç»´åº¦
        
        # å°è¯•åŠ è½½æ¨¡å‹ä»¥è·å–é…ç½®
        model_config = {
            'input_size': input_size,
            'nhead': 8,
            'num_layers': 8,  # ä»é”™è¯¯ä¿¡æ¯çœ‹æ˜¯8å±‚
            'output_size': 3,
            'd_model': 512,  # ä»é”™è¯¯ä¿¡æ¯çœ‹æ˜¯512
            'predict_profit': True,
            'num_experts': 8,  # ä»é”™è¯¯ä¿¡æ¯çœ‹æ˜¯8ä¸ªä¸“å®¶
            'top_k': 2,
            'window_size': 20,
            'attention_dropout_rate': 0.1
        }
        
        # å¦‚æœæä¾›äº†æ¨¡å‹è·¯å¾„ï¼Œå°è¯•è¯»å–é…ç½®
        if model_path is None:
            model_path = os.path.join(data_dir, 'best_moe_transformer.pth')
        
        if os.path.exists(model_path):
            try:
                checkpoint = torch.load(model_path, map_location='cpu', weights_only=False)
                if isinstance(checkpoint, dict):
                    state_dict = checkpoint.get('model_state_dict', checkpoint)
                else:
                    state_dict = checkpoint
                
                # ä»state_dictæ¨æ–­é…ç½®
                if 'input_projection.weight' in state_dict:
                    model_config['d_model'] = state_dict['input_projection.weight'].shape[0]
                if 'transformer.0.moe.gate.weight' in state_dict:
                    model_config['num_experts'] = state_dict['transformer.0.moe.gate.weight'].shape[0]
                # è®¡ç®—å±‚æ•°
                layer_keys = [k for k in state_dict.keys() if k.startswith('transformer.') and '.' in k]
                if layer_keys:
                    max_layer = max([int(k.split('.')[1]) for k in layer_keys if k.split('.')[1].isdigit()])
                    model_config['num_layers'] = max_layer + 1
                
                print(f"ğŸ“Š ä»æ¨¡å‹æ–‡ä»¶æ¨æ–­é…ç½®: d_model={model_config['d_model']}, num_layers={model_config['num_layers']}, num_experts={model_config['num_experts']}")
            except Exception as e:
                print(f"âš ï¸ æ— æ³•è¯»å–æ¨¡å‹é…ç½®ï¼Œä½¿ç”¨é»˜è®¤é…ç½®: {e}")
        
        self.model = MoETradingTransformerWithProfit(
            input_size=model_config['input_size'],
            nhead=model_config['nhead'],
            num_layers=model_config['num_layers'],
            output_size=model_config['output_size'],
            d_model=model_config['d_model'],
            predict_profit=model_config['predict_profit'],
            num_experts=model_config['num_experts'],
            top_k=model_config['top_k'],
            window_size=model_config['window_size'],
            attention_dropout_rate=model_config['attention_dropout_rate']
        ).to(self.device)
        
        # æ¨¡å‹é”
        self.model_lock = threading.Lock()
        
        # åŠ è½½æ¨¡å‹
        if model_path is None:
            model_path = os.path.join(data_dir, 'best_moe_transformer.pth')
        
        if os.path.exists(model_path):
            try:
                checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
                # å¤„ç†ä¸åŒçš„checkpointæ ¼å¼
                if isinstance(checkpoint, dict):
                    if 'model_state_dict' in checkpoint:
                        self.model.load_state_dict(checkpoint['model_state_dict'])
                    else:
                        self.model.load_state_dict(checkpoint)
                else:
                    self.model.load_state_dict(checkpoint)
                print(f"âœ… ä» {model_path} åŠ è½½MoE Transformeræ¨¡å‹æˆåŠŸ")
            except Exception as e:
                print(f"âŒ åŠ è½½MoE Transformeræ¨¡å‹å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
        else:
            print(f"âš ï¸ æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}ï¼Œä½¿ç”¨åˆå§‹æ¨¡å‹")
    
    @property
    def seq_length(self) -> int:
        """è¿”å›ç­–ç•¥éœ€è¦çš„åºåˆ—é•¿åº¦"""
        return self._seq_length
    
    @property
    def strategy_name(self) -> str:
        """è¿”å›ç­–ç•¥åç§°"""
        return "MoE Transformer"
    
    def prepare_features(self, row):
        """å‡†å¤‡ç‰¹å¾ï¼ˆä¸LLMTradingStrategyä¸€è‡´ï¼‰"""
        # ä½¿ç”¨LLMTradingStrategyçš„ç‰¹å¾å‡†å¤‡é€»è¾‘
        base_strategy = LLMTradingStrategy(mode='hybrid', predict_profit=True)
        return base_strategy.prepare_features(row)
    
    def prepare_sequence_features(self, df, current_idx, seq_length):
        """å‡†å¤‡å†å²åºåˆ—ç‰¹å¾"""
        start_idx = max(0, current_idx - seq_length + 1)
        sequence_df = df.iloc[start_idx:current_idx+1]
        
        sequences = []
        for _, row in sequence_df.iterrows():
            features = self.prepare_features(row)
            sequences.append(features)
        
        # å¦‚æœåºåˆ—ä¸è¶³seq_lengthï¼Œç”¨ç¬¬ä¸€ä¸ªå€¼å¡«å……
        feature_size = 46
        while len(sequences) < seq_length:
            if sequences:
                sequences.insert(0, sequences[0])
            else:
                sequences.insert(0, [0.0] * feature_size)
        
        return np.array(sequences, dtype=np.float32)
    
    def predict_action(self, current_data: Dict[str, Any], historical_data: Optional[pd.DataFrame] = None) -> Tuple[int, float, Optional[float]]:
        """
        ä½¿ç”¨MoE Transformeræ¨¡å‹é¢„æµ‹äº¤æ˜“åŠ¨ä½œ
        
        Args:
            current_data: å½“å‰æ•°æ®å­—å…¸
            historical_data: å†å²æ•°æ®DataFrameï¼ˆå¯é€‰ï¼‰
        
        Returns:
            (action, confidence, profit_prediction)
            - action: 0=ä¸æ“ä½œ, 1=ä¹°å…¥, 2=å–å‡º
            - confidence: ç½®ä¿¡åº¦ [0, 1]
            - profit_prediction: é¢„æµ‹æ”¶ç›Šç‡ï¼ˆå¯é€‰ï¼‰
        """
        with self.model_lock:
            try:
                # å‡†å¤‡åºåˆ—æ•°æ®
                if historical_data is not None and len(historical_data) >= self._seq_length:
                    # ä½¿ç”¨å†å²æ•°æ®æ„å»ºåºåˆ—
                    sequence = self.prepare_sequence_features(
                        historical_data, 
                        len(historical_data) - 1, 
                        self._seq_length
                    )
                else:
                    # å¦‚æœæ²¡æœ‰å†å²æ•°æ®ï¼Œä½¿ç”¨å½“å‰æ•°æ®é‡å¤å¡«å……
                    features = self.prepare_features(current_data)
                    sequence = np.tile(features, (self._seq_length, 1))
                
                # è½¬æ¢ä¸ºtensor: (batch_size=1, seq_length, feature_size)
                input_tensor = torch.tensor(sequence, dtype=torch.float32).unsqueeze(0).to(self.device)
                
                # æ¨¡å‹é¢„æµ‹
                with torch.no_grad():
                    self.model.eval()
                    model_output = self.model(input_tensor)
                    
                    # MoEæ¨¡å‹è¿”å›((outputs), aux_loss)
                    if isinstance(model_output, tuple):
                        outputs, aux_loss = model_output
                    else:
                        outputs = model_output
                    
                    # å¤„ç†è¾“å‡º
                    if isinstance(outputs, tuple):
                        action_logits, profit_pred = outputs
                    else:
                        action_logits = outputs
                        profit_pred = None
                    
                    # åŠ¨ä½œé¢„æµ‹
                    action_probs = torch.softmax(action_logits, dim=-1)
                    action = torch.argmax(action_probs, dim=-1).cpu().numpy()[0]
                    confidence = action_probs[0][action].cpu().numpy()
                    
                    # æ”¶ç›Šç‡é¢„æµ‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if profit_pred is not None:
                        profit_value = float(profit_pred.cpu().numpy()[0])
                        # åº”ç”¨ReLUå’Œclampï¼ˆä¸è®­ç»ƒæ—¶æ¨ç†ä¸€è‡´ï¼‰
                        profit_value = max(0.0, min(profit_value, 0.3))
                        return int(action), float(confidence), profit_value
                    else:
                        return int(action), float(confidence)
            
            except Exception as e:
                print(f"âŒ MoE Transformeré¢„æµ‹é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                return 0, 0.0  # é»˜è®¤ï¼šä¸æ“ä½œï¼Œç½®ä¿¡åº¦0
