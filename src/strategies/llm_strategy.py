import torch
import torch.nn as nn
from torch.utils.data import DataLoader, TensorDataset
import numpy as np
import pandas as pd
import os
from datetime import datetime
import threading
import time
import glob
import argparse
from typing import Tuple, Optional

# å¯¼å…¥åŸºç¡€ç­–ç•¥æ¥å£
try:
    from src.strategies.base_strategy import BaseTradingStrategy
except ImportError:
    # å¦‚æœæ— æ³•å¯¼å…¥ï¼Œåˆ›å»ºä¸€ä¸ªå ä½ç¬¦ç±»ï¼ˆå‘åå…¼å®¹ï¼‰
    from abc import ABC
    BaseTradingStrategy = ABC

class TradingLSTM(nn.Module):
    """ç”¨äºäº¤æ˜“å†³ç­–çš„LSTMæ¨¡å‹ï¼ˆæ”¯æŒåŠ¨ä½œé¢„æµ‹ã€æ”¶ç›Šç‡é¢„æµ‹å’Œç½‘æ ¼å‚æ•°è°ƒæ•´ï¼‰"""
    def __init__(self, input_size=46, hidden_size=128, num_layers=3, output_size=3, 
                 predict_grid_adjustment=True, predict_profit=False):
        super(TradingLSTM, self).__init__()
        self.hidden_size = hidden_size
        self.num_layers = num_layers
        self.predict_grid_adjustment = predict_grid_adjustment
        self.predict_profit = predict_profit
        
        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True, dropout=0.2)
        self.dropout = nn.Dropout(0.3)
        
        # åŠ¨ä½œé¢„æµ‹å¤´ï¼ˆ3ç±»åˆ†ç±»ï¼šä¸æ“ä½œã€ä¹°å…¥ã€å–å‡ºï¼‰
        self.action_head = nn.Linear(hidden_size, output_size)
        
        # åˆå§‹åŒ–æƒé‡ï¼ˆä½¿ç”¨Xavieråˆå§‹åŒ–ï¼Œå¯èƒ½æœ‰åŠ©äºè®­ç»ƒï¼‰
        self._initialize_weights()
        
        # æ”¶ç›Šç‡é¢„æµ‹å¤´ï¼ˆå›å½’ï¼Œç›´æ¥é¢„æµ‹æ”¶ç›Šç‡ï¼‰
        # æ”¹è¿›ï¼šä½¿ç”¨æ›´æ·±çš„ç½‘ç»œï¼Œä½†ä¸ä½¿ç”¨BatchNormï¼ˆé¿å…å•æ ·æœ¬æ¨ç†é—®é¢˜ï¼‰
        if predict_profit:
            self.profit_head = nn.Sequential(
                nn.Linear(hidden_size, hidden_size),
                nn.LayerNorm(hidden_size),  # ä½¿ç”¨LayerNormæ›¿ä»£BatchNorm
                nn.ReLU(),
                nn.Dropout(0.3),
                nn.Linear(hidden_size, hidden_size // 2),
                nn.LayerNorm(hidden_size // 2),  # ä½¿ç”¨LayerNormæ›¿ä»£BatchNorm
                nn.ReLU(),
                nn.Dropout(0.2),
                nn.Linear(hidden_size // 2, 1)
            )
        else:
            self.profit_head = None
        
        # ç½‘æ ¼è°ƒæ•´ç³»æ•°é¢„æµ‹å¤´ï¼ˆå›å½’ï¼ŒèŒƒå›´ [0.8, 1.2]ï¼‰
        if predict_grid_adjustment:
            self.grid_adjustment_head = nn.Linear(hidden_size, 1)
        else:
            self.grid_adjustment_head = None
    
    def _initialize_weights(self):
        """åˆå§‹åŒ–æ¨¡å‹æƒé‡"""
        for name, param in self.named_parameters():
            if 'weight' in name:
                if len(param.shape) >= 2:
                    # ä½¿ç”¨Xavieråˆå§‹åŒ–
                    torch.nn.init.xavier_uniform_(param)
                else:
                    torch.nn.init.uniform_(param, -0.1, 0.1)
            elif 'bias' in name:
                torch.nn.init.constant_(param, 0.0)
    
    def forward(self, x):
        # ç¡®ä¿è¾“å…¥ç»´åº¦æ­£ç¡®
        if len(x.shape) == 2:
            x = x.unsqueeze(1)  # æ·»åŠ åºåˆ—ç»´åº¦ (batch, seq, features)
        
        # åˆå§‹åŒ–éšè—çŠ¶æ€å’Œç»†èƒçŠ¶æ€ - ä½¿ç”¨ detach() ç¡®ä¿æ¢¯åº¦å›¾åˆ†ç¦»
        h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, 
                         dtype=x.dtype, device=x.device, requires_grad=False)
        c0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size, 
                         dtype=x.dtype, device=x.device, requires_grad=False)
        
        # LSTMå‰å‘ä¼ æ’­
        out, _ = self.lstm(x, (h0, c0))
        
        # å–æœ€åä¸€ä¸ªæ—¶é—´æ­¥çš„è¾“å‡º
        out = out[:, -1, :]
        
        # åº”ç”¨Dropout
        out = self.dropout(out)
        
        # åŠ¨ä½œé¢„æµ‹ï¼ˆåˆ†ç±»ï¼‰
        action_logits = self.action_head(out)
        
        # è¿”å›å€¼ç»„è£…
        outputs = []
        outputs.append(action_logits)
        
        # æ”¶ç›Šç‡é¢„æµ‹ï¼ˆå›å½’ï¼Œå¦‚æœå¯ç”¨ï¼‰
        if self.predict_profit and self.profit_head is not None:
            # BatchNormåœ¨å•æ ·æœ¬æ¨ç†æ—¶éœ€è¦ç‰¹æ®Šå¤„ç†
            if out.size(0) == 1:
                # å•æ ·æœ¬æ¨ç†ï¼Œä½¿ç”¨evalæ¨¡å¼ï¼ˆä½¿ç”¨running statsï¼‰
                self.profit_head.eval()
                profit = self.profit_head(out)
                self.profit_head.train()
            else:
                profit = self.profit_head(out)
            # æ”¹è¿›ï¼šåœ¨forwardä¸­ä¸åº”ç”¨ReLUå’Œclampï¼Œè®©æ¨¡å‹è‡ªç”±å­¦ä¹ 
            # ReLUå’Œclampåªåœ¨predict_actionä¸­åº”ç”¨ï¼ˆç”¨äºæ¨ç†æ—¶çš„è¾“å‡ºé™åˆ¶ï¼‰
            # è¿™æ ·è®­ç»ƒæ—¶å¯ä»¥ä½¿ç”¨åŸå§‹è¾“å‡ºè®¡ç®—æŸå¤±ï¼Œä¸ä¼šå½±å“æ¢¯åº¦ä¼ æ’­
            outputs.append(profit)  # ç›´æ¥è¾“å‡ºåŸå§‹å€¼ï¼Œä¸é™åˆ¶
        
        # ç½‘æ ¼è°ƒæ•´ç³»æ•°é¢„æµ‹ï¼ˆå›å½’ï¼ŒèŒƒå›´ [0.8, 1.2]ï¼‰
        if self.predict_grid_adjustment and self.grid_adjustment_head is not None:
            grid_adjustment_raw = self.grid_adjustment_head(out)
            # ä½¿ç”¨sigmoidæ˜ å°„åˆ° [0.8, 1.2]
            grid_adjustment = torch.sigmoid(grid_adjustment_raw) * 0.4 + 0.8
            outputs.append(grid_adjustment)
        
        # è¿”å›ç»“æœ
        if len(outputs) == 1:
            return outputs[0]
        elif len(outputs) == 2:
            return tuple(outputs)
        else:
            return tuple(outputs)


class LLMTradingStrategy(BaseTradingStrategy):
    """LLMäº¤æ˜“ç­–ç•¥ï¼ˆæ”¯æŒä¸¤ç§æ¨¡å¼ï¼šè®¡ç®—æ¨¡å¼å’Œå¤§æ¨¡å‹è¯†åˆ«æ¨¡å¼ï¼‰"""
    
    def __init__(self, data_dir='/home/cx/trading_data', model_path=None, mode='hybrid', predict_profit=False):
        """
        åˆå§‹åŒ–LLMäº¤æ˜“ç­–ç•¥
        
        Args:
            data_dir: æ•°æ®ç›®å½•
            model_path: æ¨¡å‹è·¯å¾„
            mode: ç­–ç•¥æ¨¡å¼
                - 'hybrid': è®¡ç®—æ¨¡å¼ï¼ˆè§„åˆ™è®¡ç®—å‚æ•°ï¼Œæ¨¡å‹é¢„æµ‹åŠ¨ä½œå’Œè°ƒæ•´ï¼‰
                - 'pure_ml': å¤§æ¨¡å‹è¯†åˆ«æ¨¡å¼ï¼ˆæ¨¡å‹è‡ªå·±è¯†åˆ«æ‰€æœ‰ç‰¹å¾å’Œå‚æ•°ï¼‰
            predict_profit: æ˜¯å¦é¢„æµ‹æ”¶ç›Šç‡ï¼ˆç›´æ¥ä¼˜åŒ–æ”¶ç›Šç›®æ ‡ï¼‰
        """
        self.mode = mode  # 'hybrid' æˆ– 'pure_ml'
        self.predict_profit = predict_profit  # æ˜¯å¦é¢„æµ‹æ”¶ç›Šç‡
        # æ£€æŸ¥GPUå¯ç”¨æ€§
        if torch.cuda.is_available():
            self.device = torch.device('cuda')
            print(f"Using device: {self.device}")
        else:
            self.device = torch.device('cpu')
            print(f"Using device: {self.device}")
        
        self.data_dir = data_dir
        
        # åˆå§‹åŒ–æ¨¡å‹ï¼ˆæ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„è¾“å…¥è¾“å‡ºï¼‰
        if mode == 'hybrid':
            # è®¡ç®—æ¨¡å¼ï¼šè¾“å…¥è®¡ç®—å¥½çš„ç‰¹å¾ï¼ˆ46ç»´ï¼ŒåŒ…å«å¤šæ—¶é—´å°ºåº¦ç‰¹å¾ï¼‰ï¼Œè¾“å‡ºåŠ¨ä½œå’Œç½‘æ ¼è°ƒæ•´ç³»æ•°
            input_size = 46
            predict_grid_adjustment = True
        elif mode == 'pure_ml':
            # å¤§æ¨¡å‹è¯†åˆ«æ¨¡å¼ï¼šè¾“å…¥åŸå§‹OHLCVæ•°æ®ï¼ˆåºåˆ—ï¼‰ï¼Œè¾“å‡ºåŠ¨ä½œå’Œç½‘æ ¼å‚æ•°
            input_size = 10  # open, high, low, close, volume (1m + 5m)
            predict_grid_adjustment = True
            # æ³¨æ„ï¼špure_mlæ¨¡å¼éœ€è¦æ›´å¤§çš„æ¨¡å‹æ¥è¯†åˆ«ç‰¹å¾
        else:
            raise ValueError(f"æœªçŸ¥çš„æ¨¡å¼: {mode}ï¼Œæ”¯æŒçš„æ¨¡å¼: 'hybrid', 'pure_ml'")
        
        self.model = TradingLSTM(
            input_size=input_size,
            hidden_size=128,  # ä»64å¢åŠ åˆ°128
            num_layers=3,      # ä»2å¢åŠ åˆ°3
            output_size=3,
            predict_grid_adjustment=predict_grid_adjustment,
            predict_profit=predict_profit
        ).to(self.device)
        
        # ç›´æ¥åˆå§‹åŒ–ä¼˜åŒ–å™¨ï¼Œè€Œä¸æ˜¯è®¾ä¸ºNone
        self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=0.001, weight_decay=1e-5)
        self.criterion = None  # å°†åœ¨è®­ç»ƒæ—¶åŠ¨æ€è®¾ç½®
        # æ”¶ç›Šç‡æŸå¤±å‡½æ•°ï¼ˆå¦‚æœå¯ç”¨æ”¶ç›Šç‡é¢„æµ‹ï¼‰
        # æ”¹è¿›ï¼šä½¿ç”¨MSELossæ›¿ä»£HuberLossï¼Œæ›´æ•æ„Ÿï¼Œæœ‰åŠ©äºæ”¶ç›Šç‡é¢„æµ‹å¤´å­¦ä¹ 
        self.profit_criterion = nn.MSELoss() if predict_profit else None
        
        # æ§åˆ¶è®­ç»ƒå’Œæ¨ç†çš„æ ‡å¿—
        self.should_train = True
        self.model_lock = threading.Lock()
        
        # åºåˆ—é•¿åº¦é…ç½®ï¼ˆæ ¹æ®æµ‹è¯•ç»“æœï¼Œåºåˆ—é•¿åº¦10è¡¨ç°æœ€å¥½ï¼‰
        self._seq_length = 10  # æ ¹æ®æµ‹è¯•ç»“æœï¼Œåºåˆ—é•¿åº¦10å‡†ç¡®ç‡æœ€é«˜ï¼ˆ48.05%ï¼‰
        self._historical_data = None  # å†å²æ•°æ®ç¼“å­˜
    
    @property
    def seq_length(self) -> int:
        """è¿”å›ç­–ç•¥éœ€è¦çš„åºåˆ—é•¿åº¦"""
        return self._seq_length
    
    @property
    def strategy_name(self) -> str:
        """è¿”å›ç­–ç•¥åç§°"""
        return f"LSTM ({self.mode})"
        
        # å¦‚æœæä¾›äº†æ¨¡å‹è·¯å¾„ï¼Œåˆ™åŠ è½½æ¨¡å‹
        if model_path and os.path.exists(model_path):
            try:
                checkpoint = torch.load(model_path, map_location=self.device, weights_only=False)
                self.model.load_state_dict(checkpoint['model_state_dict'])
                if 'optimizer_state_dict' in checkpoint:
                    self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
                print(f"âœ… ä» {model_path} åŠ è½½æ¨¡å‹æˆåŠŸ")
            except Exception as e:
                print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}ï¼Œä½¿ç”¨åˆå§‹æ¨¡å‹")
        
        # æ³¨æ„ï¼šä¸è‡ªåŠ¨å¯åŠ¨è®­ç»ƒçº¿ç¨‹ï¼Œç”±ç”¨æˆ·å†³å®šæ˜¯å¦å¯åŠ¨
        # self.training_thread = threading.Thread(target=self.train_continuously, daemon=True)
        # self.training_thread.start()

    def calculate_class_weights(self, y):
        """è®¡ç®—ç±»åˆ«æƒé‡ä»¥å¤„ç†ä¸å¹³è¡¡æ•°æ®"""
        import numpy as np
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°
        classes, counts = np.unique(y, return_counts=True)
        total_samples = len(y)
        
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æƒé‡ (æ€»æ ·æœ¬æ•° / (ç±»åˆ«æ•° * æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°))
        weights = []
        for count in counts:
            weight = total_samples / (len(classes) * count)
            weights.append(weight)
        
        # è½¬æ¢ä¸ºtensor
        class_weights = torch.FloatTensor(weights).to(self.device)
        return class_weights

    def prepare_sequence_features(self, df, current_idx, seq_length):
        """
        å‡†å¤‡å†å²åºåˆ—ç‰¹å¾
        
        Args:
            df: æ•°æ®æ¡†
            current_idx: å½“å‰ç´¢å¼•
            seq_length: åºåˆ—é•¿åº¦
        
        Returns:
            sequence: (seq_length, feature_size) çš„æ•°ç»„
        """
        start_idx = max(0, current_idx - seq_length + 1)
        sequence_df = df.iloc[start_idx:current_idx+1]
        
        sequences = []
        for _, row in sequence_df.iterrows():
            features = self.prepare_features(row)
            sequences.append(features)
        
        # ç¡®å®šç‰¹å¾å¤§å°
        feature_size = 46 if self.mode == 'hybrid' else 10  # hybridæ¨¡å¼ç°åœ¨åŒ…å«å¤šæ—¶é—´å°ºåº¦ç‰¹å¾ï¼Œæ‰€ä»¥æ˜¯46ç»´
        
        # å¦‚æœåºåˆ—ä¸è¶³seq_lengthï¼Œç”¨ç¬¬ä¸€ä¸ªå€¼å¡«å……
        while len(sequences) < seq_length:
            if sequences:
                sequences.insert(0, sequences[0])
            else:
                sequences.insert(0, [0.0] * feature_size)
        
        return np.array(sequences, dtype=np.float32)
    
    def calculate_optimal_grid_adjustment(self, current_price, future_prices, grid_base):
        """
        è®¡ç®—æœ€ä¼˜ç½‘æ ¼è°ƒæ•´ç³»æ•°ï¼ˆåŸºäºå†å²æ•°æ®ï¼‰
        
        Args:
            current_price: å½“å‰ä»·æ ¼
            future_prices: æœªæ¥ä»·æ ¼åºåˆ—
            grid_base: åŸºç¡€ç½‘æ ¼é—´è·
        
        Returns:
            optimal_adjustment: æœ€ä¼˜è°ƒæ•´ç³»æ•° [0.8, 1.2]
        """
        if grid_base <= 0 or len(future_prices) == 0:
            return 1.0
        
        best_adjustment = 1.0
        best_profit = -float('inf')
        
        # å°è¯•ä¸åŒçš„è°ƒæ•´ç³»æ•°
        for adjustment in np.arange(0.8, 1.21, 0.05):
            grid_step = grid_base * adjustment
            grid_upper = current_price + grid_step / 2
            grid_lower = current_price - grid_step / 2
            
            # è®¡ç®—åœ¨æ­¤ç½‘æ ¼å‚æ•°ä¸‹çš„æ”¶ç›Š
            # ä¹°å…¥ï¼šä»·æ ¼è¾¾åˆ°ä¸Šè½¨æ—¶å–å‡º
            buy_profit = 0.0
            if max(future_prices) >= grid_upper:
                buy_profit = (grid_upper - current_price) / current_price
            
            # å–å‡ºï¼šä»·æ ¼è¾¾åˆ°ä¸‹è½¨æ—¶ä¹°å…¥ï¼ˆåšç©ºæ”¶ç›Šï¼‰
            sell_profit = 0.0
            if min(future_prices) <= grid_lower:
                sell_profit = (current_price - grid_lower) / current_price
            
            # æ€»æ”¶ç›Šï¼ˆå–è¾ƒå¤§è€…ï¼‰
            total_profit = max(buy_profit, sell_profit)
            
            if total_profit > best_profit:
                best_profit = total_profit
                best_adjustment = adjustment
        
        return best_adjustment
    
    def train_model(self, df, seq_length=10, max_epochs=50, patience=10, train_grid_adjustment=True):
        """
        è®­ç»ƒæ¨¡å‹ï¼ˆæ”¯æŒåºåˆ—è¾“å…¥å’Œç½‘æ ¼è°ƒæ•´ç³»æ•°è®­ç»ƒï¼‰
        
        Args:
            df: è®­ç»ƒæ•°æ®æ¡†
            seq_length: åºåˆ—é•¿åº¦
            max_epochs: æœ€å¤§è®­ç»ƒè½®æ¬¡
            patience: æ—©åœè€å¿ƒå€¼
            train_grid_adjustment: æ˜¯å¦è®­ç»ƒç½‘æ ¼è°ƒæ•´ç³»æ•°
        """
        try:
            from torch.optim.lr_scheduler import ReduceLROnPlateau
            
            # é‡æ–°åˆå§‹åŒ–ä¼˜åŒ–å™¨ä»¥é¿å…çŠ¶æ€é—®é¢˜
            # ä½¿ç”¨æ›´å°çš„å­¦ä¹ ç‡ï¼Œæ›´ç¨³å®šçš„è®­ç»ƒ
            self.optimizer = torch.optim.AdamW(self.model.parameters(), lr=0.0005, weight_decay=1e-4)
            scheduler = ReduceLROnPlateau(self.optimizer, mode='max', factor=0.5, patience=5, min_lr=1e-6)
            
            # å‡†å¤‡è®­ç»ƒæ•°æ®ï¼Œä½¿ç”¨åŸºäºç›ˆåˆ©çš„æ ‡ç­¾
            X, y, y_grid = [], [], []  # y_grid: ç½‘æ ¼è°ƒæ•´ç³»æ•°æ ‡ç­¾
            y_profit = []  # æ”¶ç›Šç‡æ ‡ç­¾ï¼ˆå§‹ç»ˆåˆå§‹åŒ–ï¼Œé¿å…å±€éƒ¨å˜é‡ä½œç”¨åŸŸé—®é¢˜ï¼‰
            
            # æ”¹è¿›ï¼šåŸºäºæ—¶é—´é•¿åº¦è®¡ç®—look_aheadï¼Œè€Œä¸æ˜¯å›ºå®šæ­¥æ•°
            # ç½‘æ ¼äº¤æ˜“é€šå¸¸éœ€è¦2-4å°æ—¶çš„æŒä»“å‘¨æœŸï¼Œä½¿ç”¨2å°æ—¶ä½œä¸ºç›®æ ‡é¢„æµ‹æ—¶é•¿
            target_time_hours = 2.0  # é¢„æµ‹æœªæ¥2å°æ—¶
            # è®¡ç®—æ•°æ®çš„æ—¶é—´é—´éš”ï¼ˆå‡è®¾æ˜¯1åˆ†é’ŸKçº¿ï¼‰
            if 'timestamp' in df.columns and len(df) > 1:
                df['timestamp'] = pd.to_datetime(df['timestamp'])
                avg_interval = df['timestamp'].diff().dropna().median()
                if pd.notna(avg_interval):
                    # è®¡ç®—æ­¥æ•°ï¼šç›®æ ‡æ—¶é—´ / å¹³å‡é—´éš”
                    look_ahead = int(pd.Timedelta(hours=target_time_hours) / avg_interval)
                    print(f"ğŸ“Š æ•°æ®æ—¶é—´é—´éš”: {avg_interval}, ç›®æ ‡é¢„æµ‹æ—¶é•¿: {target_time_hours}å°æ—¶, è®¡ç®—å¾—åˆ°look_ahead: {look_ahead}æ­¥")
                else:
                    look_ahead = 120  # é»˜è®¤ï¼š2å°æ—¶ = 120åˆ†é’Ÿï¼ˆ1åˆ†é’ŸKçº¿ï¼‰
                    print(f"âš ï¸ æ— æ³•è®¡ç®—æ—¶é—´é—´éš”ï¼Œä½¿ç”¨é»˜è®¤look_ahead: {look_ahead}æ­¥ï¼ˆ{target_time_hours}å°æ—¶ï¼‰")
            else:
                look_ahead = 120  # é»˜è®¤ï¼š2å°æ—¶ = 120åˆ†é’Ÿï¼ˆ1åˆ†é’ŸKçº¿ï¼‰
                print(f"âš ï¸ æ•°æ®ä¸­æ²¡æœ‰timestampï¼Œä½¿ç”¨é»˜è®¤look_ahead: {look_ahead}æ­¥ï¼ˆ{target_time_hours}å°æ—¶ï¼‰")
            
            min_required = seq_length + look_ahead  # éœ€è¦è‡³å°‘seq_length + look_aheadä¸ªæ•°æ®ç‚¹
            
            print(f"ğŸ“Š ä½¿ç”¨åºåˆ—é•¿åº¦: {seq_length}, éœ€è¦è‡³å°‘ {min_required} ä¸ªæ•°æ®ç‚¹")
            print(f"ğŸ“Š è®­ç»ƒé…ç½®: æœ€å¤§è½®æ¬¡={max_epochs}, æ—©åœè€å¿ƒ={patience}, ç½‘æ ¼è°ƒæ•´è®­ç»ƒ={train_grid_adjustment}")
            
            for i in range(min_required, len(df)):
                # è®¡ç®—æœªæ¥look_aheadæ­¥çš„ç›ˆåˆ©ï¼ˆå…ˆæ£€æŸ¥æ•°æ®æ˜¯å¦è¶³å¤Ÿï¼‰
                if i + look_ahead >= len(df):
                    break  # æ•°æ®ä¸è¶³ï¼Œè·³å‡ºå¾ªç¯
                
                # å‡†å¤‡åºåˆ—ç‰¹å¾ï¼ˆå†å²seq_lengthä¸ªæ—¶é—´æ­¥ï¼‰
                sequence = self.prepare_sequence_features(df, i, seq_length)
                X.append(sequence)
                
                # è®¡ç®—æœªæ¥look_aheadæ­¥çš„ç›ˆåˆ©
                current_price = df.iloc[i]['price_current']
                future_prices = df.iloc[i+1:i+look_ahead+1]['price_current'].values
                
                if len(future_prices) == 0:
                    # å¦‚æœæœªæ¥ä»·æ ¼ä¸è¶³ï¼Œç§»é™¤åˆšæ·»åŠ çš„åºåˆ—
                    X.pop()
                    continue
                
                # è·å–åŸºç¡€ç½‘æ ¼å‚æ•°
                grid_lower = df.iloc[i].get('grid_lower', current_price * 0.99) if hasattr(df.iloc[i], 'get') else df.iloc[i].get('grid_lower', current_price * 0.99)
                grid_upper = df.iloc[i].get('grid_upper', current_price * 1.01) if hasattr(df.iloc[i], 'get') else df.iloc[i].get('grid_upper', current_price * 1.01)
                grid_base = max(grid_upper - grid_lower, 0.01)  # ç¡®ä¿grid_base > 0
                
                # è®¡ç®—æœ€å¤§ç›ˆåˆ©å’Œæœ€å¤§äºæŸ
                max_future_price = max(future_prices)
                min_future_price = min(future_prices)
                
                buy_profit = (max_future_price - current_price) / current_price
                sell_profit = (current_price - min_future_price) / current_price
                
                # åˆ›å»ºåŠ¨ä½œæ ‡ç­¾: 0=ä¸æ“ä½œ, 1=ä¹°å…¥, 2=å–å‡º
                # ä¼˜åŒ–æ ‡ç­¾ç”Ÿæˆé€»è¾‘ï¼šé™ä½é˜ˆå€¼ï¼Œå¢åŠ äº¤æ˜“ä¿¡å·
                # æ”¹è¿›ï¼šè€ƒè™‘æŒä»“çŠ¶æ€ï¼ˆå¦‚æœæœ‰æŒä»“ï¼Œä¼˜å…ˆè€ƒè™‘å–å‡ºï¼‰
                profit_threshold = 0.003  # ä»0.005é™ä½åˆ°0.003ï¼Œå¢åŠ äº¤æ˜“æœºä¼š
                min_diff = 0.002  # ä»0.003é™ä½åˆ°0.002ï¼Œæ›´å®¹æ˜“åŒºåˆ†æ–¹å‘
                
                # å°è¯•ä»æ•°æ®ä¸­è·å–æŒä»“çŠ¶æ€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                current_position = 0
                if 'current_position' in df.columns:
                    try:
                        current_position = int(df.iloc[i].get('current_position', 0))
                    except:
                        current_position = 0
                
                # æ ¹æ®æŒä»“çŠ¶æ€è°ƒæ•´æ ‡ç­¾ç”Ÿæˆé€»è¾‘
                # æ”¹è¿›ï¼šä¸ºäº†è®­ç»ƒæ•°æ®å¹³è¡¡ï¼Œä»ç„¶ç”Ÿæˆæ‰€æœ‰3ä¸ªæ ‡ç­¾ï¼Œä½†å®é™…äº¤æ˜“æ—¶ä¼šæ ¹æ®æŒä»“çŠ¶æ€è¿‡æ»¤
                if current_position > 0:
                    # æœ‰æŒä»“ï¼Œä¼˜å…ˆè€ƒè™‘å–å‡º
                    if sell_profit > profit_threshold:
                        label = 2  # å–å‡º
                    elif buy_profit > profit_threshold:
                        label = 1  # ä¹°å…¥ï¼ˆåŠ ä»“ï¼‰
                    else:
                        label = 0  # ä¸æ“ä½œ
                else:
                    # æ— æŒä»“ï¼Œä¼˜å…ˆä¹°å…¥ï¼Œä½†å¦‚æœsell_profitæ˜æ˜¾æ›´å¤§ï¼Œä»ç„¶æ ‡è®°ä¸ºå–å‡ºï¼ˆè®©æ¨¡å‹å­¦ä¹ ï¼‰
                    # å®é™…äº¤æ˜“æ—¶ä¼šæ ¹æ®æŒä»“çŠ¶æ€è¿‡æ»¤ï¼Œä½†è®­ç»ƒæ—¶è®©æ¨¡å‹å­¦ä¹ æ‰€æœ‰æƒ…å†µ
                    if abs(buy_profit - sell_profit) >= min_diff:
                        if buy_profit > sell_profit and buy_profit > profit_threshold:
                            label = 1  # ä¹°å…¥
                        elif sell_profit > buy_profit and sell_profit > profit_threshold:
                            label = 2  # å–å‡ºï¼ˆè®­ç»ƒæ—¶å…è®¸ï¼Œå®é™…äº¤æ˜“æ—¶ä¼šè¿‡æ»¤ï¼‰
                        else:
                            label = 0  # ä¸æ“ä½œ
                    else:
                        label = 0  # ä¸æ“ä½œ
                
                y.append(label)
                
                # è®¡ç®—å®é™…æ”¶ç›Šç‡ï¼ˆå¦‚æœå¯ç”¨æ”¶ç›Šç‡é¢„æµ‹ï¼‰
                # æ”¹è¿›ï¼šæ ¹æ®åŠ¨ä½œæ ‡ç­¾é€‰æ‹©å¯¹åº”çš„æ”¶ç›Šç‡ï¼Œè€Œä¸æ˜¯å–æœ€å¤§å€¼
                if self.predict_profit:
                    buy_profit = (max(future_prices) - current_price) / current_price
                    sell_profit = (current_price - min(future_prices)) / current_price
                    # æ ¹æ®åŠ¨ä½œæ ‡ç­¾é€‰æ‹©å¯¹åº”çš„æ”¶ç›Šç‡
                    if label == 1:  # ä¹°å…¥
                        actual_profit = buy_profit
                    elif label == 2:  # å–å‡º
                        actual_profit = sell_profit
                    else:  # ä¸æ“ä½œ
                        actual_profit = 0.0
                    y_profit.append(actual_profit)
                
                # è®¡ç®—æœ€ä¼˜ç½‘æ ¼è°ƒæ•´ç³»æ•°ï¼ˆå¦‚æœå¯ç”¨ï¼‰- ç¡®ä¿ä¸yåŒæ—¶æ·»åŠ 
                if train_grid_adjustment and self.model.predict_grid_adjustment:
                    optimal_adjustment = self.calculate_optimal_grid_adjustment(
                        current_price, future_prices, grid_base
                    )
                    y_grid.append(optimal_adjustment)
                else:
                    y_grid.append(1.0)  # é»˜è®¤ä¸è°ƒæ•´
            
            # æœ€ç»ˆæ£€æŸ¥ï¼šç¡®ä¿X, y, y_grid, y_profité•¿åº¦ä¸€è‡´
            if self.predict_profit and y_profit is not None:
                min_len = min(len(X), len(y), len(y_grid), len(y_profit))
                if len(X) != min_len or len(y) != min_len or len(y_grid) != min_len or len(y_profit) != min_len:
                    print(f"âš ï¸ è­¦å‘Š: æ•°æ®é•¿åº¦ä¸ä¸€è‡´ï¼Œè°ƒæ•´åˆ°æœ€å°é•¿åº¦ {min_len}")
                    print(f"   X={len(X)}, y={len(y)}, y_grid={len(y_grid)}, y_profit={len(y_profit)}")
                    X = X[:min_len]
                    y = y[:min_len]
                    y_grid = y_grid[:min_len]
                    y_profit = y_profit[:min_len]
            else:
                min_len = min(len(X), len(y), len(y_grid))
                if len(X) != min_len or len(y) != min_len or len(y_grid) != min_len:
                    print(f"âš ï¸ è­¦å‘Š: æ•°æ®é•¿åº¦ä¸ä¸€è‡´ï¼Œè°ƒæ•´åˆ°æœ€å°é•¿åº¦ {min_len}")
                    print(f"   X={len(X)}, y={len(y)}, y_grid={len(y_grid)}")
                    X = X[:min_len]
                    y = y[:min_len]
                    y_grid = y_grid[:min_len]
            
            if len(X) < 10:  # éœ€è¦è‡³å°‘10ä¸ªæ ·æœ¬è¿›è¡Œè®­ç»ƒ
                print("æ•°æ®ä¸è¶³ï¼Œè·³è¿‡è®­ç»ƒ")
                return
            
            # åˆ†ææ ‡ç­¾åˆ†å¸ƒ
            unique, counts = np.unique(y, return_counts=True)
            label_distribution = dict(zip(unique, counts))
            print(f"æ ‡ç­¾åˆ†å¸ƒ: {label_distribution}")
            
            # å¦‚æœæŸä¸ªç±»åˆ«å æ¯”è¿‡é«˜ï¼Œå¯èƒ½å­˜åœ¨æ•°æ®ä¸å¹³è¡¡é—®é¢˜
            total_samples = len(y)
            for label, count in label_distribution.items():
                percentage = count / total_samples * 100
                print(f"æ ‡ç­¾ {label} å æ¯”: {percentage:.2f}%")
            
            # è®¡ç®—ç±»åˆ«æƒé‡
            class_weights = self.calculate_class_weights(y)
            print(f"ç±»åˆ«æƒé‡: {class_weights}")
            
            # æ›´æ–°æŸå¤±å‡½æ•°
            self.criterion = nn.CrossEntropyLoss(weight=class_weights)
            self.grid_criterion = nn.MSELoss() if train_grid_adjustment else None
            # æ”¶ç›Šç‡æŸå¤±å‡½æ•°ï¼ˆä½¿ç”¨HuberæŸå¤±ï¼Œå¯¹å¼‚å¸¸å€¼æ›´é²æ£’ï¼‰
            self.profit_criterion = nn.HuberLoss(delta=0.01) if self.predict_profit else None
            
            # åˆ†å‰²è®­ç»ƒé›†å’ŒéªŒè¯é›† (80% è®­ç»ƒ, 20% éªŒè¯)
            split_idx = int(len(X) * 0.8)
            
            # ç¡®ä¿æ‰€æœ‰åˆ—è¡¨é•¿åº¦ä¸€è‡´
            if self.predict_profit:
                assert len(X) == len(y) == len(y_grid) == len(y_profit), \
                    f"æ•°æ®é•¿åº¦ä¸ä¸€è‡´: X={len(X)}, y={len(y)}, y_grid={len(y_grid)}, y_profit={len(y_profit)}"
            else:
                assert len(X) == len(y) == len(y_grid), \
                    f"æ•°æ®é•¿åº¦ä¸ä¸€è‡´: X={len(X)}, y={len(y)}, y_grid={len(y_grid)}"
            
            X_train = X[:split_idx]
            y_train = y[:split_idx]
            y_grid_train = y_grid[:split_idx]
            y_profit_train = y_profit[:split_idx] if self.predict_profit else None
            X_val = X[split_idx:]
            y_val = y[split_idx:]
            y_grid_val = y_grid[split_idx:]
            y_profit_val = y_profit[split_idx:] if self.predict_profit else None
            
            # å†æ¬¡æ£€æŸ¥åˆ†å‰²åçš„é•¿åº¦
            if self.predict_profit:
                assert len(X_train) == len(y_train) == len(y_grid_train) == len(y_profit_train), \
                    f"è®­ç»ƒé›†é•¿åº¦ä¸ä¸€è‡´"
                assert len(X_val) == len(y_val) == len(y_grid_val) == len(y_profit_val), \
                    f"éªŒè¯é›†é•¿åº¦ä¸ä¸€è‡´"
            else:
                assert len(X_train) == len(y_train) == len(y_grid_train), \
                    f"è®­ç»ƒé›†é•¿åº¦ä¸ä¸€è‡´"
                assert len(X_val) == len(y_val) == len(y_grid_val), \
                    f"éªŒè¯é›†é•¿åº¦ä¸ä¸€è‡´"
            
            X_train = np.array(X_train)
            y_train = np.array(y_train)
            y_grid_train = np.array(y_grid_train, dtype=np.float32)
            y_profit_train = np.array(y_profit_train, dtype=np.float32) if self.predict_profit else None
            X_val = np.array(X_val)
            y_val = np.array(y_val)
            y_grid_val = np.array(y_grid_val, dtype=np.float32)
            y_profit_val = np.array(y_profit_val, dtype=np.float32) if self.predict_profit else None
            
            # è½¬æ¢ä¸ºå¼ é‡
            X_train_tensor = torch.tensor(X_train, dtype=torch.float32).to(self.device)
            y_train_tensor = torch.tensor(y_train, dtype=torch.long).to(self.device)
            y_grid_train_tensor = torch.tensor(y_grid_train, dtype=torch.float32).to(self.device)
            y_profit_train_tensor = torch.tensor(y_profit_train, dtype=torch.float32).to(self.device) if self.predict_profit else None
            X_val_tensor = torch.tensor(X_val, dtype=torch.float32).to(self.device)
            y_val_tensor = torch.tensor(y_val, dtype=torch.long).to(self.device)
            y_grid_val_tensor = torch.tensor(y_grid_val, dtype=torch.float32).to(self.device)
            y_profit_val_tensor = torch.tensor(y_profit_val, dtype=torch.float32).to(self.device) if self.predict_profit else None
            
            print(f"âœ… æ•°æ®å‡†å¤‡å®Œæˆ: è®­ç»ƒé›†å½¢çŠ¶ {X_train_tensor.shape}, éªŒè¯é›†å½¢çŠ¶ {X_val_tensor.shape}")
            if self.predict_profit:
                print(f"ğŸ“Š æ”¶ç›Šç‡ç»Ÿè®¡: è®­ç»ƒé›† min={y_profit_train.min():.4f}, max={y_profit_train.max():.4f}, mean={y_profit_train.mean():.4f}")
            
            # åˆ›å»ºæ•°æ®é›†ï¼ˆåŒ…å«ç½‘æ ¼è°ƒæ•´ç³»æ•°å’Œæ”¶ç›Šç‡æ ‡ç­¾ï¼‰
            dataset_items = [X_train_tensor, y_train_tensor]
            val_dataset_items = [X_val_tensor, y_val_tensor]
            
            if self.predict_profit:
                dataset_items.append(y_profit_train_tensor)
                val_dataset_items.append(y_profit_val_tensor)
            
            if train_grid_adjustment and len(y_grid_train_tensor) == len(y_train_tensor):
                dataset_items.append(y_grid_train_tensor)
                val_dataset_items.append(y_grid_val_tensor)
            
            train_dataset = TensorDataset(*dataset_items)
            val_dataset = TensorDataset(*val_dataset_items)
            
            train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
            val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)
            
            # è®­ç»ƒæ¨¡å‹
            self.model.train()  # è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼
            best_val_acc = 0.0
            patience_counter = 0
            
            for epoch in range(max_epochs):
                # è®­ç»ƒé˜¶æ®µ
                total_loss = 0
                num_batches = 0
                correct_predictions = 0
                total_predictions = 0
                
                for batch_data in train_loader:
                    # å¤„ç†æ‰¹æ¬¡æ•°æ®ï¼ˆå¯èƒ½åŒ…å«æ”¶ç›Šç‡å’Œç½‘æ ¼è°ƒæ•´ç³»æ•°æ ‡ç­¾ï¼‰
                    batch_x = batch_data[0]
                    batch_y = batch_data[1]
                    batch_y_profit = None
                    batch_y_grid = None
                    
                    # è§£ææ‰¹æ¬¡æ•°æ®
                    if self.predict_profit:
                        if len(batch_data) >= 3:
                            batch_y_profit = batch_data[2].to(self.device)
                        if len(batch_data) >= 4:
                            batch_y_grid = batch_data[3].to(self.device)
                    else:
                        if len(batch_data) >= 3:
                            batch_y_grid = batch_data[2].to(self.device)
                    
                    # åˆ›å»ºæ–°çš„å¼ é‡å‰¯æœ¬ä»¥é¿å…ç‰ˆæœ¬å†²çª
                    batch_x = batch_x.clone().detach().to(self.device)
                    batch_y = batch_y.clone().detach().to(self.device)
                    
                    # batch_xå·²ç»æ˜¯(batch, seq, features)å½¢çŠ¶ï¼Œä¸éœ€è¦å†unsqueeze
                    # å¦‚æœå·²ç»æ˜¯3Dï¼Œç›´æ¥ä½¿ç”¨ï¼›å¦‚æœæ˜¯2Dï¼Œéœ€è¦unsqueeze
                    if len(batch_x.shape) == 2:
                        # (batch, features) -> (batch, 1, features)
                        batch_x = batch_x.unsqueeze(1).contiguous()
                    elif len(batch_x.shape) == 3:
                        # å·²ç»æ˜¯(batch, seq, features)ï¼Œç›´æ¥ä½¿ç”¨
                        pass
                    else:
                        # å…¶ä»–æƒ…å†µï¼Œå°è¯•reshape
                        batch_x = batch_x.view(batch_x.size(0), -1, batch_x.size(-1)).contiguous()
                    
                    self.optimizer.zero_grad()
                    model_output = self.model(batch_x)
                    
                    # å¤„ç†æ¨¡å‹è¾“å‡ºå’Œè®¡ç®—æŸå¤±
                    if isinstance(model_output, tuple):
                        # è§£ææ¨¡å‹è¾“å‡º
                        if len(model_output) == 2:
                            if self.predict_profit:
                                # æ”¶ç›Šç‡ + ç½‘æ ¼è°ƒæ•´
                                action_logits, profit = model_output
                                grid_adjustment = None
                            else:
                                # åŠ¨ä½œ + ç½‘æ ¼è°ƒæ•´
                                action_logits, grid_adjustment = model_output
                                profit = None
                        elif len(model_output) == 3:
                            # åŠ¨ä½œ + æ”¶ç›Šç‡ + ç½‘æ ¼è°ƒæ•´
                            action_logits, profit, grid_adjustment = model_output
                        else:
                            action_logits = model_output[0]
                            profit = model_output[1] if len(model_output) > 1 else None
                            grid_adjustment = model_output[2] if len(model_output) > 2 else None
                        
                        # åŠ¨ä½œåˆ†ç±»æŸå¤±
                        action_loss = self.criterion(action_logits, batch_y)
                        loss = action_loss
                        
                        # æ”¶ç›Šç‡å›å½’æŸå¤±ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if self.predict_profit and profit is not None and batch_y_profit is not None and self.profit_criterion is not None:
                            profit_loss = self.profit_criterion(profit.squeeze(), batch_y_profit)
                            # æ”¶ç›Šç‡æŸå¤±æƒé‡å¢åŠ åˆ°1.0ï¼ˆä¸åŠ¨ä½œåˆ†ç±»åŒç­‰é‡è¦ï¼Œå› ä¸ºè¿™æ˜¯ä¸»è¦ç›®æ ‡ï¼‰
                            loss = loss + 1.0 * profit_loss
                        
                        # ç½‘æ ¼è°ƒæ•´ç³»æ•°å›å½’æŸå¤±ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if train_grid_adjustment and grid_adjustment is not None and batch_y_grid is not None and self.grid_criterion is not None:
                            grid_loss = self.grid_criterion(grid_adjustment.squeeze(), batch_y_grid)
                            # ç»„åˆæŸå¤±ï¼ˆç½‘æ ¼æŸå¤±æƒé‡0.1ï¼‰
                            loss = loss + 0.1 * grid_loss
                    else:
                        action_logits = model_output
                        loss = self.criterion(action_logits, batch_y)
                    
                    loss.backward()
                    # æ¢¯åº¦è£å‰ªï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
                    torch.nn.utils.clip_grad_norm_(self.model.parameters(), max_norm=1.0)
                    self.optimizer.step()
                    
                    # è®¡ç®—å‡†ç¡®ç‡
                    predictions = torch.argmax(action_logits, dim=1)
                    correct_predictions += (predictions == batch_y).sum().item()
                    total_predictions += batch_y.size(0)
                    
                    total_loss += loss.item()
                    num_batches += 1
                    
                    # ç´¯è®¡æ”¶ç›Šç‡é¢„æµ‹è¯¯å·®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                    if self.predict_profit and profit is not None and batch_y_profit is not None:
                        profit_errors = torch.abs(profit.squeeze() - batch_y_profit)
                        if not hasattr(self, '_train_profit_errors'):
                            self._train_profit_errors = []
                        self._train_profit_errors.extend(profit_errors.detach().cpu().numpy().tolist())
                
                train_avg_loss = total_loss / num_batches
                train_accuracy = correct_predictions / total_predictions if total_predictions > 0 else 0
                train_profit_mae = np.mean(self._train_profit_errors) if hasattr(self, '_train_profit_errors') and len(self._train_profit_errors) > 0 else None
                if hasattr(self, '_train_profit_errors'):
                    delattr(self, '_train_profit_errors')
                
                # éªŒè¯é˜¶æ®µ
                self.model.eval()  # è®¾ç½®ä¸ºè¯„ä¼°æ¨¡å¼
                val_correct = 0
                val_total = 0
                val_loss = 0
                with torch.no_grad():
                    for batch_data in val_loader:
                        # å¤„ç†æ‰¹æ¬¡æ•°æ®ï¼ˆä¸è®­ç»ƒé›†ç›¸åŒï¼‰
                        batch_x = batch_data[0]
                        batch_y = batch_data[1]
                        batch_y_profit = None
                        batch_y_grid = None
                        
                        # è§£ææ‰¹æ¬¡æ•°æ®
                        if self.predict_profit:
                            if len(batch_data) >= 3:
                                batch_y_profit = batch_data[2]
                            if len(batch_data) >= 4:
                                batch_y_grid = batch_data[3]
                        else:
                            if len(batch_data) >= 3:
                                batch_y_grid = batch_data[2]
                        
                        batch_x = batch_x.clone().detach().to(self.device)
                        batch_y = batch_y.clone().detach().to(self.device)
                        
                        # batch_xå·²ç»æ˜¯(batch, seq, features)å½¢çŠ¶ï¼Œä¸éœ€è¦å†unsqueeze
                        if len(batch_x.shape) == 2:
                            batch_x = batch_x.unsqueeze(1).contiguous()
                        elif len(batch_x.shape) == 3:
                            pass  # å·²ç»æ˜¯æ­£ç¡®å½¢çŠ¶
                        else:
                            batch_x = batch_x.view(batch_x.size(0), -1, batch_x.size(-1)).contiguous()
                        
                        model_output = self.model(batch_x)
                        
                        # å¤„ç†æ¨¡å‹è¾“å‡ºï¼ˆä¸è®­ç»ƒé˜¶æ®µç›¸åŒçš„é€»è¾‘ï¼‰
                        if isinstance(model_output, tuple):
                            if len(model_output) == 2:
                                if self.predict_profit:
                                    # æ”¶ç›Šç‡ + ç½‘æ ¼è°ƒæ•´ï¼ˆä¸åº”è¯¥å‘ç”Ÿï¼‰
                                    action_logits, profit_or_grid = model_output
                                    grid_adjustment = None
                                    profit = profit_or_grid
                                else:
                                    # åŠ¨ä½œ + ç½‘æ ¼è°ƒæ•´
                                    action_logits, grid_adjustment = model_output
                                    profit = None
                            elif len(model_output) == 3:
                                # åŠ¨ä½œ + æ”¶ç›Šç‡ + ç½‘æ ¼è°ƒæ•´
                                action_logits, profit, grid_adjustment = model_output
                            else:
                                action_logits = model_output[0]
                                profit = model_output[1] if len(model_output) > 1 and self.predict_profit else None
                                grid_adjustment = model_output[2] if len(model_output) > 2 else None
                        else:
                            action_logits = model_output
                            grid_adjustment = None
                            profit = None
                        
                        # è®¡ç®—æŸå¤±
                        action_loss = self.criterion(action_logits, batch_y)
                        loss = action_loss
                        
                        # æ”¶ç›Šç‡æŸå¤±ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if self.predict_profit and profit is not None and batch_y_profit is not None and self.profit_criterion is not None:
                            profit_loss = self.profit_criterion(profit.squeeze(), batch_y_profit)
                            # æ”¶ç›Šç‡æŸå¤±æƒé‡å¢åŠ åˆ°1.0ï¼ˆä¸åŠ¨ä½œåˆ†ç±»åŒç­‰é‡è¦ï¼‰
                            loss = loss + 1.0 * profit_loss
                        
                        # ç½‘æ ¼è°ƒæ•´æŸå¤±ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if train_grid_adjustment and grid_adjustment is not None and batch_y_grid is not None and self.grid_criterion is not None:
                            batch_y_grid = batch_y_grid.to(self.device)
                            grid_loss = self.grid_criterion(grid_adjustment.squeeze(), batch_y_grid)
                            loss = loss + 0.1 * grid_loss
                        
                        val_loss += loss.item()
                        predictions = torch.argmax(action_logits, dim=1)
                        val_correct += (predictions == batch_y).sum().item()
                        val_total += batch_y.size(0)
                        
                        # ç´¯è®¡æ”¶ç›Šç‡é¢„æµ‹è¯¯å·®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                        if self.predict_profit and profit is not None and batch_y_profit is not None:
                            profit_errors = torch.abs(profit.squeeze() - batch_y_profit)
                            if not hasattr(self, '_val_profit_errors'):
                                self._val_profit_errors = []
                            self._val_profit_errors.extend(profit_errors.detach().cpu().numpy().tolist())
                
                val_avg_loss = val_loss / len(val_loader)
                val_accuracy = val_correct / val_total if val_total > 0 else 0
                val_profit_mae = np.mean(self._val_profit_errors) if hasattr(self, '_val_profit_errors') and len(self._val_profit_errors) > 0 else None
                if hasattr(self, '_val_profit_errors'):
                    delattr(self, '_val_profit_errors')
                
                # å­¦ä¹ ç‡è°ƒåº¦
                scheduler.step(val_accuracy)
                
                print(f"è®­ç»ƒè½®æ¬¡ {epoch+1}/{max_epochs}")
                print(f"  è®­ç»ƒ - æŸå¤±: {train_avg_loss:.4f}, å‡†ç¡®ç‡: {train_accuracy:.3f}")
                if train_profit_mae is not None:
                    print(f"  è®­ç»ƒ - æ”¶ç›Šç‡é¢„æµ‹è¯¯å·®(MAE): {train_profit_mae:.4f}")
                print(f"  éªŒè¯ - æŸå¤±: {val_avg_loss:.4f}, å‡†ç¡®ç‡: {val_accuracy:.3f}")
                if val_profit_mae is not None:
                    print(f"  éªŒè¯ - æ”¶ç›Šç‡é¢„æµ‹è¯¯å·®(MAE): {val_profit_mae:.4f}")
                print(f"  å­¦ä¹ ç‡: {self.optimizer.param_groups[0]['lr']:.6f}")
                
                # ä¿å­˜æœ€ä½³æ¨¡å‹å’Œæ—©åœ
                if val_accuracy > best_val_acc:
                    best_val_acc = val_accuracy
                    patience_counter = 0
                    print(f"  ğŸ† æ–°çš„æœ€ä½³éªŒè¯å‡†ç¡®ç‡: {best_val_acc:.3f}")
                    # ä¿å­˜æœ€ä½³æ¨¡å‹
                    best_model_path = os.path.join(self.data_dir, 'best_model.pth')
                    torch.save({
                        'model_state_dict': self.model.state_dict(),
                        'optimizer_state_dict': self.optimizer.state_dict(),
                        'best_val_acc': best_val_acc,
                        'epoch': epoch
                    }, best_model_path)
                else:
                    patience_counter += 1
                    if patience_counter >= patience:
                        print(f"  â¹ï¸ æ—©åœäºç¬¬ {epoch+1} è½®ï¼ˆéªŒè¯å‡†ç¡®ç‡æœªæå‡ {patience} è½®ï¼‰")
                        break
                
                self.model.train()  # é‡æ–°è®¾ç½®ä¸ºè®­ç»ƒæ¨¡å¼ä»¥è¿›è¡Œä¸‹ä¸€è½®è®­ç»ƒ
        
        except Exception as e:
            print(f"è®­ç»ƒè¿‡ç¨‹é”™è¯¯: {e}")
            import traceback
            traceback.print_exc()

    def prepare_features(self, row):
        """ä»æ•°æ®è¡Œä¸­å‡†å¤‡ç‰¹å¾å‘é‡ï¼ˆæ”¯æŒSerieså’Œå­—å…¸ï¼Œæ ¹æ®æ¨¡å¼é€‰æ‹©ä¸åŒçš„ç‰¹å¾ï¼‰"""
        try:
            # ç»Ÿä¸€è®¿é—®æ–¹å¼ï¼šåŒæ—¶æ”¯æŒSerieså’Œå­—å…¸
            def get_value(key, default=0):
                if isinstance(row, dict):
                    return row.get(key, default)
                elif isinstance(row, pd.Series):
                    return row.get(key, default) if key in row.index else default
                else:
                    return getattr(row, key, default)
            
            def get_value_safe(key, default=0, check_na=True):
                val = get_value(key, default)
                if check_na and pd.isna(val):
                    return default
                return val
            
            if self.mode == 'hybrid':
                # è®¡ç®—æ¨¡å¼ï¼šä½¿ç”¨è®¡ç®—å¥½çš„ç‰¹å¾ï¼ˆ47ç»´ï¼ŒåŒ…å«å¤šæ—¶é—´å°ºåº¦ç‰¹å¾ï¼‰
                # è·å–Tickä»·æ ¼ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
                tick_price = get_value_safe('tick_price', 0)
                if tick_price == 0:
                    # å¦‚æœtick_priceä¸å­˜åœ¨ï¼Œä½¿ç”¨price_current
                    tick_price = get_value_safe('price_current', 0)
                
                # Tickç›¸å…³ç‰¹å¾
                tick_price_change = get_value_safe('tick_price_change', 0)
                tick_volatility = get_value_safe('tick_volatility', 0)
                tick_volume = get_value_safe('tick_volume', 0)
                tick_count = get_value_safe('tick_count', 0)
                tick_buy_volume = get_value_safe('tick_buy_volume', 0)
                tick_sell_volume = get_value_safe('tick_sell_volume', 0)
                
                # è®¡ç®—Tickä¹°å–æ¯”ä¾‹ï¼ˆå¦‚æœå¯ç”¨ï¼‰
                tick_buy_sell_ratio = get_value_safe('tick_buy_sell_ratio', 0.5)
                if tick_buy_volume + tick_sell_volume > 0:
                    tick_buy_sell_ratio = tick_buy_volume / (tick_buy_volume + tick_sell_volume)
                
                # 1åˆ†é’Ÿç‰¹å¾
                atr_1m = get_value_safe('atr_1m', get_value_safe('atr', 0))
                rsi_1m = get_value_safe('rsi_1m', 50, check_na=True)
                boll_upper_1m = get_value_safe('boll_upper_1m', get_value('boll_upper', 0))
                boll_mid_1m = get_value_safe('boll_mid_1m', get_value('boll_mid', 0))
                boll_lower_1m = get_value_safe('boll_lower_1m', get_value('boll_lower', 0))
                boll_position_1m = get_value_safe('boll_position_1m', get_value('boll_position', 0.5))
                volatility_1m = get_value_safe('volatility_1m', get_value('volatility', 0))
                volume_1m = get_value_safe('volume_1m', 0)
                
                # 5åˆ†é’Ÿç‰¹å¾
                price_5m = get_value_safe('price_5m', get_value_safe('price_current', 0))
                rsi_5m = get_value_safe('rsi_5m', 50, check_na=True)
                atr_5m = get_value_safe('atr_5m', atr_1m)
                boll_upper_5m = get_value_safe('boll_upper_5m', boll_upper_1m)
                boll_mid_5m = get_value_safe('boll_mid_5m', boll_mid_1m)
                boll_lower_5m = get_value_safe('boll_lower_5m', boll_lower_1m)
                boll_position_5m = get_value_safe('boll_position_5m', boll_position_1m)
                volume_5m = get_value_safe('volume_5m', volume_1m)
                
                # 1å°æ—¶ç‰¹å¾
                price_1h = get_value_safe('price_1h', get_value_safe('price_current', 0))
                rsi_1h = get_value_safe('rsi_1h', 50, check_na=True)
                atr_1h = get_value_safe('atr_1h', atr_1m)
                boll_upper_1h = get_value_safe('boll_upper_1h', boll_upper_1m)
                boll_mid_1h = get_value_safe('boll_mid_1h', boll_mid_1m)
                boll_lower_1h = get_value_safe('boll_lower_1h', boll_lower_1m)
                boll_position_1h = get_value_safe('boll_position_1h', boll_position_1m)
                volume_1h = get_value_safe('volume_1h', volume_1m)
                trend_1h = get_value_safe('trend_1h', 0.5)  # 0=ä¸‹è·Œ, 0.5=æ¨ªç›˜, 1=ä¸Šæ¶¨
                
                # æ—¥çº¿ç‰¹å¾
                price_1d = get_value_safe('price_1d', get_value_safe('price_current', 0))
                rsi_1d = get_value_safe('rsi_1d', 50, check_na=True)
                atr_1d = get_value_safe('atr_1d', atr_1m)
                boll_upper_1d = get_value_safe('boll_upper_1d', boll_upper_1m)
                boll_mid_1d = get_value_safe('boll_mid_1d', boll_mid_1m)
                boll_lower_1d = get_value_safe('boll_lower_1d', boll_lower_1m)
                boll_position_1d = get_value_safe('boll_position_1d', boll_position_1m)
                volume_1d = get_value_safe('volume_1d', volume_1m)
                trend_1d = get_value_safe('trend_1d', 0.5)
                ma_5d = get_value_safe('ma_5d', price_1d)
                ma_10d = get_value_safe('ma_10d', price_1d)
                ma_20d = get_value_safe('ma_20d', price_1d)
                
                # ç½‘æ ¼å‚æ•°
                grid_lower = get_value('grid_lower', boll_lower_1m)
                grid_upper = get_value('grid_upper', boll_upper_1m)
                
                # æ„å»º47ç»´ç‰¹å¾å‘é‡
                features = [
                    # åŸºç¡€ç‰¹å¾ï¼ˆ1åˆ†é’Ÿï¼‰- 16ç»´
                    get_value_safe('price_current', 0),  # 0: Kçº¿ä»·æ ¼
                    tick_price,  # 1: çœŸå®Tickä»·æ ¼
                    tick_price_change,  # 2: Tickä»·æ ¼å˜åŒ–
                    tick_volatility,  # 3: Tickæ³¢åŠ¨ç‡
                    tick_volume,  # 4: Tickæˆäº¤é‡
                    tick_count,  # 5: Tickæ•°é‡
                    tick_buy_sell_ratio,  # 6: Tickä¹°å–æ¯”ä¾‹
                    atr_1m,  # 7: 1åˆ†é’ŸATR
                    rsi_1m,  # 8: 1åˆ†é’ŸRSI
                    boll_upper_1m,  # 9: 1åˆ†é’Ÿå¸ƒæ—å¸¦ä¸Šè½¨
                    boll_mid_1m,  # 10: 1åˆ†é’Ÿå¸ƒæ—å¸¦ä¸­è½¨
                    boll_lower_1m,  # 11: 1åˆ†é’Ÿå¸ƒæ—å¸¦ä¸‹è½¨
                    boll_position_1m,  # 12: 1åˆ†é’Ÿå¸ƒæ—å¸¦ä½ç½®
                    volatility_1m,  # 13: 1åˆ†é’Ÿæ³¢åŠ¨ç‡
                    volume_1m,  # 14: 1åˆ†é’Ÿæˆäº¤é‡
                    # 5åˆ†é’Ÿç‰¹å¾ - 8ç»´
                    price_5m,  # 15: 5åˆ†é’Ÿä»·æ ¼
                    rsi_5m,  # 16: 5åˆ†é’ŸRSI
                    atr_5m,  # 17: 5åˆ†é’ŸATR
                    boll_upper_5m,  # 18: 5åˆ†é’Ÿå¸ƒæ—å¸¦ä¸Šè½¨
                    boll_mid_5m,  # 19: 5åˆ†é’Ÿå¸ƒæ—å¸¦ä¸­è½¨
                    boll_lower_5m,  # 20: 5åˆ†é’Ÿå¸ƒæ—å¸¦ä¸‹è½¨
                    boll_position_5m,  # 21: 5åˆ†é’Ÿå¸ƒæ—å¸¦ä½ç½®
                    volume_5m,  # 22: 5åˆ†é’Ÿæˆäº¤é‡
                    # 1å°æ—¶ç‰¹å¾ - 9ç»´
                    price_1h,  # 23: 1å°æ—¶ä»·æ ¼
                    rsi_1h,  # 24: 1å°æ—¶RSI
                    atr_1h,  # 25: 1å°æ—¶ATR
                    boll_upper_1h,  # 26: 1å°æ—¶å¸ƒæ—å¸¦ä¸Šè½¨
                    boll_mid_1h,  # 27: 1å°æ—¶å¸ƒæ—å¸¦ä¸­è½¨
                    boll_lower_1h,  # 28: 1å°æ—¶å¸ƒæ—å¸¦ä¸‹è½¨
                    boll_position_1h,  # 29: 1å°æ—¶å¸ƒæ—å¸¦ä½ç½®
                    volume_1h,  # 30: 1å°æ—¶æˆäº¤é‡
                    trend_1h,  # 31: 1å°æ—¶è¶‹åŠ¿
                    # æ—¥çº¿ç‰¹å¾ - 11ç»´
                    price_1d,  # 32: æ—¥çº¿ä»·æ ¼
                    rsi_1d,  # 33: æ—¥çº¿RSI
                    atr_1d,  # 34: æ—¥çº¿ATR
                    boll_upper_1d,  # 35: æ—¥çº¿å¸ƒæ—å¸¦ä¸Šè½¨
                    boll_mid_1d,  # 36: æ—¥çº¿å¸ƒæ—å¸¦ä¸­è½¨
                    boll_lower_1d,  # 37: æ—¥çº¿å¸ƒæ—å¸¦ä¸‹è½¨
                    boll_position_1d,  # 38: æ—¥çº¿å¸ƒæ—å¸¦ä½ç½®
                    volume_1d,  # 39: æ—¥çº¿æˆäº¤é‡
                    trend_1d,  # 40: æ—¥çº¿è¶‹åŠ¿
                    ma_5d,  # 41: 5æ—¥å‡çº¿
                    ma_10d,  # 42: 10æ—¥å‡çº¿
                    ma_20d,  # 43: 20æ—¥å‡çº¿
                    # ç½‘æ ¼å‚æ•° - 2ç»´
                    grid_lower,  # 44: ç½‘æ ¼ä¸‹è½¨
                    grid_upper,  # 45: ç½‘æ ¼ä¸Šè½¨
                ]
                feature_size = 46  # 46ç»´å¤šæ—¶é—´å°ºåº¦ç‰¹å¾ï¼ˆä¸åŒ…å«timestampï¼‰
            elif self.mode == 'pure_ml':
                # å¤§æ¨¡å‹è¯†åˆ«æ¨¡å¼ï¼šåªä½¿ç”¨åŸå§‹OHLCVæ•°æ®ï¼ˆ10ç»´ï¼š1må’Œ5må„5ä¸ªï¼‰
                # 1åˆ†é’Ÿæ•°æ®
                features = [
                    get_value_safe('open_1m', 0),
                    get_value_safe('high_1m', 0),
                    get_value_safe('low_1m', 0),
                    get_value_safe('close_1m', get_value_safe('price_current', 0)),
                    get_value_safe('volume_1m', 0),
                    # 5åˆ†é’Ÿæ•°æ®
                    get_value_safe('open_5m', 0),
                    get_value_safe('high_5m', 0),
                    get_value_safe('low_5m', 0),
                    get_value_safe('close_5m', get_value_safe('price_current', 0)),
                    get_value_safe('volume_5m', 0)
                ]
                feature_size = 10
            else:
                raise ValueError(f"æœªçŸ¥çš„æ¨¡å¼: {self.mode}")
            
            # å½’ä¸€åŒ–ç‰¹å¾
            features_np = np.array(features, dtype=np.float32)
            mean_val = np.mean(features_np)
            std_val = np.std(features_np) + 1e-8
            normalized_features = (features_np - mean_val) / std_val
            return normalized_features.tolist()
        except Exception as e:
            print(f"prepare_featuresé”™è¯¯: {e}")
            import traceback
            traceback.print_exc()
            # è¿”å›é»˜è®¤ç‰¹å¾å€¼
            feature_size = 46 if self.mode == 'hybrid' else 10  # hybridæ¨¡å¼ç°åœ¨åŒ…å«å¤šæ—¶é—´å°ºåº¦ç‰¹å¾
            return [0.0] * feature_size
    
    
    
    def predict_action(self, current_data, historical_data=None):
        """
        ä½¿ç”¨æ¨¡å‹é¢„æµ‹äº¤æ˜“åŠ¨ä½œ
        
        Args:
            current_data: å½“å‰æ•°æ®å­—å…¸
            historical_data: å†å²æ•°æ®DataFrameï¼ˆå¯é€‰ï¼‰
        
        Returns:
            (action, confidence, profit_prediction) æˆ– (action, confidence)
        """
        with self.model_lock:
            try:
                # å‡†å¤‡è¾“å…¥æ•°æ®ï¼ˆæ”¯æŒåºåˆ—è¾“å…¥ï¼‰
                # å¦‚æœæä¾›äº†å†å²æ•°æ®å’Œåºåˆ—é•¿åº¦ï¼Œä½¿ç”¨åºåˆ—æ•°æ®
                if hasattr(self, '_seq_length') and self._seq_length > 1 and hasattr(self, '_historical_data'):
                    historical_data = self._historical_data
                    seq_length = self._seq_length
                    if historical_data is not None and len(historical_data) >= seq_length:
                        # ä½¿ç”¨å†å²åºåˆ—æ•°æ®
                        # å‡è®¾current_dataæ˜¯historical_dataçš„æœ€åä¸€è¡Œæˆ–å½“å‰è¡Œ
                        try:
                            if isinstance(current_data, pd.Series):
                                current_idx = len(historical_data) - 1
                            else:
                                current_idx = len(historical_data) - 1
                            sequence = self.prepare_sequence_features(historical_data, current_idx, seq_length)
                            input_tensor = torch.tensor([sequence], dtype=torch.float32).to(self.device)
                        except Exception as e:
                            # é™çº§åˆ°å•ç‚¹ç‰¹å¾
                            features = self.prepare_features(current_data)
                            input_tensor = torch.tensor([features], dtype=torch.float32).unsqueeze(1).to(self.device)
                    else:
                        # æ•°æ®ä¸è¶³ï¼Œä½¿ç”¨å•ç‚¹ç‰¹å¾
                        features = self.prepare_features(current_data)
                        input_tensor = torch.tensor([features], dtype=torch.float32).unsqueeze(1).to(self.device)
                else:
                    # é»˜è®¤ä½¿ç”¨å•ç‚¹ç‰¹å¾ï¼ˆå‘åå…¼å®¹ï¼‰
                    features = self.prepare_features(current_data)
                    input_tensor = torch.tensor([features], dtype=torch.float32).unsqueeze(1).to(self.device)
                
                # é¢„æµ‹
                with torch.no_grad():
                    self.model.eval()
                    model_output = self.model(input_tensor)
                    
                    # å¤„ç†æ¨¡å‹è¾“å‡ºï¼ˆå¯èƒ½æ˜¯åŠ¨ä½œlogitsã€(action_logits, grid_adjustment)æˆ–(action_logits, profit, grid_adjustment)ï¼‰
                    action_logits = None
                    profit = None
                    grid_adjustment_value = 1.0
                    
                    if isinstance(model_output, tuple):
                        if len(model_output) == 2:
                            if self.predict_profit:
                                # æ”¶ç›Šç‡ + ç½‘æ ¼è°ƒæ•´ï¼ˆæ²¡æœ‰åŠ¨ä½œå¤´ï¼Ÿè¿™ä¸åº”è¯¥å‘ç”Ÿï¼‰
                                action_logits, profit_or_grid = model_output
                                if self.model.predict_grid_adjustment:
                                    profit, grid_adjustment = profit_or_grid, model_output[1] if len(model_output) > 1 else None
                                    grid_adjustment_value = float(grid_adjustment.cpu().item()) if grid_adjustment is not None else 1.0
                                else:
                                    profit = profit_or_grid
                            else:
                                # åŠ¨ä½œ + ç½‘æ ¼è°ƒæ•´
                                action_logits, grid_adjustment = model_output
                                grid_adjustment_value = float(grid_adjustment.cpu().item())
                        elif len(model_output) == 3:
                            # åŠ¨ä½œ + æ”¶ç›Šç‡ + ç½‘æ ¼è°ƒæ•´
                            action_logits, profit, grid_adjustment = model_output
                            grid_adjustment_value = float(grid_adjustment.cpu().item())
                        else:
                            action_logits = model_output[0]
                            profit = model_output[1] if len(model_output) > 1 and self.predict_profit else None
                            grid_adjustment = model_output[2] if len(model_output) > 2 else None
                            grid_adjustment_value = float(grid_adjustment.cpu().item()) if grid_adjustment is not None else 1.0
                    else:
                        action_logits = model_output
                    
                    # è®¡ç®—åŠ¨ä½œæ¦‚ç‡
                    probabilities = torch.softmax(action_logits, dim=1).cpu().numpy().flatten() if action_logits.dim() > 1 else torch.softmax(action_logits, dim=1).cpu().numpy()
                    if hasattr(probabilities, 'shape') and probabilities.shape and len(probabilities.shape) > 1:
                        probabilities = probabilities[0]
                    elif not isinstance(probabilities, np.ndarray):
                        probabilities = np.array([probabilities])
                    
                    # è¿”å›æœ€å¯èƒ½çš„åŠ¨ä½œ: 0=ä¸æ“ä½œ, 1=ä¹°å…¥, 2=å–å‡º
                    action = np.argmax(probabilities)
                    base_confidence = probabilities[action]
                    
                    # å¦‚æœå¯ç”¨äº†æ”¶ç›Šç‡é¢„æµ‹ï¼Œä½¿ç”¨æ”¶ç›Šç‡é¢„æµ‹æ¥è°ƒæ•´ç½®ä¿¡åº¦
                    if self.predict_profit and profit is not None:
                        # åœ¨æ¨ç†æ—¶åº”ç”¨ReLUå’Œclampé™åˆ¶è¾“å‡ºèŒƒå›´
                        profit = torch.relu(profit)  # ç¡®ä¿éè´Ÿ
                        profit = torch.clamp(profit, max=0.3)  # é™åˆ¶ä¸Šé™ä¸º0.3ï¼ˆ30%ï¼‰
                        profit_value = float(profit.cpu().item())
                        
                        # åŸºäºæ”¶ç›Šç‡é¢„æµ‹è°ƒæ•´ç½®ä¿¡åº¦
                        if action == 1:  # ä¹°å…¥
                            # é¢„æµ‹æ”¶ç›Šç‡è¶Šé«˜ï¼Œç½®ä¿¡åº¦è¶Šé«˜
                            # å‡è®¾5%ä¸ºé«˜æ”¶ç›Šï¼Œå°†æ”¶ç›Šç‡æ˜ å°„åˆ°[0, 1]
                            profit_confidence = min(1.0, max(0.0, profit_value / 0.05))
                            # ç»“åˆåŠ¨ä½œåˆ†ç±»ç½®ä¿¡åº¦å’Œæ”¶ç›Šç‡ç½®ä¿¡åº¦ï¼ˆæ”¶ç›Šç‡æƒé‡æ›´é«˜ï¼‰
                            confidence = (base_confidence * 0.3 + profit_confidence * 0.7)
                        elif action == 2:  # å–å‡º
                            # é¢„æµ‹æ”¶ç›Šç‡è¶Šä½ï¼ˆè´Ÿå€¼ï¼‰ï¼Œç½®ä¿¡åº¦è¶Šé«˜
                            profit_confidence = min(1.0, max(0.0, abs(profit_value) / 0.05))
                            confidence = (base_confidence * 0.3 + profit_confidence * 0.7)
                        else:  # ä¸æ“ä½œ
                            # æ”¶ç›Šç‡æ¥è¿‘0æ—¶ï¼Œä¸æ“ä½œçš„ç½®ä¿¡åº¦é«˜
                            profit_confidence = 1.0 - min(1.0, abs(profit_value) / 0.02)
                            confidence = (base_confidence * 0.5 + profit_confidence * 0.5)
                    else:
                        # æ²¡æœ‰æ”¶ç›Šç‡é¢„æµ‹ï¼Œä½¿ç”¨åŠ¨ä½œåˆ†ç±»çš„ç½®ä¿¡åº¦
                        confidence = base_confidence
                        profit_value = None
                    
                    # è¿”å›ç»“æœï¼ˆç»Ÿä¸€æ¥å£ï¼š(action, confidence, profit_prediction)ï¼‰
                    if self.predict_profit and profit is not None:
                        profit_value = float(profit.cpu().item())
                        return int(action), float(confidence), float(profit_value)
                    else:
                        return int(action), float(confidence), None
            except Exception as e:
                print(f"é¢„æµ‹é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                return 0, 0.0, None  # é»˜è®¤ä¸æ“ä½œ
    
    def load_training_data(self):
        """åŠ è½½è®­ç»ƒæ•°æ®"""
        # è·å–æœ€æ–°çš„æ•°æ®æ–‡ä»¶
        all_data_files = []
        
        # è·å–æ‰€æœ‰æ•°æ®ç›®å½•
        all_data_dirs = glob.glob(os.path.join(self.data_dir, '202*-*-*'))
        if all_data_dirs:
            # æŒ‰æ—¥æœŸæ’åºï¼Œè·å–æœ€æ–°çš„å‡ ä¸ªæ–‡ä»¶
            sorted_dirs = sorted(all_data_dirs, reverse=True)
            for data_dir in sorted_dirs[:7]:  # ä½¿ç”¨æœ€è¿‘7å¤©çš„æ•°æ®
                # åŒ…å«åŸå§‹æ•°æ®å’Œæ‰©å±•æ•°æ®
                data_files = glob.glob(os.path.join(data_dir, 'trading_data_*.csv'))
                data_files.extend(glob.glob(os.path.join(data_dir, 'extended_trading_data_*.csv')))
                data_files.extend(glob.glob(os.path.join(data_dir, 'prepared_features_*.csv')))  # ä¹ŸåŒ…å«å‡†å¤‡å¥½çš„ç‰¹å¾æ•°æ®
                all_data_files.extend(data_files)
        
        if not all_data_files:
            return None
        
        # æŒ‰ä¿®æ”¹æ—¶é—´æ’åºï¼Œè·å–æœ€æ–°çš„æ–‡ä»¶
        data_file = sorted(all_data_files, key=os.path.getmtime, reverse=True)[0]
        
        try:
            df = pd.read_csv(data_file)
            # æ¸…ç†æ•°æ®
            df = df.dropna(subset=['price_current', 'grid_lower', 'grid_upper', 'atr', 'rsi_1m', 'rsi_5m'])
            
            if len(df) < 10:  # éœ€è¦è‡³å°‘10ä¸ªæ ·æœ¬è¿›è¡Œè®­ç»ƒ
                return None
                
            return df
        except Exception as e:
            print(f"åŠ è½½è®­ç»ƒæ•°æ®é”™è¯¯: {e}")
            return None
    
    def train_continuously(self):
        """è¿ç»­è®­ç»ƒæ¨¡å‹çš„åå°çº¿ç¨‹"""
        while self.should_train:
            try:
                # åŠ è½½æ•°æ®
                df = self.load_training_data()
                if df is not None and len(df) > 0:
                    print(f"å¼€å§‹è®­ç»ƒæ¨¡å‹ï¼Œæ•°æ®é‡: {len(df)}")
                    with self.model_lock:
                        self.train_model(df)
                    print("æ¨¡å‹è®­ç»ƒå®Œæˆ")
                
                # è®­ç»ƒè¾ƒæ…¢ï¼Œæ¯30åˆ†é’Ÿè®­ç»ƒä¸€æ¬¡
                time.sleep(1800)
                
            except Exception as e:
                print(f"è®­ç»ƒçº¿ç¨‹é”™è¯¯: {e}")
                import traceback
                traceback.print_exc()
                time.sleep(60)  # å‡ºé”™åç­‰å¾…1åˆ†é’Ÿåç»§ç»­
    
    def save_model(self, path):
        """ä¿å­˜æ¨¡å‹"""
        with self.model_lock:
            torch.save({
                'model_state_dict': self.model.state_dict(),
                'optimizer_state_dict': self.optimizer.state_dict(),
            }, path)
            print(f"æ¨¡å‹å·²ä¿å­˜åˆ° {path}")


def main():
    parser = argparse.ArgumentParser(description='LLM Trading Strategy')
    parser.add_argument('--mode', choices=['train', 'predict', 'both'], default='both',
                        help='è¿è¡Œæ¨¡å¼: train(ä»…è®­ç»ƒ), predict(ä»…é¢„æµ‹), both(å…¨éƒ¨)')
    parser.add_argument('--model_path', type=str, default=None,
                        help='æ¨¡å‹ä¿å­˜æˆ–åŠ è½½è·¯å¾„')
    args = parser.parse_args()
    
    strategy = LLMTradingStrategy(model_path=args.model_path)
    
    if args.mode == 'train':
        print("ä»…è¿è¡Œè®­ç»ƒæ¨¡å¼...")
        # è®­ç»ƒæ¨¡å¼ï¼Œä¸é€€å‡º
        try:
            while True:
                time.sleep(60)
        except KeyboardInterrupt:
            print("è®­ç»ƒå·²åœæ­¢")
    elif args.mode == 'predict':
        print("ä»…è¿è¡Œé¢„æµ‹æ¨¡å¼...")
        # é¢„æµ‹æ¨¡å¼ï¼Œæ¼”ç¤ºå¦‚ä½•ä½¿ç”¨
        sample_data = {
            'price_current': 93.5,
            'grid_lower': 93.0,
            'grid_upper': 94.0,
            'atr': 0.2,
            'rsi_1m': 30.0,
            'rsi_5m': 40.0,
            'buffer': 0.05,
            'threshold': 93.05,
            'near_lower': True,
            'rsi_ok': True
        }
        
        action, confidence = strategy.predict_action(sample_data)
        action_map = {0: "ä¸æ“ä½œ", 1: "ä¹°å…¥", 2: "å–å‡º"}
        print(f"é¢„æµ‹åŠ¨ä½œ: {action_map[action]}, ç½®ä¿¡åº¦: {confidence:.3f}")
        
        try:
            while True:
                time.sleep(60)
        except KeyboardInterrupt:
            print("ç¨‹åºå·²åœæ­¢")
    else:
        print("è¿è¡Œè®­ç»ƒå’Œé¢„æµ‹æ¨¡å¼...")
        try:
            while True:
                time.sleep(60)
        except KeyboardInterrupt:
            print("ç¨‹åºå·²åœæ­¢")
    
    # å¦‚æœæä¾›äº†ä¿å­˜è·¯å¾„ï¼Œä¿å­˜æ¨¡å‹
    if args.model_path:
        strategy.save_model(args.model_path)


if __name__ == "__main__":
    main()