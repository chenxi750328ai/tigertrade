#!/usr/bin/env python3
"""
å¤§è§„æ¨¡1åˆ†é’ŸKçº¿æ•°æ®é‡‡é›† - ç›®æ ‡2ä¸‡+æ¡æ•°æ®
"""

import sys
import os
import time
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
import argparse

sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))

from config import DataConfig, LabelConfig, DataSplitConfig, FeatureConfig
from tiger1 import get_kline_data, calculate_indicators, FUTURE_SYMBOL


class Massive1MinCollector:
    """å¤§è§„æ¨¡1åˆ†é’ŸKçº¿æ•°æ®é‡‡é›†å™¨"""
    
    def __init__(self, days=90, output_dir='/home/cx/trading_data/massive_1min'):
        """
        åˆå§‹åŒ–
        
        Args:
            days: è·å–å¤©æ•°ï¼ˆç™½é“¶æœŸè´§SIL.COMEX.202603ï¼‰
            output_dir: è¾“å‡ºç›®å½•
        """
        self.days = days
        self.output_dir = output_dir
        self.timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        os.makedirs(output_dir, exist_ok=True)
        
        self.log_file = os.path.join(output_dir, f'collection_log_{self.timestamp}.txt')
        self._log(f"ğŸš€ åˆå§‹åŒ–å¤§è§„æ¨¡1åˆ†é’Ÿæ•°æ®é‡‡é›†å™¨")
        self._log(f"   äº¤æ˜“æ ‡çš„: ç™½é“¶æœŸè´§ SIL.COMEX.202603")
        self._log(f"   ç›®æ ‡å¤©æ•°: {days} å¤©")
        self._log(f"   é¢„è®¡1åˆ†é’Ÿæ•°æ®é‡: ~{days * 6 * 60:,} æ¡ï¼ˆæŒ‰æ¯å¤©çº¦6å°æ—¶äº¤æ˜“ä¼°ç®—ï¼‰")
    
    def _log(self, message):
        """è®°å½•æ—¥å¿—"""
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        log_message = f"[{timestamp}] {message}"
        print(log_message)
        
        with open(self.log_file, 'a', encoding='utf-8') as f:
            f.write(log_message + '\n')
    
    def fetch_1min_data(self):
        """è·å–1åˆ†é’ŸKçº¿æ•°æ®"""
        self._log(f"{'='*80}")
        self._log(f"ğŸ“¥ å¼€å§‹è·å–1åˆ†é’ŸKçº¿æ•°æ®...")
        
        # è®¡ç®—éœ€è¦çš„æ•°é‡
        # ç™½é“¶æœŸè´§äº¤æ˜“æ—¶é—´æœ‰é™ï¼Œä¿å®ˆä¼°è®¡æ¯å¤©çº¦6å°æ—¶æœ‰æ•ˆäº¤æ˜“æ—¶é—´
        # ä½†æˆ‘ä»¬è¯·æ±‚æ›´å¤šæ•°æ®ï¼Œè®©APIè¿”å›å®é™…å¯ç”¨çš„
        expected_count = self.days * 1440  # è¯·æ±‚è¶³å¤Ÿå¤šï¼ŒAPIä¼šè¿”å›å®é™…æœ‰çš„
        
        self._log(f"   è¯·æ±‚æ•°é‡: {expected_count:,} æ¡1åˆ†é’ŸKçº¿")
        
        try:
            # è·å–1åˆ†é’Ÿæ•°æ®
            df_1min = get_kline_data([FUTURE_SYMBOL], "1min", count=expected_count)
            
            if df_1min.empty:
                self._log(f"âŒ 1åˆ†é’Ÿæ•°æ®ä¸ºç©º")
                return None
            
            self._log(f"âœ… æˆåŠŸè·å–1åˆ†é’Ÿæ•°æ®: {len(df_1min):,} æ¡")
            self._log(f"   æ—¶é—´èŒƒå›´: {df_1min.index[0]} è‡³ {df_1min.index[-1]}")
            
            # åŒæ—¶è·å–5åˆ†é’Ÿæ•°æ®ç”¨äºè®¡ç®—ä¸€äº›æŒ‡æ ‡
            expected_5min = self.days * 24 * 12  # 5åˆ†é’Ÿæ•°æ®
            df_5min = get_kline_data([FUTURE_SYMBOL], "5min", count=expected_5min)
            
            if df_5min.empty:
                self._log(f"âš ï¸ 5åˆ†é’Ÿæ•°æ®ä¸ºç©ºï¼Œå°†åªä½¿ç”¨1åˆ†é’Ÿæ•°æ®")
                df_5min = None
            else:
                self._log(f"âœ… æˆåŠŸè·å–5åˆ†é’Ÿæ•°æ®: {len(df_5min):,} æ¡")
            
            return df_1min, df_5min
            
        except Exception as e:
            self._log(f"âŒ è·å–æ•°æ®å¤±è´¥: {e}")
            import traceback
            self._log(traceback.format_exc())
            return None, None
    
    def calculate_features_from_1min(self, df_1min, df_5min):
        """ä»1åˆ†é’Ÿæ•°æ®è®¡ç®—ç‰¹å¾"""
        self._log(f"{'='*80}")
        self._log(f"ğŸ”§ å¼€å§‹è®¡ç®—ç‰¹å¾...")
        
        features_list = []
        min_len = 60  # è‡³å°‘éœ€è¦60æ ¹1åˆ†é’ŸKçº¿ï¼ˆ1å°æ—¶ï¼‰
        
        if len(df_1min) < min_len:
            self._log(f"âŒ æ•°æ®ä¸è¶³ï¼Œéœ€è¦è‡³å°‘ {min_len} æ¡")
            return pd.DataFrame()
        
        self._log(f"   1åˆ†é’Ÿæ•°æ®é‡: {len(df_1min):,}")
        if df_5min is not None:
            self._log(f"   5åˆ†é’Ÿæ•°æ®é‡: {len(df_5min):,}")
        
        window_size = 60  # ä½¿ç”¨60åˆ†é’Ÿä½œä¸ºçª—å£
        total = len(df_1min) - min_len
        
        self._log(f"   å¼€å§‹è®¡ç®— {total:,} æ¡ç‰¹å¾...")
        
        for i in range(min_len, len(df_1min)):
            if (i - min_len) % 1000 == 0:
                progress = (i - min_len) / total * 100
                self._log(f"   è¿›åº¦: {progress:.1f}% ({i-min_len:,}/{total:,})")
            
            try:
                # è·å–1åˆ†é’Ÿæ•°æ®çª—å£
                window_1m = df_1min.iloc[max(0, i-window_size):i+1]
                current_timestamp = df_1min.index[i]
                
                # è·å–å¯¹åº”çš„5åˆ†é’Ÿæ•°æ®
                if df_5min is not None:
                    df_5min_slice = df_5min[df_5min.index <= current_timestamp]
                    if len(df_5min_slice) >= 20:
                        window_5m = df_5min_slice.iloc[-20:]
                    else:
                        window_5m = None
                else:
                    window_5m = None
                
                # è®¡ç®—æŒ‡æ ‡
                if window_5m is not None and len(window_5m) > 0:
                    inds = calculate_indicators(window_5m, window_1m)
                else:
                    # å¦‚æœæ²¡æœ‰5åˆ†é’Ÿæ•°æ®ï¼Œç”¨1åˆ†é’Ÿæ•°æ®ä»£æ›¿
                    inds = calculate_indicators(window_1m, window_1m)
                
                if '1m' not in inds:
                    continue
                
                # æå–ç‰¹å¾
                price_current = inds['1m']['close']
                
                # ATRï¼ˆä»5åˆ†é’Ÿæˆ–1åˆ†é’Ÿï¼‰
                if '5m' in inds and 'atr' in inds['5m']:
                    atr = inds['5m']['atr']
                else:
                    atr = inds['1m'].get('atr', price_current * 0.01)
                
                # RSI
                rsi_1m = inds['1m'].get('rsi', 50)
                rsi_5m = inds.get('5m', {}).get('rsi', 50)
                
                # å¸ƒæ—å¸¦
                boll_upper = inds.get('5m', {}).get('boll_upper', 0)
                boll_mid = inds.get('5m', {}).get('boll_mid', price_current)
                boll_lower = inds.get('5m', {}).get('boll_lower', 0)
                
                # æˆäº¤é‡
                volume_1m = inds['1m'].get('volume', 0)
                
                # è®¡ç®—ä»·æ ¼å˜åŒ–ç‡
                if len(window_1m) >= 2:
                    price_change_1 = (price_current - window_1m['close'].iloc[-2]) / window_1m['close'].iloc[-2] * 100
                else:
                    price_change_1 = 0
                
                if len(window_1m) >= 6:
                    price_change_5 = (price_current - window_1m['close'].iloc[-6]) / window_1m['close'].iloc[-6] * 100
                else:
                    price_change_5 = 0
                
                # æ³¢åŠ¨ç‡ï¼ˆåŸºäºæœ€è¿‘60åˆ†é’Ÿï¼‰
                volatility = window_1m['close'].std() / window_1m['close'].mean() * 100 if len(window_1m) > 1 else 0
                
                # å¸ƒæ—å¸¦ä½ç½®
                if (boll_upper - boll_lower) > 0:
                    boll_position = (price_current - boll_lower) / (boll_upper - boll_lower)
                else:
                    boll_position = 0.5
                
                # ç½‘æ ¼å‚æ•°ï¼ˆç®€åŒ–ç‰ˆï¼‰
                grid_upper = price_current * 1.005  # 0.5%
                grid_lower = price_current * 0.995
                
                features = {
                    'timestamp': current_timestamp,
                    'price_current': price_current,
                    'atr': atr,
                    'rsi_1m': rsi_1m,
                    'rsi_5m': rsi_5m,
                    'boll_upper': boll_upper,
                    'boll_mid': boll_mid,
                    'boll_lower': boll_lower,
                    'boll_position': boll_position,
                    'volume': volume_1m,
                    'price_change_1min': price_change_1,
                    'price_change_5min': price_change_5,
                    'volatility': volatility,
                }
                
                features_list.append(features)
                
            except Exception as e:
                if (i - min_len) % 1000 == 0:
                    self._log(f"   âš ï¸ è®¡ç®—ç‰¹å¾å‡ºé”™ (ç´¢å¼• {i}): {e}")
                continue
        
        df_features = pd.DataFrame(features_list)
        self._log(f"âœ… ç‰¹å¾è®¡ç®—å®Œæˆ: {len(df_features):,} æ¡è®°å½•")
        
        return df_features
    
    def generate_labels(self, df, look_ahead=5):
        """ç”Ÿæˆè®­ç»ƒæ ‡ç­¾"""
        self._log(f"{'='*80}")
        self._log(f"ğŸ·ï¸  å¼€å§‹ç”Ÿæˆæ ‡ç­¾...")
        self._log(f"   å‰ç»å‘¨æœŸ: {look_ahead} åˆ†é’Ÿ")
        
        df = df.copy()
        df['label'] = 0  # 0=æŒæœ‰, 1=ä¹°å…¥, 2=å–å‡º
        
        # ä½¿ç”¨ä»·æ ¼å˜åŒ–ä½œä¸ºæ ‡ç­¾
        buy_threshold = 0.3  # 0.3%ä¸Šæ¶¨
        sell_threshold = -0.3  # 0.3%ä¸‹è·Œ
        
        for i in range(len(df) - look_ahead):
            current_price = df.iloc[i]['price_current']
            future_price = df.iloc[i + look_ahead]['price_current']
            price_change_pct = (future_price - current_price) / current_price * 100
            
            if price_change_pct > buy_threshold:
                df.iloc[i, df.columns.get_loc('label')] = 1  # ä¹°å…¥
            elif price_change_pct < sell_threshold:
                df.iloc[i, df.columns.get_loc('label')] = 2  # å–å‡º
        
        # ç»Ÿè®¡æ ‡ç­¾åˆ†å¸ƒ
        label_counts = df['label'].value_counts().sort_index()
        total = len(df)
        
        self._log(f"\n   æ ‡ç­¾åˆ†å¸ƒ:")
        self._log(f"   æŒæœ‰(0): {label_counts.get(0, 0):,} ({label_counts.get(0, 0)/total*100:.1f}%)")
        self._log(f"   ä¹°å…¥(1): {label_counts.get(1, 0):,} ({label_counts.get(1, 0)/total*100:.1f}%)")
        self._log(f"   å–å‡º(2): {label_counts.get(2, 0):,} ({label_counts.get(2, 0)/total*100:.1f}%)")
        
        return df
    
    def split_dataset(self, df):
        """åˆ’åˆ†æ•°æ®é›†ï¼ˆä½¿ç”¨åˆ†å±‚é‡‡æ ·ï¼‰"""
        self._log(f"{'='*80}")
        self._log(f"ğŸ“Š åˆ’åˆ†æ•°æ®é›†...")
        
        from sklearn.model_selection import train_test_split
        
        # ç¬¬ä¸€æ¬¡åˆ†å‰²ï¼šåˆ†ç¦»æµ‹è¯•é›†
        train_val, test = train_test_split(
            df,
            test_size=0.15,
            random_state=42,
            stratify=df['label']
        )
        
        # ç¬¬äºŒæ¬¡åˆ†å‰²ï¼šåˆ†ç¦»è®­ç»ƒé›†å’ŒéªŒè¯é›†
        train, val = train_test_split(
            train_val,
            test_size=0.15 / 0.85,  # ç¡®ä¿éªŒè¯é›†å æ€»æ•°æ®çš„15%
            random_state=42,
            stratify=train_val['label']
        )
        
        self._log(f"\n   æ•°æ®é›†å¤§å°:")
        self._log(f"   è®­ç»ƒé›†: {len(train):,} æ¡ ({len(train)/len(df)*100:.1f}%)")
        self._log(f"   éªŒè¯é›†: {len(val):,} æ¡ ({len(val)/len(df)*100:.1f}%)")
        self._log(f"   æµ‹è¯•é›†: {len(test):,} æ¡ ({len(test)/len(df)*100:.1f}%)")
        
        # æ‰“å°å„é›†çš„æ ‡ç­¾åˆ†å¸ƒ
        for name, data in [('è®­ç»ƒé›†', train), ('éªŒè¯é›†', val), ('æµ‹è¯•é›†', test)]:
            counts = data['label'].value_counts().sort_index()
            self._log(f"\n   {name}æ ‡ç­¾åˆ†å¸ƒ:")
            self._log(f"     æŒæœ‰(0): {counts.get(0, 0):,} ({counts.get(0, 0)/len(data)*100:.1f}%)")
            self._log(f"     ä¹°å…¥(1): {counts.get(1, 0):,} ({counts.get(1, 0)/len(data)*100:.1f}%)")
            self._log(f"     å–å‡º(2): {counts.get(2, 0):,} ({counts.get(2, 0)/len(data)*100:.1f}%)")
        
        return train, val, test
    
    def save_datasets(self, train, val, test, full_df):
        """ä¿å­˜æ•°æ®é›†"""
        self._log(f"{'='*80}")
        self._log(f"ğŸ’¾ ä¿å­˜æ•°æ®é›†...")
        
        files = {}
        
        train_file = os.path.join(self.output_dir, f'train_{self.timestamp}.csv')
        train.to_csv(train_file, index=True)
        self._log(f"   âœ… è®­ç»ƒé›†: {train_file}")
        files['train'] = train_file
        
        val_file = os.path.join(self.output_dir, f'val_{self.timestamp}.csv')
        val.to_csv(val_file, index=True)
        self._log(f"   âœ… éªŒè¯é›†: {val_file}")
        files['val'] = val_file
        
        test_file = os.path.join(self.output_dir, f'test_{self.timestamp}.csv')
        test.to_csv(test_file, index=True)
        self._log(f"   âœ… æµ‹è¯•é›†: {test_file}")
        files['test'] = test_file
        
        full_file = os.path.join(self.output_dir, f'full_{self.timestamp}.csv')
        full_df.to_csv(full_file, index=True)
        self._log(f"   âœ… å®Œæ•´æ•°æ®: {full_file}")
        files['full'] = full_file
        
        return files
    
    def run(self):
        """è¿è¡Œå®Œæ•´æµç¨‹"""
        try:
            # 1. è·å–æ•°æ®
            result = self.fetch_1min_data()
            if result is None:
                return None
            
            df_1min, df_5min = result
            
            # 2. è®¡ç®—ç‰¹å¾
            df_features = self.calculate_features_from_1min(df_1min, df_5min)
            
            if df_features.empty:
                self._log("âŒ ç‰¹å¾è®¡ç®—å¤±è´¥")
                return None
            
            # 3. ç”Ÿæˆæ ‡ç­¾
            df_labeled = self.generate_labels(df_features, look_ahead=5)
            
            # 4. åˆ’åˆ†æ•°æ®é›†
            train, val, test = self.split_dataset(df_labeled)
            
            # 5. ä¿å­˜æ•°æ®é›†
            files = self.save_datasets(train, val, test, df_labeled)
            
            self._log(f"\n{'='*80}")
            self._log(f"âœ… æ•°æ®é‡‡é›†å®Œæˆï¼")
            self._log(f"{'='*80}")
            self._log(f"\n   æ€»æ•°æ®é‡: {len(df_labeled):,} æ¡")
            self._log(f"   æ—¥å¿—æ–‡ä»¶: {self.log_file}")
            
            return files
            
        except Exception as e:
            self._log(f"âŒ æ•°æ®é‡‡é›†å‡ºé”™: {e}")
            import traceback
            self._log(traceback.format_exc())
            return None


def main():
    parser = argparse.ArgumentParser(description='å¤§è§„æ¨¡1åˆ†é’ŸKçº¿æ•°æ®é‡‡é›†')
    parser.add_argument('--days', type=int, default=90, help='è·å–å¤©æ•°ï¼ˆé»˜è®¤90å¤©ï¼‰')
    parser.add_argument('--output-dir', type=str, default='/home/cx/trading_data/massive_1min', help='è¾“å‡ºç›®å½•')
    
    args = parser.parse_args()
    
    print(f"\n{'='*80}")
    print(f"ğŸš€ å¤§è§„æ¨¡1åˆ†é’ŸKçº¿æ•°æ®é‡‡é›†")
    print(f"{'='*80}")
    print(f"   ç›®æ ‡å¤©æ•°: {args.days} å¤©")
    print(f"   é¢„è®¡æ•°æ®é‡: {args.days * 24 * 60:,} æ¡")
    print(f"{'='*80}\n")
    
    collector = Massive1MinCollector(days=args.days, output_dir=args.output_dir)
    files = collector.run()
    
    if files:
        print(f"\n{'='*80}")
        print(f"âœ… æ•°æ®é‡‡é›†æˆåŠŸï¼å¯ä»¥å¼€å§‹è®­ç»ƒæ¨¡å‹")
        print(f"{'='*80}")
        print(f"\nè®­ç»ƒå‘½ä»¤ç¤ºä¾‹:")
        print(f"python train_all_real_models.py --train-file {files['train']} --val-file {files['val']}")


if __name__ == "__main__":
    main()
